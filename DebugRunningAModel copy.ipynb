{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:09:14.574671: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-29 13:09:14.620754: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-29 13:09:14.620784: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-29 13:09:14.622012: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 13:09:14.629981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-29 13:09:16.406494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "from functools import partial\n",
    "\n",
    "# add code directory to path\n",
    "import sys\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from metrics import top_k_onehot_indicator\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from torch_models import NegativeBinomialDebug, torch_bpr_uncurried, deterministic_bpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_df_to_3d_array(df):\n",
    "    # Ensure the DataFrame has a MultiIndex with 'geoid' and 'timestep'\n",
    "    if not isinstance(df.index, pd.MultiIndex) or set(df.index.names) != {'geoid', 'timestep'}:\n",
    "        raise ValueError(\"DataFrame must have a MultiIndex with levels 'geoid' and 'timestep'\")\n",
    "\n",
    "    # Get unique geoids and timesteps, sorted\n",
    "    geoids = sorted(df.index.get_level_values('geoid').unique())\n",
    "    timesteps = sorted(df.index.get_level_values('timestep').unique())\n",
    "\n",
    "    # Create a mapping of geoids to indices\n",
    "    geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "\n",
    "    # Initialize the 3D array\n",
    "    num_timesteps = len(timesteps)\n",
    "    num_locations = len(geoids)\n",
    "    num_features = len(df.columns)\n",
    "    X = np.zeros((num_timesteps, num_locations, num_features))\n",
    "\n",
    "    # Fill the 3D array\n",
    "    for (geoid, timestep), row in df.iterrows():\n",
    "        t_idx = timesteps.index(timestep)\n",
    "        g_idx = geoid_to_idx[geoid]\n",
    "        X[t_idx, g_idx, :] = row.values\n",
    "\n",
    "    return X, geoids, timesteps\n",
    "\n",
    "def convert_y_df_to_2d_array(y_df, geoids, timesteps):\n",
    "    # Ensure the DataFrame has a MultiIndex with 'geoid' and 'timestep'\n",
    "    if not isinstance(y_df.index, pd.MultiIndex) or set(y_df.index.names) != {'geoid', 'timestep'}:\n",
    "        raise ValueError(\"DataFrame must have a MultiIndex with levels 'geoid' and 'timestep'\")\n",
    "\n",
    "    # Initialize the 2D array\n",
    "    num_timesteps = len(timesteps)\n",
    "    num_locations = len(geoids)\n",
    "    y = np.zeros((num_timesteps, num_locations))\n",
    "\n",
    "    # Create a mapping of geoids to indices\n",
    "    geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "\n",
    "    # Fill the 2D array\n",
    "    for (geoid, timestep), value in y_df.iloc[:, 0].items():\n",
    "        t_idx = timesteps.index(timestep)\n",
    "        g_idx = geoid_to_idx[geoid]\n",
    "        y[t_idx, g_idx] = value\n",
    "\n",
    "    return y\n",
    "\n",
    "def evaluate_model(model, X, y, time, K, M_score_func, perturbed_top_K_func):\n",
    "    \"\"\"Evaluate model on given data and return metrics.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        dist = model(X, time)\n",
    "        \n",
    "        # Sample and calculate ratio ratings\n",
    "        y_sample_TMS = dist.sample((M_score_func,)).permute(1, 0, 2)\n",
    "        ratio_rating_TMS = y_sample_TMS/(1+y_sample_TMS.sum(dim=-1, keepdim=True))\n",
    "        ratio_rating_TS = ratio_rating_TMS.mean(dim=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        nll = -model.log_likelihood(y, X, time)\n",
    "        perturbed_bpr_T = torch_bpr_uncurried(ratio_rating_TS, y, K=K, \n",
    "                                             perturbed_top_K_func=perturbed_top_K_func)\n",
    "        deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, y, K=K)\n",
    "        \n",
    "        metrics = {\n",
    "            'nll': nll.item(),\n",
    "            'perturbed_bpr': torch.mean(perturbed_bpr_T).item(),\n",
    "            'deterministic_bpr': torch.mean(deterministic_bpr_T).item()\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "from torch import cuda\n",
    "\n",
    "\n",
    "def get_less_used_gpu(gpus=None, debug=False):\n",
    "    \"\"\"Inspect cached/reserved and allocated memory on specified gpus and return the id of the less used device\"\"\"\n",
    "    if gpus is None:\n",
    "        warn = 'Falling back to default: all gpus'\n",
    "        gpus = range(cuda.device_count())\n",
    "    elif isinstance(gpus, str):\n",
    "        gpus = [int(el) for el in gpus.split(',')]\n",
    "\n",
    "    # check gpus arg VS available gpus\n",
    "    sys_gpus = list(range(cuda.device_count()))\n",
    "    if len(gpus) > len(sys_gpus):\n",
    "        gpus = sys_gpus\n",
    "        warn = f'WARNING: Specified {len(gpus)} gpus, but only {cuda.device_count()} available. Falling back to default: all gpus.\\nIDs:\\t{list(gpus)}'\n",
    "    elif set(gpus).difference(sys_gpus):\n",
    "        # take correctly specified and add as much bad specifications as unused system gpus\n",
    "        available_gpus = set(gpus).intersection(sys_gpus)\n",
    "        unavailable_gpus = set(gpus).difference(sys_gpus)\n",
    "        unused_gpus = set(sys_gpus).difference(gpus)\n",
    "        gpus = list(available_gpus) + list(unused_gpus)[:len(unavailable_gpus)]\n",
    "        warn = f'GPU ids {unavailable_gpus} not available. Falling back to {len(gpus)} device(s).\\nIDs:\\t{list(gpus)}'\n",
    "\n",
    "    cur_allocated_mem = {}\n",
    "    cur_cached_mem = {}\n",
    "    max_allocated_mem = {}\n",
    "    max_cached_mem = {}\n",
    "    for i in gpus:\n",
    "        cur_allocated_mem[i] = cuda.memory_allocated(i)\n",
    "        cur_cached_mem[i] = cuda.memory_reserved(i)\n",
    "        max_allocated_mem[i] = cuda.max_memory_allocated(i)\n",
    "        max_cached_mem[i] = cuda.max_memory_reserved(i)\n",
    "    min_allocated = min(cur_allocated_mem, key=cur_allocated_mem.get)\n",
    "    if debug:\n",
    "        print(warn)\n",
    "        print('Current allocated memory:', {f'cuda:{k}': v for k, v in cur_allocated_mem.items()})\n",
    "        print('Current reserved memory:', {f'cuda:{k}': v for k, v in cur_cached_mem.items()})\n",
    "        print('Maximum allocated memory:', {f'cuda:{k}': v for k, v in max_allocated_mem.items()})\n",
    "        print('Maximum reserved memory:', {f'cuda:{k}': v for k, v in max_cached_mem.items()})\n",
    "        print('Suggested GPU:', min_allocated)\n",
    "    return min_allocated\n",
    "import gc\n",
    "import inspect\n",
    "def free_memory(to_delete: list, debug=False):\n",
    "    import gc\n",
    "    import inspect\n",
    "    calling_namespace = inspect.currentframe().f_back\n",
    "    if debug:\n",
    "        print('Before:')\n",
    "        get_less_used_gpu(debug=True)\n",
    "\n",
    "    for _var in to_delete:\n",
    "        calling_namespace.f_locals.pop(_var, None)\n",
    "        gc.collect()\n",
    "        cuda.empty_cache()\n",
    "    if debug:\n",
    "        print('After:')\n",
    "        get_less_used_gpu(debug=True)\n",
    "\n",
    "def train_epoch_neg_binom(model, optimizer, K, threshold,\n",
    "                         M_score_func, feat_TSF,\n",
    "                         time_T, train_y_TS,\n",
    "                         perturbed_top_K_func, bpr_weight, nll_weight, update=True):\n",
    "    \"\"\"Train one epoch of the negative binomial model.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_gradient_P = None\n",
    "    \n",
    "    for t in range(feat_TSF.shape[0]):\n",
    "        print(f'T: {t}!')\n",
    "        dist = model(feat_TSF[t:t+1], time_T[t:t+1])\n",
    "        \n",
    "        y_sample_TMS = dist.sample((M_score_func,)).permute(1, 0, 2)\n",
    "        action_denominator_TM = y_sample_TMS.sum(dim=-1, keepdim=True) + 1 \n",
    "\n",
    "        ratio_rating_TMS = y_sample_TMS / action_denominator_TM\n",
    "        ratio_rating_TS = ratio_rating_TMS.mean(dim=1)\n",
    "        ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "        def get_log_probs_baked(param):\n",
    "            distribution = model.build_from_single_tensor(param, feat_TSF[t:t+1], time_T[t:t+1])\n",
    "            log_probs_TMS = distribution.log_prob(y_sample_TMS.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "            return log_probs_TMS\n",
    "\n",
    "        jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, \n",
    "                                                      (model.params_to_single_tensor()), \n",
    "                                                      strategy='forward-mode', \n",
    "                                                      vectorize=True)\n",
    "\n",
    "        score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "        score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "        positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS[t:t+1]), \n",
    "                                             K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "\n",
    "        if nll_weight > 0:\n",
    "            bpr_threshold_diff_T = positive_bpr_T - threshold\n",
    "            violate_threshold_flag = bpr_threshold_diff_T < 0\n",
    "            negative_bpr_loss = torch.mean(-bpr_threshold_diff_T * violate_threshold_flag)\n",
    "        else:\n",
    "            negative_bpr_loss = torch.mean(-positive_bpr_T)\n",
    "\n",
    "        nll = -model.log_likelihood(train_y_TS[t:t+1], feat_TSF[t:t+1], time_T[t:t+1])\n",
    "        loss = bpr_weight * negative_bpr_loss + nll_weight * nll\n",
    "        loss.backward()\n",
    "\n",
    "        loss_grad_TS = ratio_rating_TS.grad\n",
    "        gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "        gradient_P = torch.sum(gradient_TSP, dim=[0, 1])\n",
    "        \n",
    "        if total_gradient_P is None:\n",
    "            total_gradient_P = gradient_P\n",
    "        else:\n",
    "            total_gradient_P += gradient_P\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        print(f'{jac_TMSP.shape}')\n",
    "        # Measure memory before and after an operation\n",
    "        start_memory = torch.cuda.memory_allocated()\n",
    "        del jac_TMSP, score_func_estimator_TMSP, y_sample_TMS, dist, gradient_TSP, score_func_estimator_TSP\n",
    "        gc.collect()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        end_memory = torch.cuda.memory_allocated()\n",
    "        print(f'Memory difference: {(end_memory - start_memory)/1024**2:.2f} MB')\n",
    "        print(f'Ending memory: {end_memory/1024**2:.2f} MB')\n",
    "        #print(f'{jac_TMSP.shape}')\n",
    "\n",
    "    gradient_tuple = model.single_tensor_to_params(total_gradient_P)\n",
    "\n",
    "    for param, gradient in zip(model.parameters(), gradient_tuple):\n",
    "        if nll_weight > 0:\n",
    "            gradient = gradient + param.grad\n",
    "        param.grad = gradient\n",
    "\n",
    "    if update:\n",
    "        optimizer.step()\n",
    "\n",
    "    deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n",
    "    det_bpr = torch.mean(deterministic_bpr_T)\n",
    "\n",
    "    metrics = {\n",
    "        'loss': total_loss ,\n",
    "        'deterministic_bpr': det_bpr.item(),\n",
    "        'perturbed_bpr': torch.mean(positive_bpr_T).item(),\n",
    "        'nll': nll.item()\n",
    "    }\n",
    "\n",
    "    return metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_nll_model = '/cluster/tufts/hugheslab/kheuto01/opioid_grid_try_fix_params/MA/K100_bw30_nw1_ss0.001_nss100_nps100_seed123_sig0.001_tr0.5'\n",
    "data_dir = '/cluster/tufts/hugheslab/fmuenc01/code/prob_diff_topk/data_dir/asurv/2monthly_ctxtSize5_small_5yrTrain//' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50\n",
    "bpr_weight = 0\n",
    "nll_weight = 1\n",
    "step_size = 0.001\n",
    "num_score_samples = 3\n",
    "num_pert_samples = 100\n",
    "seed = 123\n",
    "perturbed_noise = 0.001\n",
    "threshold = 0.5\n",
    "epochs = 1\n",
    "outdir = '/cluster/tufts/hugheslab/kheuto01/debug'\n",
    "device = 'cuda'\n",
    "val_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# Load training data\n",
    "train_X_df = pd.read_csv(os.path.join(data_dir, 'bird_train_x.csv'), index_col=[0,1])\n",
    "train_Y_df = pd.read_csv(os.path.join(data_dir, 'bird_train_y.csv'), index_col=[0,1])\n",
    "\n",
    "# Load validation data\n",
    "val_X_df = pd.read_csv(os.path.join(data_dir, 'bird_valid_x.csv'), index_col=[0,1])\n",
    "val_Y_df = pd.read_csv(os.path.join(data_dir, 'bird_valid_y.csv'), index_col=[0,1])\n",
    "\n",
    "# Process training data\n",
    "train_X, geoids, timesteps = convert_df_to_3d_array(train_X_df)#.drop(columns='timestep.1'))\n",
    "train_time_arr = np.array([timesteps] * len(geoids)).T\n",
    "train_y = convert_y_df_to_2d_array(train_Y_df, geoids, timesteps)\n",
    "\n",
    "# Process validation data\n",
    "val_X, _, val_timesteps = convert_df_to_3d_array(val_X_df)#.drop(columns='timestep.1'))\n",
    "val_time_arr = np.array([val_timesteps] * len(geoids)).T\n",
    "val_y = convert_y_df_to_2d_array(val_Y_df, geoids, val_timesteps)\n",
    "\n",
    "# Convert to tensors and move to device\n",
    "X_train = torch.tensor(train_X, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(train_y, dtype=torch.float32).to(device)\n",
    "time_train = torch.tensor(train_time_arr, dtype=torch.float32).to(device)\n",
    "\n",
    "X_val = torch.tensor(val_X, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(val_y, dtype=torch.float32).to(device)\n",
    "time_val = torch.tensor(val_time_arr, dtype=torch.float32).to(device)\n",
    "\n",
    "# Initialize model\n",
    "model = NegativeBinomialDebug(\n",
    "    num_locations=len(geoids),\n",
    "    num_fixed_effects=train_X.shape[2], device=device\n",
    ").to(device)\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)\n",
    "\n",
    "# Setup top-k function\n",
    "top_k_func = partial(top_k_onehot_indicator, k=K)\n",
    "perturbed_top_K_func = perturbed(top_k_func, sigma=perturbed_noise, num_samples=num_pert_samples)\n",
    "\n",
    "# Initialize metric tracking with separate epoch tracking for validation\n",
    "metrics = {\n",
    "    'train': {\n",
    "        'epochs': [], \n",
    "        'loss': [], \n",
    "        'nll': [], \n",
    "        'perturbed_bpr': [], \n",
    "        'deterministic_bpr': []\n",
    "    },\n",
    "    'val': {\n",
    "        'epochs': [], \n",
    "        'nll': [], \n",
    "        'perturbed_bpr': [], \n",
    "        'deterministic_bpr': []\n",
    "    },\n",
    "    'times': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1338, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_269964/1563398251.py:167: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS[t:t+1]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 2287.57 MB\n",
      "T: 1!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 2455.70 MB\n",
      "T: 2!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 2623.83 MB\n",
      "T: 3!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 2791.95 MB\n",
      "T: 4!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 2960.07 MB\n",
      "T: 5!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3128.19 MB\n",
      "T: 6!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3296.31 MB\n",
      "T: 7!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3464.44 MB\n",
      "T: 8!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3632.56 MB\n",
      "T: 9!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3800.68 MB\n",
      "T: 10!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 3968.80 MB\n",
      "T: 11!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 4136.93 MB\n",
      "T: 12!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 4305.05 MB\n",
      "T: 13!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 4473.17 MB\n",
      "T: 14!\n",
      "torch.Size([1, 3, 1338, 2690])\n",
      "Memory difference: -112.03 MB\n",
      "Ending memory: 4641.29 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_269964/1563398251.py:213: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epoch = 0\n",
    "\n",
    "# Training step\n",
    "train_metrics, model = train_epoch_neg_binom(\n",
    "    model, optimizer, K, threshold,\n",
    "    num_score_samples, X_train, time_train,\n",
    "    y_train, perturbed_top_K_func,\n",
    "    bpr_weight, nll_weight, device\n",
    ")\n",
    "\n",
    "# Update training metrics\n",
    "metrics['train']['epochs'].append(epoch)\n",
    "for metric, value in train_metrics.items():\n",
    "    metrics['train'][metric].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'epochs': [0],\n",
       "  'loss': [inf],\n",
       "  'nll': [inf],\n",
       "  'perturbed_bpr': [0.03333333134651184],\n",
       "  'deterministic_bpr': [0.0]},\n",
       " 'val': {'epochs': [],\n",
       "  'nll': [],\n",
       "  'perturbed_bpr': [],\n",
       "  'deterministic_bpr': []},\n",
       " 'times': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
