{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 13:07:54.111212: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-12 13:07:54.154828: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 13:07:54.154861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 13:07:54.155898: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 13:07:54.163393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 13:07:58.681426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Poisson, MixtureSameFamily\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from torch_perturb.torch_pert_topk import PerturbedTopK\n",
    "from torch_models import MixtureOfPoissonsModel, torch_bpr_uncurried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "# tracts/distributions\n",
    "S=12\n",
    "# history/features\n",
    "H = 3\n",
    "# total timepoints\n",
    "T= 500\n",
    "num_components=4\n",
    "K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 13:08:27.748410: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-12 13:08:27.748446: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: s1cmp008.pax.tufts.edu\n",
      "2024-07-12 13:08:27.748452: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: s1cmp008.pax.tufts.edu\n",
      "2024-07-12 13:08:27.748487: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.129.3\n",
      "2024-07-12 13:08:27.748511: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2024-07-12 13:08:27.748517: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.129.3\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = example_datasets(H, T, seed=seed)\n",
    "train_X_THS, train_y_TS = to_numpy(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_log_rates = torch.log(torch.tensor([0+1e-8, 7, 10, 100]))\n",
    "ideal_mix_weights = torch.log(1e-13 + torch.tensor(\n",
    "                                [[0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = MixtureOfPoissonsModel()\n",
    "step_size = 0.05\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)\n",
    "model.update_params(torch.cat([ideal_log_rates, ideal_mix_weights.view(-1)]))\n",
    "#model.update_params(torch.cat([bpr_log_rates, bpr_mix_weights.view(-1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_score_func =  200\n",
    "M_action = 200\n",
    "train_T = train_y_TS.shape[0]\n",
    "perturbed_top_K_func = PerturbedTopK(k=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_model = model()\n",
    "sample = mix_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  9.,  4.,  9., 12.,  0., 13., 15.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9038, -2.2886, -2.3944, -2.2886, -2.7129, -1.2039, -2.9752, -3.7172,\n",
       "        -0.1054, -0.1054, -0.1054, -0.1054], grad_fn=<LogsumexpBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_model.log_prob(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "bprs = []\n",
    "nlls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg bpr: -0.5340473651885986\n",
      "nll: 5465.9228515625\n",
      "Loss: 5198.8994140625\n",
      "Neg bpr: -0.5160810351371765\n",
      "nll: 5502.291015625\n",
      "Loss: 5244.25048828125\n",
      "Neg bpr: -0.5138471722602844\n",
      "nll: 5583.00732421875\n",
      "Loss: 5326.083984375\n",
      "Neg bpr: -0.5174436569213867\n",
      "nll: 5579.869140625\n",
      "Loss: 5321.1474609375\n",
      "Neg bpr: -0.5164773464202881\n",
      "nll: 5557.49658203125\n",
      "Loss: 5299.2578125\n",
      "Neg bpr: -0.5135536789894104\n",
      "nll: 5550.232421875\n",
      "Loss: 5293.45556640625\n",
      "Neg bpr: -0.5140158534049988\n",
      "nll: 5566.26123046875\n",
      "Loss: 5309.25341796875\n",
      "Neg bpr: -0.5116745233535767\n",
      "nll: 5549.02001953125\n",
      "Loss: 5293.1826171875\n",
      "Neg bpr: -0.5121027231216431\n",
      "nll: 5531.09521484375\n",
      "Loss: 5275.0439453125\n",
      "Neg bpr: -0.5115639567375183\n",
      "nll: 5516.201171875\n",
      "Loss: 5260.4189453125\n",
      "Neg bpr: -0.5182583928108215\n",
      "nll: 5501.34033203125\n",
      "Loss: 5242.2109375\n",
      "Neg bpr: -0.5081961154937744\n",
      "nll: 5499.42626953125\n",
      "Loss: 5245.328125\n",
      "Neg bpr: -0.5147411823272705\n",
      "nll: 5506.16357421875\n",
      "Loss: 5248.79296875\n",
      "Neg bpr: -0.5120266079902649\n",
      "nll: 5517.39501953125\n",
      "Loss: 5261.3818359375\n",
      "Neg bpr: -0.510908842086792\n",
      "nll: 5527.337890625\n",
      "Loss: 5271.88330078125\n",
      "Neg bpr: -0.5103322863578796\n",
      "nll: 5539.90185546875\n",
      "Loss: 5284.73583984375\n",
      "Neg bpr: -0.5093417167663574\n",
      "nll: 5554.85400390625\n",
      "Loss: 5300.18310546875\n",
      "Neg bpr: -0.5141302347183228\n",
      "nll: 5567.8271484375\n",
      "Loss: 5310.76220703125\n",
      "Neg bpr: -0.5074089765548706\n",
      "nll: 5571.08447265625\n",
      "Loss: 5317.3798828125\n",
      "Neg bpr: -0.5081238746643066\n",
      "nll: 5564.9345703125\n",
      "Loss: 5310.87255859375\n",
      "Neg bpr: -0.5095306038856506\n",
      "nll: 5566.234375\n",
      "Loss: 5311.46923828125\n",
      "Neg bpr: -0.5137625336647034\n",
      "nll: 5576.3076171875\n",
      "Loss: 5319.42626953125\n",
      "Neg bpr: -0.5036855340003967\n",
      "nll: 5596.8017578125\n",
      "Loss: 5344.958984375\n",
      "Neg bpr: -0.5086763501167297\n",
      "nll: 5622.14013671875\n",
      "Loss: 5367.8017578125\n",
      "Neg bpr: -0.5021991729736328\n",
      "nll: 5640.28466796875\n",
      "Loss: 5389.18505859375\n",
      "Neg bpr: -0.5095291137695312\n",
      "nll: 5661.9052734375\n",
      "Loss: 5407.140625\n",
      "Neg bpr: -0.5068106055259705\n",
      "nll: 5682.7021484375\n",
      "Loss: 5429.296875\n",
      "Neg bpr: -0.5029416084289551\n",
      "nll: 5704.9453125\n",
      "Loss: 5453.474609375\n",
      "Neg bpr: -0.5046893358230591\n",
      "nll: 5735.68994140625\n",
      "Loss: 5483.34521484375\n",
      "Neg bpr: -0.5034229755401611\n",
      "nll: 5778.1767578125\n",
      "Loss: 5526.46533203125\n",
      "Neg bpr: -0.4964176416397095\n",
      "nll: 5814.576171875\n",
      "Loss: 5566.3671875\n",
      "Neg bpr: -0.4931028187274933\n",
      "nll: 5846.37939453125\n",
      "Loss: 5599.828125\n",
      "Neg bpr: -0.4965498447418213\n",
      "nll: 5877.78564453125\n",
      "Loss: 5629.5107421875\n",
      "Neg bpr: -0.4913156032562256\n",
      "nll: 5906.05322265625\n",
      "Loss: 5660.3955078125\n",
      "Neg bpr: -0.49031758308410645\n",
      "nll: 5939.64501953125\n",
      "Loss: 5694.486328125\n",
      "Neg bpr: -0.4888381063938141\n",
      "nll: 5968.3173828125\n",
      "Loss: 5723.8984375\n",
      "Neg bpr: -0.4938386082649231\n",
      "nll: 6008.20263671875\n",
      "Loss: 5761.283203125\n",
      "Neg bpr: -0.49308300018310547\n",
      "nll: 6056.88134765625\n",
      "Loss: 5810.33984375\n",
      "Neg bpr: -0.49431148171424866\n",
      "nll: 6086.17041015625\n",
      "Loss: 5839.0146484375\n",
      "Neg bpr: -0.493246853351593\n",
      "nll: 6114.0361328125\n",
      "Loss: 5867.41259765625\n",
      "Neg bpr: -0.49412062764167786\n",
      "nll: 6117.2578125\n",
      "Loss: 5870.197265625\n",
      "Neg bpr: -0.49033233523368835\n",
      "nll: 6129.783203125\n",
      "Loss: 5884.6171875\n",
      "Neg bpr: -0.49299585819244385\n",
      "nll: 6124.84130859375\n",
      "Loss: 5878.34326171875\n",
      "Neg bpr: -0.49267110228538513\n",
      "nll: 6119.67431640625\n",
      "Loss: 5873.3388671875\n",
      "Neg bpr: -0.49232423305511475\n",
      "nll: 6118.79296875\n",
      "Loss: 5872.630859375\n",
      "Neg bpr: -0.4924684762954712\n",
      "nll: 6106.39453125\n",
      "Loss: 5860.16015625\n",
      "Neg bpr: -0.48853784799575806\n",
      "nll: 6117.7900390625\n",
      "Loss: 5873.52099609375\n",
      "Neg bpr: -0.48698297142982483\n",
      "nll: 6110.57373046875\n",
      "Loss: 5867.08203125\n",
      "Neg bpr: -0.48887261748313904\n",
      "nll: 6109.25\n",
      "Loss: 5864.8134765625\n",
      "Neg bpr: -0.4859298765659332\n",
      "nll: 6124.001953125\n",
      "Loss: 5881.037109375\n",
      "Neg bpr: -0.48780959844589233\n",
      "nll: 6158.150390625\n",
      "Loss: 5914.24560546875\n",
      "Neg bpr: -0.4866870045661926\n",
      "nll: 6184.0009765625\n",
      "Loss: 5940.6572265625\n",
      "Neg bpr: -0.48446890711784363\n",
      "nll: 6213.68310546875\n",
      "Loss: 5971.44873046875\n",
      "Neg bpr: -0.48477113246917725\n",
      "nll: 6244.79296875\n",
      "Loss: 6002.4072265625\n",
      "Neg bpr: -0.4870055019855499\n",
      "nll: 6278.93408203125\n",
      "Loss: 6035.43115234375\n",
      "Neg bpr: -0.4878791272640228\n",
      "nll: 6360.12939453125\n",
      "Loss: 6116.18994140625\n",
      "Neg bpr: -0.4889777600765228\n",
      "nll: 6452.99560546875\n",
      "Loss: 6208.5068359375\n",
      "Neg bpr: -0.4887767434120178\n",
      "nll: 6543.95654296875\n",
      "Loss: 6299.568359375\n",
      "Neg bpr: -0.4920898973941803\n",
      "nll: 6616.5361328125\n",
      "Loss: 6370.4912109375\n",
      "Neg bpr: -0.493540495634079\n",
      "nll: 6680.84326171875\n",
      "Loss: 6434.0732421875\n",
      "Neg bpr: -0.4890279769897461\n",
      "nll: 6747.41943359375\n",
      "Loss: 6502.9052734375\n",
      "Neg bpr: -0.4920867383480072\n",
      "nll: 6844.04638671875\n",
      "Loss: 6598.0029296875\n",
      "Neg bpr: -0.4864135682582855\n",
      "nll: 6897.78466796875\n",
      "Loss: 6654.578125\n",
      "Neg bpr: -0.4899001121520996\n",
      "nll: 6940.1953125\n",
      "Loss: 6695.2451171875\n",
      "Neg bpr: -0.49134644865989685\n",
      "nll: 6931.7998046875\n",
      "Loss: 6686.12646484375\n",
      "Neg bpr: -0.4864991307258606\n",
      "nll: 6957.55517578125\n",
      "Loss: 6714.3056640625\n",
      "Neg bpr: -0.4861244857311249\n",
      "nll: 7023.78125\n",
      "Loss: 6780.71923828125\n",
      "Neg bpr: -0.4858120083808899\n",
      "nll: 7079.546875\n",
      "Loss: 6836.640625\n",
      "Neg bpr: -0.47810032963752747\n",
      "nll: 7130.775390625\n",
      "Loss: 6891.72509765625\n",
      "Neg bpr: -0.47774821519851685\n",
      "nll: 7153.42236328125\n",
      "Loss: 6914.54833984375\n",
      "Neg bpr: -0.47432708740234375\n",
      "nll: 7175.74267578125\n",
      "Loss: 6938.5791015625\n",
      "Neg bpr: -0.47644272446632385\n",
      "nll: 7184.06494140625\n",
      "Loss: 6945.84375\n",
      "Neg bpr: -0.46203485131263733\n",
      "nll: 7181.40283203125\n",
      "Loss: 6950.38525390625\n",
      "Neg bpr: -0.4614846706390381\n",
      "nll: 7184.92578125\n",
      "Loss: 6954.18359375\n",
      "Neg bpr: -0.4576413035392761\n",
      "nll: 7158.9951171875\n",
      "Loss: 6930.17431640625\n",
      "Neg bpr: -0.4618161916732788\n",
      "nll: 7146.00537109375\n",
      "Loss: 6915.09716796875\n",
      "Neg bpr: -0.4616219103336334\n",
      "nll: 7139.40478515625\n",
      "Loss: 6908.59375\n",
      "Neg bpr: -0.46735647320747375\n",
      "nll: 7122.3583984375\n",
      "Loss: 6888.68017578125\n",
      "Neg bpr: -0.46642935276031494\n",
      "nll: 7135.30517578125\n",
      "Loss: 6902.09033203125\n",
      "Neg bpr: -0.4690653085708618\n",
      "nll: 7145.05859375\n",
      "Loss: 6910.52587890625\n",
      "Neg bpr: -0.4723200500011444\n",
      "nll: 7164.6572265625\n",
      "Loss: 6928.4970703125\n",
      "Neg bpr: -0.480920672416687\n",
      "nll: 7167.8583984375\n",
      "Loss: 6927.39794921875\n",
      "Neg bpr: -0.47865426540374756\n",
      "nll: 7200.30810546875\n",
      "Loss: 6960.98095703125\n",
      "Neg bpr: -0.4818461239337921\n",
      "nll: 7197.5458984375\n",
      "Loss: 6956.623046875\n",
      "Neg bpr: -0.4828372597694397\n",
      "nll: 7215.52197265625\n",
      "Loss: 6974.103515625\n",
      "Neg bpr: -0.48754093050956726\n",
      "nll: 7271.1787109375\n",
      "Loss: 7027.408203125\n",
      "Neg bpr: -0.49761006236076355\n",
      "nll: 7369.0478515625\n",
      "Loss: 7120.24267578125\n",
      "Neg bpr: -0.4932117760181427\n",
      "nll: 7473.05859375\n",
      "Loss: 7226.45263671875\n",
      "Neg bpr: -0.5026246309280396\n",
      "nll: 7537.9765625\n",
      "Loss: 7286.6640625\n",
      "Neg bpr: -0.5120265483856201\n",
      "nll: 7594.9287109375\n",
      "Loss: 7338.91552734375\n",
      "Neg bpr: -0.5134085416793823\n",
      "nll: 7662.5966796875\n",
      "Loss: 7405.892578125\n",
      "Neg bpr: -0.5198511481285095\n",
      "nll: 7745.13330078125\n",
      "Loss: 7485.20751953125\n",
      "Neg bpr: -0.5216363668441772\n",
      "nll: 7822.37939453125\n",
      "Loss: 7561.56103515625\n",
      "Neg bpr: -0.5292015075683594\n",
      "nll: 7886.478515625\n",
      "Loss: 7621.8779296875\n",
      "Neg bpr: -0.5357282757759094\n",
      "nll: 7973.03125\n",
      "Loss: 7705.1669921875\n",
      "Neg bpr: -0.53460294008255\n",
      "nll: 8071.8115234375\n",
      "Loss: 7804.51025390625\n",
      "Neg bpr: -0.5335212349891663\n",
      "nll: 8108.328125\n",
      "Loss: 7841.5673828125\n",
      "Neg bpr: -0.5358447432518005\n",
      "nll: 8128.9150390625\n",
      "Loss: 7860.99267578125\n",
      "Neg bpr: -0.5394330024719238\n",
      "nll: 8188.34814453125\n",
      "Loss: 7918.6318359375\n",
      "Neg bpr: -0.5420064926147461\n",
      "nll: 8267.609375\n",
      "Loss: 7996.60595703125\n",
      "Neg bpr: -0.5392264127731323\n",
      "nll: 8334.0869140625\n",
      "Loss: 8064.4736328125\n",
      "Neg bpr: -0.5446026921272278\n",
      "nll: 8358.29296875\n",
      "Loss: 8085.99169921875\n",
      "Neg bpr: -0.5454350709915161\n",
      "nll: 8365.064453125\n",
      "Loss: 8092.3466796875\n",
      "Neg bpr: -0.5435779690742493\n",
      "nll: 8310.341796875\n",
      "Loss: 8038.552734375\n",
      "Neg bpr: -0.5424025654792786\n",
      "nll: 8273.6201171875\n",
      "Loss: 8002.4189453125\n",
      "Neg bpr: -0.5457307696342468\n",
      "nll: 8246.712890625\n",
      "Loss: 7973.84765625\n",
      "Neg bpr: -0.5440312027931213\n",
      "nll: 8228.8525390625\n",
      "Loss: 7956.8369140625\n",
      "Neg bpr: -0.5438961982727051\n",
      "nll: 8165.34619140625\n",
      "Loss: 7893.39794921875\n",
      "Neg bpr: -0.5464057326316833\n",
      "nll: 8137.87109375\n",
      "Loss: 7864.66796875\n",
      "Neg bpr: -0.5469610691070557\n",
      "nll: 8121.0634765625\n",
      "Loss: 7847.5830078125\n",
      "Neg bpr: -0.5513536334037781\n",
      "nll: 8126.24609375\n",
      "Loss: 7850.5693359375\n",
      "Neg bpr: -0.5526814460754395\n",
      "nll: 8094.27294921875\n",
      "Loss: 7817.93212890625\n",
      "Neg bpr: -0.550962507724762\n",
      "nll: 8055.81103515625\n",
      "Loss: 7780.32958984375\n",
      "Neg bpr: -0.5550961494445801\n",
      "nll: 8035.7578125\n",
      "Loss: 7758.2099609375\n",
      "Neg bpr: -0.5538991093635559\n",
      "nll: 8017.5810546875\n",
      "Loss: 7740.63134765625\n",
      "Neg bpr: -0.5566808581352234\n",
      "nll: 7980.0537109375\n",
      "Loss: 7701.71337890625\n",
      "Neg bpr: -0.5614627003669739\n",
      "nll: 7951.95849609375\n",
      "Loss: 7671.22705078125\n",
      "Neg bpr: -0.5588000416755676\n",
      "nll: 7936.93896484375\n",
      "Loss: 7657.5390625\n",
      "Neg bpr: -0.5611971616744995\n",
      "nll: 7927.71044921875\n",
      "Loss: 7647.11181640625\n",
      "Neg bpr: -0.561447262763977\n",
      "nll: 7926.7578125\n",
      "Loss: 7646.0341796875\n",
      "Neg bpr: -0.5643628835678101\n",
      "nll: 7882.787109375\n",
      "Loss: 7600.60546875\n",
      "Neg bpr: -0.563014030456543\n",
      "nll: 7818.38134765625\n",
      "Loss: 7536.87451171875\n",
      "Neg bpr: -0.5658795237541199\n",
      "nll: 7763.7451171875\n",
      "Loss: 7480.80517578125\n",
      "Neg bpr: -0.5659390091896057\n",
      "nll: 7719.31396484375\n",
      "Loss: 7436.34423828125\n",
      "Neg bpr: -0.5692453980445862\n",
      "nll: 7723.41650390625\n",
      "Loss: 7438.7939453125\n",
      "Neg bpr: -0.5671571493148804\n",
      "nll: 7726.2783203125\n",
      "Loss: 7442.69970703125\n",
      "Neg bpr: -0.566699743270874\n",
      "nll: 7674.85009765625\n",
      "Loss: 7391.5\n",
      "Neg bpr: -0.5668871998786926\n",
      "nll: 7632.333984375\n",
      "Loss: 7348.890625\n",
      "Neg bpr: -0.5656934380531311\n",
      "nll: 7598.396484375\n",
      "Loss: 7315.5498046875\n",
      "Neg bpr: -0.5670047998428345\n",
      "nll: 7584.2724609375\n",
      "Loss: 7300.77001953125\n",
      "Neg bpr: -0.5664202570915222\n",
      "nll: 7598.4267578125\n",
      "Loss: 7315.216796875\n",
      "Neg bpr: -0.5657911896705627\n",
      "nll: 7576.32373046875\n",
      "Loss: 7293.42822265625\n",
      "Neg bpr: -0.5684695839881897\n",
      "nll: 7560.87255859375\n",
      "Loss: 7276.6376953125\n",
      "Neg bpr: -0.5666313767433167\n",
      "nll: 7559.796875\n",
      "Loss: 7276.4814453125\n",
      "Neg bpr: -0.566200852394104\n",
      "nll: 7599.3427734375\n",
      "Loss: 7316.2421875\n",
      "Neg bpr: -0.567466676235199\n",
      "nll: 7633.19091796875\n",
      "Loss: 7349.45751953125\n",
      "Neg bpr: -0.5653778314590454\n",
      "nll: 7621.17578125\n",
      "Loss: 7338.48681640625\n",
      "Neg bpr: -0.5663771033287048\n",
      "nll: 7605.99365234375\n",
      "Loss: 7322.80517578125\n",
      "Neg bpr: -0.5661791563034058\n",
      "nll: 7661.14892578125\n",
      "Loss: 7378.0595703125\n",
      "Neg bpr: -0.5661619305610657\n",
      "nll: 7703.357421875\n",
      "Loss: 7420.2763671875\n",
      "Neg bpr: -0.5662937164306641\n",
      "nll: 7732.68603515625\n",
      "Loss: 7449.5390625\n",
      "Neg bpr: -0.5660015940666199\n",
      "nll: 7732.7294921875\n",
      "Loss: 7449.728515625\n",
      "Neg bpr: -0.570304274559021\n",
      "nll: 7643.1533203125\n",
      "Loss: 7358.0009765625\n",
      "Neg bpr: -0.5680964589118958\n",
      "nll: 7583.169921875\n",
      "Loss: 7299.12158203125\n",
      "Neg bpr: -0.5695468783378601\n",
      "nll: 7544.72802734375\n",
      "Loss: 7259.95458984375\n",
      "Neg bpr: -0.5694087147712708\n",
      "nll: 7482.1669921875\n",
      "Loss: 7197.462890625\n",
      "Neg bpr: -0.5683522820472717\n",
      "nll: 7471.37060546875\n",
      "Loss: 7187.1943359375\n",
      "Neg bpr: -0.5695552229881287\n",
      "nll: 7466.3056640625\n",
      "Loss: 7181.52783203125\n",
      "Neg bpr: -0.5713596343994141\n",
      "nll: 7447.0234375\n",
      "Loss: 7161.34375\n",
      "Neg bpr: -0.5739695429801941\n",
      "nll: 7464.81787109375\n",
      "Loss: 7177.8330078125\n",
      "Neg bpr: -0.570131242275238\n",
      "nll: 7552.220703125\n",
      "Loss: 7267.1552734375\n",
      "Neg bpr: -0.5709435939788818\n",
      "nll: 7640.892578125\n",
      "Loss: 7355.4208984375\n",
      "Neg bpr: -0.5718132257461548\n",
      "nll: 7738.57421875\n",
      "Loss: 7452.66748046875\n",
      "Neg bpr: -0.5740909576416016\n",
      "nll: 7789.9638671875\n",
      "Loss: 7502.91845703125\n",
      "Neg bpr: -0.5725888013839722\n",
      "nll: 7817.30712890625\n",
      "Loss: 7531.0126953125\n",
      "Neg bpr: -0.5695309042930603\n",
      "nll: 7842.7421875\n",
      "Loss: 7557.9765625\n",
      "Neg bpr: -0.5726183652877808\n",
      "nll: 7871.02685546875\n",
      "Loss: 7584.7177734375\n",
      "Neg bpr: -0.5750787258148193\n",
      "nll: 7888.77490234375\n",
      "Loss: 7601.2353515625\n",
      "Neg bpr: -0.572639524936676\n",
      "nll: 7930.119140625\n",
      "Loss: 7643.79931640625\n",
      "Neg bpr: -0.573218584060669\n",
      "nll: 7974.57861328125\n",
      "Loss: 7687.96923828125\n",
      "Neg bpr: -0.5731436610221863\n",
      "nll: 8013.146484375\n",
      "Loss: 7726.57470703125\n",
      "Neg bpr: -0.5727843642234802\n",
      "nll: 8049.384765625\n",
      "Loss: 7762.99267578125\n",
      "Neg bpr: -0.5738515853881836\n",
      "nll: 8070.89794921875\n",
      "Loss: 7783.97216796875\n",
      "Neg bpr: -0.5756657123565674\n",
      "nll: 8116.9208984375\n",
      "Loss: 7829.087890625\n",
      "Neg bpr: -0.5761299729347229\n",
      "nll: 8216.9873046875\n",
      "Loss: 7928.92236328125\n",
      "Neg bpr: -0.5728533864021301\n",
      "nll: 8292.587890625\n",
      "Loss: 8006.1611328125\n",
      "Neg bpr: -0.5739243030548096\n",
      "nll: 8399.6865234375\n",
      "Loss: 8112.724609375\n",
      "Neg bpr: -0.5753170251846313\n",
      "nll: 8515.1162109375\n",
      "Loss: 8227.4580078125\n",
      "Neg bpr: -0.5735155344009399\n",
      "nll: 8649.0341796875\n",
      "Loss: 8362.2763671875\n",
      "Neg bpr: -0.5737621784210205\n",
      "nll: 8800.78515625\n",
      "Loss: 8513.904296875\n",
      "Neg bpr: -0.5737471580505371\n",
      "nll: 8980.703125\n",
      "Loss: 8693.8291015625\n",
      "Neg bpr: -0.5755446553230286\n",
      "nll: 9152.244140625\n",
      "Loss: 8864.4716796875\n",
      "Neg bpr: -0.5747362375259399\n",
      "nll: 9357.0419921875\n",
      "Loss: 9069.673828125\n",
      "Neg bpr: -0.5736743807792664\n",
      "nll: 9475.3369140625\n",
      "Loss: 9188.5\n",
      "Neg bpr: -0.5733276009559631\n",
      "nll: 9507.533203125\n",
      "Loss: 9220.869140625\n",
      "Neg bpr: -0.5760546922683716\n",
      "nll: 9626.421875\n",
      "Loss: 9338.39453125\n",
      "Neg bpr: -0.5723525881767273\n",
      "nll: 9658.017578125\n",
      "Loss: 9371.8408203125\n",
      "Neg bpr: -0.5711215734481812\n",
      "nll: 9723.400390625\n",
      "Loss: 9437.83984375\n",
      "Neg bpr: -0.5702742338180542\n",
      "nll: 9746.056640625\n",
      "Loss: 9460.919921875\n",
      "Neg bpr: -0.5697832107543945\n",
      "nll: 9747.3583984375\n",
      "Loss: 9462.466796875\n",
      "Neg bpr: -0.5686047077178955\n",
      "nll: 9704.50390625\n",
      "Loss: 9420.201171875\n",
      "Neg bpr: -0.5713523626327515\n",
      "nll: 9628.517578125\n",
      "Loss: 9342.841796875\n",
      "Neg bpr: -0.5683571100234985\n",
      "nll: 9523.2080078125\n",
      "Loss: 9239.029296875\n",
      "Neg bpr: -0.568727433681488\n",
      "nll: 9358.306640625\n",
      "Loss: 9073.943359375\n",
      "Neg bpr: -0.5713145136833191\n",
      "nll: 9204.1875\n",
      "Loss: 8918.5302734375\n",
      "Neg bpr: -0.5701979398727417\n",
      "nll: 9114.232421875\n",
      "Loss: 8829.1337890625\n",
      "Neg bpr: -0.5694057941436768\n",
      "nll: 9024.099609375\n",
      "Loss: 8739.396484375\n",
      "Neg bpr: -0.5674859881401062\n",
      "nll: 8919.181640625\n",
      "Loss: 8635.4384765625\n",
      "Neg bpr: -0.5673000812530518\n",
      "nll: 8866.58984375\n",
      "Loss: 8582.939453125\n",
      "Neg bpr: -0.5655885934829712\n",
      "nll: 8787.1796875\n",
      "Loss: 8504.3857421875\n",
      "Neg bpr: -0.5673509240150452\n",
      "nll: 8667.86328125\n",
      "Loss: 8384.1875\n",
      "Neg bpr: -0.565925657749176\n",
      "nll: 8539.1884765625\n",
      "Loss: 8256.2255859375\n",
      "Neg bpr: -0.5676812529563904\n",
      "nll: 8462.650390625\n",
      "Loss: 8178.8095703125\n",
      "Neg bpr: -0.5655254125595093\n",
      "nll: 8387.7607421875\n",
      "Loss: 8104.998046875\n",
      "Neg bpr: -0.5667415261268616\n",
      "nll: 8352.9453125\n",
      "Loss: 8069.57470703125\n",
      "Neg bpr: -0.5653455853462219\n",
      "nll: 8287.314453125\n",
      "Loss: 8004.6416015625\n",
      "Neg bpr: -0.5662413239479065\n",
      "nll: 8192.5703125\n",
      "Loss: 7909.44970703125\n",
      "Neg bpr: -0.5646127462387085\n",
      "nll: 8109.1455078125\n",
      "Loss: 7826.83935546875\n",
      "Neg bpr: -0.5642277002334595\n",
      "nll: 8000.52001953125\n",
      "Loss: 7718.40625\n",
      "Neg bpr: -0.5641566514968872\n",
      "nll: 7901.70849609375\n",
      "Loss: 7619.63037109375\n",
      "Neg bpr: -0.5668704509735107\n",
      "nll: 7811.9296875\n",
      "Loss: 7528.49462890625\n",
      "Neg bpr: -0.5647832155227661\n",
      "nll: 7727.3876953125\n",
      "Loss: 7444.99609375\n",
      "Neg bpr: -0.5635161995887756\n",
      "nll: 7640.8369140625\n",
      "Loss: 7359.07861328125\n",
      "Neg bpr: -0.5643818378448486\n",
      "nll: 7594.77734375\n",
      "Loss: 7312.58642578125\n",
      "Neg bpr: -0.5641852021217346\n",
      "nll: 7540.24658203125\n",
      "Loss: 7258.15380859375\n",
      "Neg bpr: -0.5635073184967041\n",
      "nll: 7481.9501953125\n",
      "Loss: 7200.1962890625\n",
      "Neg bpr: -0.561940610408783\n",
      "nll: 7407.599609375\n",
      "Loss: 7126.62939453125\n",
      "Neg bpr: -0.5644326210021973\n",
      "nll: 7321.02734375\n",
      "Loss: 7038.81103515625\n",
      "Neg bpr: -0.5650928020477295\n",
      "nll: 7213.791015625\n",
      "Loss: 6931.24462890625\n",
      "Neg bpr: -0.5646893382072449\n",
      "nll: 7147.04638671875\n",
      "Loss: 6864.70166015625\n",
      "Neg bpr: -0.5665292143821716\n",
      "nll: 7100.7529296875\n",
      "Loss: 6817.48828125\n",
      "Neg bpr: -0.5692877173423767\n",
      "nll: 7066.33837890625\n",
      "Loss: 6781.6943359375\n",
      "Neg bpr: -0.5673072338104248\n",
      "nll: 7042.71630859375\n",
      "Loss: 6759.0625\n",
      "Neg bpr: -0.5681143403053284\n",
      "nll: 7022.01123046875\n",
      "Loss: 6737.9541015625\n",
      "Neg bpr: -0.5696154236793518\n",
      "nll: 6995.54638671875\n",
      "Loss: 6710.73876953125\n",
      "Neg bpr: -0.5663735866546631\n",
      "nll: 6977.45654296875\n",
      "Loss: 6694.26953125\n",
      "Neg bpr: -0.5676184296607971\n",
      "nll: 6946.38671875\n",
      "Loss: 6662.57763671875\n",
      "Neg bpr: -0.5677216649055481\n",
      "nll: 6924.4873046875\n",
      "Loss: 6640.62646484375\n",
      "Neg bpr: -0.5702840089797974\n",
      "nll: 6930.05859375\n",
      "Loss: 6644.91650390625\n",
      "Neg bpr: -0.5684458017349243\n",
      "nll: 6936.599609375\n",
      "Loss: 6652.376953125\n",
      "Neg bpr: -0.5678443312644958\n",
      "nll: 6940.1396484375\n",
      "Loss: 6656.21728515625\n",
      "Neg bpr: -0.5681637525558472\n",
      "nll: 6943.1396484375\n",
      "Loss: 6659.0576171875\n",
      "Neg bpr: -0.5690021514892578\n",
      "nll: 6970.556640625\n",
      "Loss: 6686.0556640625\n",
      "Neg bpr: -0.5674760341644287\n",
      "nll: 6990.47265625\n",
      "Loss: 6706.73486328125\n",
      "Neg bpr: -0.5662346482276917\n",
      "nll: 7018.8740234375\n",
      "Loss: 6735.7568359375\n",
      "Neg bpr: -0.5660901069641113\n",
      "nll: 7050.376953125\n",
      "Loss: 6767.33203125\n",
      "Neg bpr: -0.5674326419830322\n",
      "nll: 7065.76025390625\n",
      "Loss: 6782.0439453125\n",
      "Neg bpr: -0.567868173122406\n",
      "nll: 7095.30615234375\n",
      "Loss: 6811.3720703125\n",
      "Neg bpr: -0.5667380094528198\n",
      "nll: 7140.63818359375\n",
      "Loss: 6857.26904296875\n",
      "Neg bpr: -0.5651305913925171\n",
      "nll: 7162.7431640625\n",
      "Loss: 6880.177734375\n",
      "Neg bpr: -0.5639851093292236\n",
      "nll: 7188.5498046875\n",
      "Loss: 6906.55712890625\n",
      "Neg bpr: -0.5615097284317017\n",
      "nll: 7238.14306640625\n",
      "Loss: 6957.38818359375\n",
      "Neg bpr: -0.5606035590171814\n",
      "nll: 7308.91796875\n",
      "Loss: 7028.6162109375\n",
      "Neg bpr: -0.563624382019043\n",
      "nll: 7368.03515625\n",
      "Loss: 7086.22314453125\n",
      "Neg bpr: -0.5627297759056091\n",
      "nll: 7403.8818359375\n",
      "Loss: 7122.51708984375\n",
      "Neg bpr: -0.5592966079711914\n",
      "nll: 7460.65869140625\n",
      "Loss: 7181.01025390625\n",
      "Neg bpr: -0.5608878135681152\n",
      "nll: 7518.72802734375\n",
      "Loss: 7238.2841796875\n",
      "Neg bpr: -0.5575690865516663\n",
      "nll: 7579.19775390625\n",
      "Loss: 7300.4130859375\n",
      "Neg bpr: -0.559964120388031\n",
      "nll: 7632.5703125\n",
      "Loss: 7352.58837890625\n",
      "Neg bpr: -0.5574987530708313\n",
      "nll: 7677.8681640625\n",
      "Loss: 7399.11865234375\n",
      "Neg bpr: -0.5588408708572388\n",
      "nll: 7733.75927734375\n",
      "Loss: 7454.3388671875\n",
      "Neg bpr: -0.5567354559898376\n",
      "nll: 7764.4091796875\n",
      "Loss: 7486.04150390625\n",
      "Neg bpr: -0.5521221160888672\n",
      "nll: 7777.2783203125\n",
      "Loss: 7501.21728515625\n",
      "Neg bpr: -0.5566170811653137\n",
      "nll: 7790.12548828125\n",
      "Loss: 7511.81689453125\n",
      "Neg bpr: -0.5529401898384094\n",
      "nll: 7793.31201171875\n",
      "Loss: 7516.841796875\n",
      "Neg bpr: -0.5487797260284424\n",
      "nll: 7789.017578125\n",
      "Loss: 7514.6279296875\n",
      "Neg bpr: -0.5516504049301147\n",
      "nll: 7770.595703125\n",
      "Loss: 7494.7705078125\n",
      "Neg bpr: -0.5526804327964783\n",
      "nll: 7783.5673828125\n",
      "Loss: 7507.22705078125\n",
      "Neg bpr: -0.5490615367889404\n",
      "nll: 7778.1552734375\n",
      "Loss: 7503.62451171875\n",
      "Neg bpr: -0.5474489331245422\n",
      "nll: 7770.0927734375\n",
      "Loss: 7496.3681640625\n",
      "Neg bpr: -0.5462347269058228\n",
      "nll: 7771.61279296875\n",
      "Loss: 7498.49560546875\n",
      "Neg bpr: -0.5474163889884949\n",
      "nll: 7783.18994140625\n",
      "Loss: 7509.48193359375\n",
      "Neg bpr: -0.5467149019241333\n",
      "nll: 7836.3896484375\n",
      "Loss: 7563.0322265625\n",
      "Neg bpr: -0.5449914336204529\n",
      "nll: 7872.8505859375\n",
      "Loss: 7600.35498046875\n",
      "Neg bpr: -0.5456413626670837\n",
      "nll: 7882.7919921875\n",
      "Loss: 7609.97119140625\n",
      "Neg bpr: -0.5471075177192688\n",
      "nll: 7885.708984375\n",
      "Loss: 7612.1552734375\n",
      "Neg bpr: -0.5442693829536438\n",
      "nll: 7883.8154296875\n",
      "Loss: 7611.6806640625\n",
      "Neg bpr: -0.5412637591362\n",
      "nll: 7914.74169921875\n",
      "Loss: 7644.10986328125\n",
      "Neg bpr: -0.5409723520278931\n",
      "nll: 7929.048828125\n",
      "Loss: 7658.5625\n",
      "Neg bpr: -0.5411335229873657\n",
      "nll: 7885.43408203125\n",
      "Loss: 7614.8671875\n",
      "Neg bpr: -0.5448870062828064\n",
      "nll: 7849.2333984375\n",
      "Loss: 7576.7900390625\n",
      "Neg bpr: -0.5451987981796265\n",
      "nll: 7860.19677734375\n",
      "Loss: 7587.59716796875\n",
      "Neg bpr: -0.543722927570343\n",
      "nll: 7893.39111328125\n",
      "Loss: 7621.52978515625\n",
      "Neg bpr: -0.5452656745910645\n",
      "nll: 7920.04443359375\n",
      "Loss: 7647.41162109375\n",
      "Neg bpr: -0.5453841090202332\n",
      "nll: 7916.455078125\n",
      "Loss: 7643.76318359375\n",
      "Neg bpr: -0.5482427477836609\n",
      "nll: 7913.62060546875\n",
      "Loss: 7639.4990234375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1000):\n",
    "    mix_model = model()\n",
    "    \n",
    "    y_sample_TMS = mix_model.sample((train_T, M_score_func))\n",
    "    y_sample_action_TMS = mix_model.sample((train_T, M_action))\n",
    "\n",
    "    ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "    ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "    ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "    #pred_y_TS = torch.mean(y_sample_action_TMS, dim=1)\n",
    "    #pred_y_TS.requires_grad_(True)\n",
    "\n",
    "    def get_log_probs_baked(param):\n",
    "        distribution = model.build_from_single_tensor(param)\n",
    "        log_probs_TMS = distribution.log_prob(y_sample_TMS)\n",
    "\n",
    "        return log_probs_TMS\n",
    "\n",
    "    jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n",
    "\n",
    "    score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "    score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "    # get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "    positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=4, perturbed_top_K_func=perturbed_top_K_func)\n",
    "    negative_bpr = torch.mean(-positive_bpr_T)\n",
    "    \n",
    "    nll = torch.sum(-mix_model.log_prob( torch.tensor(train_y_TS)))\n",
    "\n",
    "    print(f'Neg bpr: {negative_bpr}')\n",
    "    print(f'nll: {nll}')\n",
    "\n",
    "    loss = 500*negative_bpr + nll\n",
    "    print(f'Loss: {loss}')\n",
    "    losses.append(loss)\n",
    "    bprs.append(negative_bpr)\n",
    "    nlls.append(nll)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "    gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "    gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "    gradient_tuple = model.single_tensor_to_params(gradient_P)\n",
    "\n",
    "    for param, gradient in zip(model.parameters(), gradient_tuple):\n",
    "        param.grad = gradient\n",
    "    optimizer.step()\n",
    "        \n",
    "    #model.update_params(model.params_to_single_tensor() - step_size * gradient_P)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_poisson_rates, mixture_probs = model.single_tensor_to_params(model.params_to_single_tensor())\n",
    "poisson_rates = torch.exp(log_poisson_rates)\n",
    "mixture_probs_normalized = torch.nn.functional.softmax(mixture_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.7100e-01, 1.9218e+03, 4.9587e+01, 1.2280e+00],\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.6893, 0.1125, 0.1014],\n",
       "        [0.0973, 0.5291, 0.2687, 0.1050],\n",
       "        [0.0774, 0.6380, 0.1631, 0.1215],\n",
       "        [0.0799, 0.6271, 0.1755, 0.1176],\n",
       "        [0.1006, 0.5921, 0.1887, 0.1186],\n",
       "        [0.1680, 0.1963, 0.4311, 0.2046],\n",
       "        [0.1232, 0.2403, 0.4629, 0.1736],\n",
       "        [0.2049, 0.2543, 0.3067, 0.2342],\n",
       "        [0.2719, 0.0658, 0.1216, 0.5408],\n",
       "        [0.7167, 0.0633, 0.0852, 0.1348],\n",
       "        [0.5129, 0.0530, 0.0773, 0.3568],\n",
       "        [0.2567, 0.0683, 0.0814, 0.5936]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_probs_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([857., 821., 913.,   2.,   1.,   1., 875., 861.,   0.,   0.,   1.,   1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([nan, nan, nan, nan], grad_fn=<SliceBackward0>),\n",
       " tensor([[nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
