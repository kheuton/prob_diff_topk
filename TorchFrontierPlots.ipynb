{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:15:34.322462: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-15 15:15:34.384247: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-15 15:15:34.384311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-15 15:15:34.386171: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-15 15:15:34.399345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 15:15:41.907518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Poisson, MixtureSameFamily\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from torch_perturb.torch_pert_topk import PerturbedTopK\n",
    "from torch_models import MixtureOfPoissonsModel, MixtureOfTruncNormModel, torch_bpr_uncurried, deterministic_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "# tracts/distributions\n",
    "S=12\n",
    "# history/features\n",
    "H = 3\n",
    "# total timepoints\n",
    "T= 500\n",
    "num_components=4\n",
    "K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:16:02.887326: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-07-15 15:16:02.887369: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: s1cmp008.pax.tufts.edu\n",
      "2024-07-15 15:16:02.887374: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: s1cmp008.pax.tufts.edu\n",
      "2024-07-15 15:16:02.887415: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.129.3\n",
      "2024-07-15 15:16:02.887442: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2024-07-15 15:16:02.887448: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.129.3\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = example_datasets(H, T, seed=seed)\n",
    "train_X_THS, train_y_TS = to_numpy(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take inverse softplus\n",
    "ideal_means = torch.tensor([0+1e-8, 7, 10, 100])\n",
    "ideal_softinv_means = ideal_means + torch.log(-torch.expm1(-ideal_means))\n",
    "ideal_scales = torch.tensor([0.2, 0.2, 0.2, 0.2])\n",
    "ideal_softinv_scales = ideal_scales - 0.2 + torch.log(-torch.expm1(-ideal_scales + 0.2)) \n",
    "ideal_mix_weights = torch.log(1e-13 + torch.tensor(\n",
    "                                [[0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0,1,0,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.3,0,0.7,0],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1],\n",
    "                                 [0.9,0,0,0.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixtureOfTruncNormModel()\n",
    "step_size = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)\n",
    "\n",
    "#model.update_params(torch.cat([ideal_softinv_means, ideal_softinv_scales, ideal_mix_weights.view(-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_score_func =  200\n",
    "M_action = 200\n",
    "train_T = train_y_TS.shape[0]\n",
    "perturbed_top_K_func = PerturbedTopK(k=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "bprs = []\n",
    "nlls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "det bpr: 0.47491520643234253\n",
      "nll: 321912.4375\n",
      "Loss: 321673.71875\n",
      "Epoch: 1\n",
      "det bpr: 0.48146504163742065\n",
      "nll: 291136.21875\n",
      "Loss: 290898.21875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(2):\n",
    "    mix_model = model()\n",
    "    \n",
    "    y_sample_TMS = mix_model.sample((train_T, M_score_func))\n",
    "    y_sample_action_TMS = mix_model.sample((train_T, M_action))\n",
    "\n",
    "    ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "    ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "    ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "    #pred_y_TS = torch.mean(y_sample_action_TMS, dim=1)\n",
    "    #pred_y_TS.requires_grad_(True)\n",
    "\n",
    "    def get_log_probs_baked(param):\n",
    "        distribution = model.build_from_single_tensor(param)\n",
    "        log_probs_TMS = distribution.log_prob(y_sample_TMS)\n",
    "\n",
    "        return log_probs_TMS\n",
    "\n",
    "    jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n",
    "\n",
    "    score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "    score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "    # get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "    positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=4, perturbed_top_K_func=perturbed_top_K_func)\n",
    "    negative_bpr = torch.mean(-positive_bpr_T)\n",
    "    \n",
    "    nll = torch.sum(-mix_model.log_prob( torch.tensor(train_y_TS)))\n",
    "\n",
    "    \n",
    "    loss = 500*negative_bpr + nll\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "    gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "    gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "    gradient_tuple = model.single_tensor_to_params(gradient_P)\n",
    "\n",
    "    for param, gradient in zip(model.parameters(), gradient_tuple):\n",
    "        param.grad = gradient\n",
    "    optimizer.step()\n",
    "\n",
    "    deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n",
    "    det_bpr =torch.mean(deterministic_bpr_T)\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'det bpr: {det_bpr}')\n",
    "    print(f'nll: {nll}')\n",
    "    print(f'Loss: {loss}')\n",
    "    losses.append(loss)\n",
    "    bprs.append(det_bpr)\n",
    "    nlls.append(nll)\n",
    "        \n",
    "    #model.update_params(model.params_to_single_tensor() - step_size * gradient_P)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(289367.4688, requires_grad=True),\n",
       " tensor(292217.5312, requires_grad=True),\n",
       " tensor(294833.4688, requires_grad=True),\n",
       " tensor(296400.2188, requires_grad=True),\n",
       " tensor(298546.8438, requires_grad=True),\n",
       " tensor(300956.8750, requires_grad=True),\n",
       " tensor(303040.0312, requires_grad=True),\n",
       " tensor(305312.0312, requires_grad=True),\n",
       " tensor(306492.3750, requires_grad=True),\n",
       " tensor(306622.1875, requires_grad=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('/cluster/home/kheuto01/code/prob_diff_topk/scratch/losses.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/IPython/core/completerlib.py:149: UserWarning: using rootmodules_cache requires you to install the `pickleshare` library.\n",
      "  ip.db['rootmodules_cache'] = rootmodules_cache\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bpr_T\n",
    "threshold = 0.55\n",
    "#create flag where bpr > threshold\n",
    "flag = positive_bpr_T > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.5918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.5782, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.5648, 0.5814, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.5620, 0.0000, 0.0000, 0.0000, 0.5820, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5854,\n",
       "        0.5522, 0.0000, 0.0000, 0.5573, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5634, 0.0000, 0.0000,\n",
       "        0.0000, 0.5700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.5807, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5802,\n",
       "        0.5759, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5504, 0.5740,\n",
       "        0.0000, 0.0000, 0.5857, 0.0000, 0.0000, 0.0000, 0.0000, 0.5860, 0.5722,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5857,\n",
       "        0.5616, 0.0000, 0.0000, 0.0000, 0.0000, 0.5705, 0.0000, 0.0000, 0.0000,\n",
       "        0.5842, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.5618, 0.0000, 0.5669, 0.0000, 0.0000, 0.0000, 0.5762,\n",
       "        0.5825, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.5758, 0.0000, 0.0000, 0.5659, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.5658, 0.0000, 0.0000, 0.0000, 0.0000, 0.5734, 0.0000,\n",
       "        0.0000, 0.0000, 0.5712, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.5939, 0.0000, 0.5572, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.5663, 0.0000, 0.5552, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5675, 0.0000, 0.5515,\n",
       "        0.5525, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5583, 0.5891,\n",
       "        0.5791, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.5786, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5858, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.5827], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag*positive_bpr_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softplus(torch.tensor([10.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
