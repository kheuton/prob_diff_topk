{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 19:23:32.018800: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-12 19:23:32.066179: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-12 19:23:32.066208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-12 19:23:32.067286: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-12 19:23:32.075049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-12 19:23:36.983325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functools import partial\n",
    "\n",
    "import keras\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from models import mixture_poissons,location_specific_linear, CustomPenalizedMixtureDecisionModel, get_mixture\n",
    "from metrics import mixture_poi_loss, get_bpr_loss_func, mix_bpr, get_penalized_bpr_loss_func_mix, cross_ratio_decision, get_perturbed_bpr_func\n",
    "from experiments import training_loop, training_loop_score_function_trick, score_function_trick, overall_gradient_calculation\n",
    "from plotting_funcs import plot_losses, plot_frontier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import resource\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "num_components=4\n",
    "learning_rate = 0.05\n",
    "epochs=200\n",
    "outdir = '/cluster/home/kheuto01/testdir'\n",
    "penalty = 5000\n",
    "threshold = 0.55\n",
    "K=4\n",
    "do_only=True\n",
    "# tracts/distributions\n",
    "S=12\n",
    "# history/features\n",
    "H = 3\n",
    "# total timepoints\n",
    "T= 500\n",
    "perturbed_sigma=0.1\n",
    "num_score_func_samples=5\n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 19:23:53.258711: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-05-12 19:23:53.258747: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: s1cmp008.pax.tufts.edu\n",
      "2024-05-12 19:23:53.258754: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: s1cmp008.pax.tufts.edu\n",
      "2024-05-12 19:23:53.258839: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.129.3\n",
      "2024-05-12 19:23:53.258864: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2024-05-12 19:23:53.258869: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.129.3\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = example_datasets(H, T, seed=seed, batch_size=batch_size)\n",
    "train_X_THS, train_y_TS = to_numpy(train_dataset)\n",
    "val_X_THS, val_y_TS = to_numpy(val_dataset)\n",
    "input_shape = (H,S)\n",
    "\n",
    "bpr_K = get_perturbed_bpr_func(K, sigma=perturbed_sigma)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = get_mixture(location_specific_linear, input_shape, num_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_all(mix, num_score_func_samples, y_BS, threshold, penalty, bpr_K):\n",
    "\n",
    "    # add constant to avoid log 0\n",
    "    print('before samp')\n",
    "    sample_y_MBS = mix.sample(num_score_func_samples)#+1e-13\n",
    "    print('got samp')\n",
    "\n",
    "    sample_log_probs_MBS = mix.log_prob(sample_y_MBS)\n",
    "    print('got prob')\n",
    "    sample_decisions_MBS = cross_ratio_decision(sample_y_MBS)\n",
    "    print('got dec')\n",
    "    expected_decisions_BS = tf.reduce_mean(sample_decisions_MBS, axis=0)\n",
    "    print('mean dec')\n",
    "    bpr_B = bpr_K(y_BS, expected_decisions_BS)\n",
    "    print('got bpr')\n",
    "    observed_log_prob_BS = mix.log_prob(y_BS)\n",
    "    print ('got log prob obs')\n",
    "\n",
    "\n",
    "    loss_B = -tf.reduce_sum(observed_log_prob_BS, axis=-1)\n",
    "    print('reduced log prob')\n",
    "    violate_threshold_flag_B = tf.cast(tf.greater(threshold,\n",
    "                                                bpr_B),\n",
    "                                        tf.float32)\n",
    "    print('made a flag')\n",
    "    loss_B += penalty * violate_threshold_flag_B *(threshold - bpr_B)\n",
    "    print('added penalty')\n",
    "\n",
    "    return loss_B, sample_log_probs_MBS, sample_decisions_MBS, expected_decisions_BS, observed_log_prob_BS, bpr_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "0\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "1\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "2\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "3\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "4\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x2b0bbb8137e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "5\n",
      "got mix\n",
      "before samp\n",
      "got samp\n",
      "got prob\n",
      "got dec\n",
      "mean dec\n",
      "got bpr\n",
      "got log prob obs\n",
      "reduced log prob\n",
      "made a flag\n",
      "added penalty\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x2b0bbb812340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "got jac\n",
      "did score func trick\n",
      "got grad\n",
      "got overall gradient\n",
      "applied\n",
      "recorded\n",
      "Loss: 646.4557495117188\n",
      "NLL: -134.3720245361328\n",
      "BPR: 0.49512946605682373\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "losses['train'] = {}\n",
    "losses['val'] ={}\n",
    "losses['train']['loss']=[]\n",
    "losses['train']['nll']=[]\n",
    "losses['train']['bpr']=[]\n",
    "losses['val']['loss']=[]\n",
    "losses['val']['nll']=[]\n",
    "losses['val']['bpr']=[]\n",
    "verbose=True\n",
    "\n",
    "for epoch in range(1):\n",
    "    if verbose:\n",
    "        print(f'Epoch {epoch}')\n",
    "    else:\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}')\n",
    "\n",
    "    batch_losses = {'train': {'loss': [], 'nll': [], 'bpr': []}}\n",
    "    for step, (x_BHS, y_BS) in enumerate(train_dataset):\n",
    "        print(step)\n",
    "        with tf.GradientTape() as jacobian_tape, tf.GradientTape() as loss_tape:\n",
    "            mixture = model(x_BHS)\n",
    "            print('got mix')\n",
    "            loss_B, sample_log_probs_MBS, sample_decisions_MBS, expected_decisions_BS, observed_log_prob_BS, bpr_B = do_it_all(mixture, num_score_func_samples, y_BS, threshold, penalty, bpr_K)\n",
    "\n",
    "        jacobian_pMBS = jacobian_tape.jacobian(sample_log_probs_MBS, model.trainable_weights)\n",
    "        print('got jac')\n",
    "        param_gradient_pBS = [score_function_trick(j, sample_decisions_MBS) for j in jacobian_pMBS]\n",
    "        print('did score func trick')\n",
    "        loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)\n",
    "        print('got grad')\n",
    "        overall_gradient = [overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]\n",
    "        print('got overall gradient')\n",
    "\n",
    "        optimizer.apply_gradients(zip(overall_gradient, model.trainable_weights))\n",
    "        print('applied')\n",
    "        batch_losses['train']['loss'].append(tf.reduce_mean(loss_B))\n",
    "        batch_losses['train']['nll'].append(tf.reduce_mean(tf.reduce_sum(observed_log_prob_BS, axis=-1)))\n",
    "        batch_losses['train']['bpr'].append(tf.reduce_mean(bpr_B))\n",
    "        print('recorded')\n",
    "\n",
    "    losses['train']['loss'].append(tf.reduce_mean(batch_losses['train']['loss']))\n",
    "    losses['train']['nll'].append(tf.reduce_mean(batch_losses['train']['nll']))\n",
    "    losses['train']['bpr'].append(tf.reduce_mean(batch_losses['train']['bpr']))\n",
    "\n",
    "    if verbose:\n",
    "        # print all metrics\n",
    "        print(f'Loss: {losses[\"train\"][\"loss\"][-1]}')\n",
    "        print(f'NLL: {losses[\"train\"][\"nll\"][-1]}')\n",
    "        print(f'BPR: {losses[\"train\"][\"bpr\"][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Reparameterization Type: NOT_REPARAMETERIZED>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture.reparameterization_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-2.1269157, shape=(), dtype=float32)\n",
      "[None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# test if I can take gradient of samples from mixure with a tape\n",
    "with tf.GradientTape() as tape:\n",
    "    sample = mixture.sample(10)\n",
    "    log_prob = mixture.log_prob(sample)\n",
    "    print(tf.reduce_mean(log_prob))\n",
    "print(tape.gradient(log_prob, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_poi = tfp.distributions.Poisson(rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Reparameterization Type: NOT_REPARAMETERIZED>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_poi.reparameterization_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k2_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
