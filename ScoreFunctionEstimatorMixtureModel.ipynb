{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import scipy\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "means = [5, 15, 25, 35]\n",
    "num_locations_S = 4\n",
    "num_components_C = num_locations_S\n",
    "\n",
    "# simulate data for each location\n",
    "data_distributions = [scipy.stats.norm(loc=mean, scale=scale) for mean in means]\n",
    "\n",
    "# Use t-3 data points as features\n",
    "num_features_per_location_H = 3\n",
    "num_datapoints_T = 100\n",
    "# need to draw T+H so every point has enough history\n",
    "data_samples_to_draw = num_features_per_location_H+num_datapoints_T\n",
    "# eventually we'll flatten data\n",
    "num_features_total_F = num_features_per_location_H*num_locations_S\n",
    "input_shape = (num_datapoints_T, num_features_total_F)\n",
    "\n",
    "seed=360\n",
    "\n",
    "data_HT_S = np.zeros((data_samples_to_draw, num_locations_S))\n",
    "for s, dist in enumerate(data_distributions):\n",
    "    random_state = np.random.RandomState(seed+s*1000)\n",
    "    data_HT_S[:, s] = dist.rvs(size=data_samples_to_draw, random_state=random_state)\n",
    "\n",
    "# Reshape so that previous H samples are features for time t\n",
    "X_THS = np.array([data_HT_S[t:num_features_per_location_H+t,:] for t in range(num_datapoints_T)], dtype=np.float32)\n",
    "y_TS = np.array([data_HT_S[num_features_per_location_H+t, :] for t in range(num_datapoints_T)], dtype=np.float32)\n",
    "\n",
    "# reshape inputs so that data is 2D: sample-by-features\n",
    "X_TF = np.reshape(X_THS, (num_datapoints_T, -1))\n",
    "assert(X_TF.shape == input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureWeightLayer(keras.layers.Layer):\n",
    "    \"\"\"Dumb layer that just returns mixture weights\n",
    "    Constrained to unit norm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_locations, num_components=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = self.add_weight(shape=(num_locations, num_components ),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        \n",
    "        self.softmax = keras.layers.Softmax(axis=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.softmax(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m mixture_weight_layer \u001b[38;5;241m=\u001b[39m MixtureWeightLayer(num_locations_S, num_components_C)\n\u001b[1;32m      5\u001b[0m mixture_weights \u001b[38;5;241m=\u001b[39m mixture_weight_layer([\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(mixture_weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m,num_locations_S, num_components_C))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(np\u001b[38;5;241m.\u001b[39misclose(tf\u001b[38;5;241m.\u001b[39mreduce_sum(mixture_weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy(), np\u001b[38;5;241m.\u001b[39mones(num_locations_S))\u001b[38;5;241m.\u001b[39mall())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Add a component dimension to outputs of each component model\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build layers\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "component_layers = [keras.layers.Dense(1, activation='softplus') for _ in range(num_components_C)]\n",
    "mixture_weight_layer = MixtureWeightLayer(num_locations_S, num_components_C)\n",
    "mixture_weights = mixture_weight_layer([0])\n",
    "assert(mixture_weights.shape == (1,num_locations_S, num_components_C))\n",
    "assert(np.isclose(tf.reduce_sum(mixture_weights, axis=1).numpy(), np.ones(num_locations_S)).all())\n",
    "\n",
    "# Add a component dimension to outputs of each component model\n",
    "reshape_layer = keras.layers.Reshape(name='mix_reshape', target_shape=(-1,1))\n",
    "# Concatenate components along new dimension\n",
    "concat_layer = keras.layers.Concatenate(name='mix_concat',axis=-1)\n",
    "\n",
    "# get tfp mixture model\n",
    "mixture_distribution_layer = tfp.layers.DistributionLambda(lambda params: \n",
    "        tfp.distributions.MixtureSameFamily(mixture_distribution=\n",
    "                                                tfp.distributions.Categorical(probs=params[0]),\n",
    "                                            components_distribution=\n",
    "                                                tfp.distributions.Normal(loc=params[1],\n",
    "                                                                        scale=scale,\n",
    "                                                                        validate_args=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"distribution_lambda_3\" (type DistributionLambda).\n\nIncompatible shapes for broadcasting. Two shapes are compatible if for each dimension pair they are either equal or one of them is 1. Received: (None, 100) and (1, 4).\n\nCall arguments received by layer \"distribution_lambda_3\" (type DistributionLambda):\n  • inputs=['tf.Tensor(shape=(1, 4, 4), dtype=float32)', 'tf.Tensor(shape=(None, 100, 4), dtype=float32)']\n  • args=<class 'inspect._empty'>\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m component_predictions \u001b[38;5;241m=\u001b[39m [component(inputs) \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m component_layers]\n\u001b[1;32m      3\u001b[0m combined_components \u001b[38;5;241m=\u001b[39m concat_layer([reshape_layer(member) \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m component_predictions])\n\u001b[0;32m----> 4\u001b[0m output_distribution \u001b[38;5;241m=\u001b[39m \u001b[43mmixture_distribution_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmixture_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_components\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs,outputs\u001b[38;5;241m=\u001b[39moutputs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/layers/distribution_layer.py:220\u001b[0m, in \u001b[0;36mDistributionLambda.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    219\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enter_dunder_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m   distribution, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDistributionLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enter_dunder_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    223\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/layers/distribution_layer.py:226\u001b[0m, in \u001b[0;36mDistributionLambda.call\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 226\u001b[0m   distribution, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDistributionLambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m   \u001b[38;5;66;03m# We always save the most recently built distribution variables for tracking\u001b[39;00m\n\u001b[1;32m    229\u001b[0m   \u001b[38;5;66;03m# purposes.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_most_recently_built_distribution_vars \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mvariables\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/layers/distribution_layer.py:180\u001b[0m, in \u001b[0;36mDistributionLambda.__init__.<locals>._fn\u001b[0;34m(*fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m distribution \u001b[38;5;241m=\u001b[39m dtc\u001b[38;5;241m.\u001b[39m_TensorCoercible(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     distribution\u001b[38;5;241m=\u001b[39md,\n\u001b[1;32m    173\u001b[0m     convert_to_tensor_fn\u001b[38;5;241m=\u001b[39mmaybe_composite_convert_to_tensor_fn)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Calling `distrbution._value()` is equivalent to:\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.framework import ops\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# value = ops.convert_to_tensor_or_composite(distribution)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# We'd prefer to call ops.convert_to_tensor_or_composite but do not,\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# favoring our own non-public API over TF's.\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# TODO(b/126056144): Remove silent handle once we identify how/why Keras\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# is losing the distribution handle for activity_regularizer.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m value\u001b[38;5;241m.\u001b[39m_tfp_distribution \u001b[38;5;241m=\u001b[39m distribution  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py:215\u001b[0m, in \u001b[0;36m_TensorCoercible._value\u001b[0;34m(self, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to convert object of type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to Tensor. Contents: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    208\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCall `distribution.set_tensor_conversion(lambda self: ...)` to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m results in `tf.convert_to_tensor(x)` being identical to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    212\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`x.mean()`.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 215\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_tensor_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_distribution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor_fn)\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_tensor_fn)\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_value) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_value,\n\u001b[1;32m    220\u001b[0m                      composite_tensor\u001b[38;5;241m.\u001b[39mCompositeTensor)):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_value \u001b[38;5;241m=\u001b[39m nest_util\u001b[38;5;241m.\u001b[39mconvert_to_nested_tensor(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_value,\n\u001b[1;32m    223\u001b[0m         name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcrete_value\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    224\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    225\u001b[0m         dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_distribution\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:284\u001b[0m, in \u001b[0;36m_MixtureSameFamily._sample_n\u001b[0;34m(self, n, seed)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample_n\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, seed):\n\u001b[1;32m    281\u001b[0m   components_seed, mix_seed \u001b[38;5;241m=\u001b[39m samplers\u001b[38;5;241m.\u001b[39msplit_seed(seed,\n\u001b[1;32m    282\u001b[0m                                                   salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMixtureSameFamily\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    283\u001b[0m   mixture_distribution, components_distribution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 284\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_distributions_with_broadcast_batch_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    285\u001b[0m   x \u001b[38;5;241m=\u001b[39m components_distribution\u001b[38;5;241m.\u001b[39msample(  \u001b[38;5;66;03m# [n, B, k, E]\u001b[39;00m\n\u001b[1;32m    286\u001b[0m       n, seed\u001b[38;5;241m=\u001b[39mcomponents_seed)\n\u001b[1;32m    288\u001b[0m   event_ndims \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mrank_from_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_shape_tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_shape)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:255\u001b[0m, in \u001b[0;36m_MixtureSameFamily._get_distributions_with_broadcast_batch_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_distributions_with_broadcast_batch_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    254\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcasts the mixture and component dists to have full batch shape.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m   overall_batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_shape\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (tensorshape_util\u001b[38;5;241m.\u001b[39mis_fully_defined(overall_batch_shape) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    257\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_distribution\u001b[38;5;241m.\u001b[39mbatch_shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m overall_batch_shape \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    258\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixture_distribution\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m==\u001b[39m overall_batch_shape):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# No need to broadcast.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixture_distribution, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_distribution\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1079\u001b[0m, in \u001b[0;36mDistribution.batch_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Shape of a single sample from a single event index as a `TensorShape`.\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03mMay be partially defined or unknown.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m  batch_shape: `TensorShape`, possibly unknown.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__cached_batch_shape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;66;03m# Cache the batch shape so that it's only inferred once. This is safe\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m   \u001b[38;5;66;03m# because runtime changes to parameter shapes can only affect\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m   \u001b[38;5;66;03m# `batch_shape_tensor`, never `batch_shape`.\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m   batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m   \u001b[38;5;66;03m# See comment in `batch_shape_tensor()` on structured batch shapes. If\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m   \u001b[38;5;66;03m# `_batch_shape()` is a `tf.TensorShape` instance or a flat list/tuple\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;66;03m# that does not contain `tf.TensorShape`s, we infer that it is not\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m   \u001b[38;5;66;03m# structured.\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(batch_shape, tf\u001b[38;5;241m.\u001b[39mTensorShape)\n\u001b[1;32m   1086\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, tf\u001b[38;5;241m.\u001b[39mTensorShape)\n\u001b[1;32m   1087\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m path, s \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten_with_tuple_paths(batch_shape))):\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1057\u001b[0m, in \u001b[0;36mDistribution._batch_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Infers static batch shape from parameters.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03mThe overall batch shape is inferred by broadcasting the batch shapes of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    be partially defined or unknown.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1057\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m batch_shape_lib\u001b[38;5;241m.\u001b[39minferred_batch_shape(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m   \u001b[38;5;66;03m# If a distribution doesn't implement `_parameter_properties` or its own\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m   \u001b[38;5;66;03m# `_batch_shape` method, we can only return the most general shape.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py:73\u001b[0m, in \u001b[0;36minferred_batch_shape\u001b[0;34m(batch_object, bijector_x_event_ndims)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Infers an object's batch shape from its  parameters.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mEach parameter contributes a batch shape of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m      be partially defined or unknown.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m batch_shapes \u001b[38;5;241m=\u001b[39m map_fn_over_parameters_with_event_ndims(\n\u001b[1;32m     69\u001b[0m     batch_object,\n\u001b[1;32m     70\u001b[0m     get_batch_shape_part,\n\u001b[1;32m     71\u001b[0m     require_static\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m     bijector_x_event_ndims\u001b[38;5;241m=\u001b[39mbijector_x_event_ndims)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_static_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_shapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"distribution_lambda_3\" (type DistributionLambda).\n\nIncompatible shapes for broadcasting. Two shapes are compatible if for each dimension pair they are either equal or one of them is 1. Received: (None, 100) and (1, 4).\n\nCall arguments received by layer \"distribution_lambda_3\" (type DistributionLambda):\n  • inputs=['tf.Tensor(shape=(1, 4, 4), dtype=float32)', 'tf.Tensor(shape=(None, 100, 4), dtype=float32)']\n  • args=<class 'inspect._empty'>\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "component_predictions = [component(inputs) for component in component_layers]\n",
    "combined_components = concat_layer([reshape_layer(member) for member in component_predictions])\n",
    "output_distribution = mixture_distribution_layer([mixture_weights, combined_components])\n",
    "model = keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 4) dtype=float32 (created by layer 'mix_concat')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0100352, 0.9951776, 1.0068451, 0.9879423], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(mixture_weights, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k2_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
