{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "\n",
    "from distributions import ZeroInflatedDist, QuantizedNormal\n",
    "from torch_models import MixtureOfTruncNormModel, SpatialWaves\n",
    "from torch_training import train_epoch\n",
    "from torch_perturb.torch_pert_topk import PerturbedBrokenTopK\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from metrics import top_k_onehot_indicator\n",
    "import time\n",
    "from torch_training import train_epoch_largesynth\n",
    "from torch_models import torch_bpr_uncurried, deterministic_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "num_components=2\n",
    "init_idx=10\n",
    "perturbed_noise=0.05\n",
    "step_size=0.1\n",
    "threshold = 1\n",
    "bpr_weight=30\n",
    "nll_weight=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total timepoints\n",
    "T= 500\n",
    "S=7\n",
    "K=5\n",
    "\n",
    "dist_S = [QuantizedNormal(10, 0.3),\n",
    "        QuantizedNormal(20, 0.3),\n",
    "        QuantizedNormal(30, 0.3),\n",
    "        QuantizedNormal(40, 0.3),\n",
    "        QuantizedNormal(50, 0.3),\n",
    "        QuantizedNormal(60, 0.3),\n",
    "        QuantizedNormal(100, 0.3)]\n",
    "train_y_TS = np.zeros((T, S))\n",
    "for s, dist in enumerate(dist_S):\n",
    "    random_state = np.random.RandomState(10000 * seed + s*123456)\n",
    "    train_y_TS[:, s] = dist.rvs(size=T, random_state=random_state)\n",
    "\n",
    "model = MixtureOfTruncNormModel(num_components=num_components, S=S, low=0, high=150)\n",
    "if init_idx is not None:\n",
    "    # Reproducibly, randomly generate some numbers using a numpy rng\n",
    "    init_rng = np.random.RandomState(1989)\n",
    "    # generate 20 sets of 2 floats between 0.5 and 60\n",
    "    all_means = init_rng.uniform(8, 102, (20, num_components))\n",
    "    # generate 20 sets of 2 floats between 0.25 and 6\n",
    "    all_scales = init_rng.uniform(0.25, 8, (20, num_components))\n",
    "    # generate 20 lists length S containing lists length 2 which sum to 1\n",
    "    all_mix_weights = init_rng.dirichlet([0.5]*num_components, (20,S))\n",
    "\n",
    "    softinv_means = torch.tensor(all_means[init_idx]) + torch.log(-torch.expm1(torch.tensor(-all_means[init_idx])))\n",
    "    softinv_scales = torch.tensor(all_scales[init_idx]) - 0.2 + torch.log(-torch.expm1(torch.tensor(-all_scales[init_idx] + 0.2)))\n",
    "    mix_weights = torch.log(1e-13 + torch.tensor(all_mix_weights[init_idx]))\n",
    "    model.update_params(torch.cat([softinv_means, softinv_scales, mix_weights.view(-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "det bpr: 0.8489137885029586\n",
      "Pert bpr: 0.8022005155574058\n",
      "nll: 14.704272689897223\n",
      "Loss: -24.066015466722174\n",
      "EPOCH: 1\n",
      "det bpr: 0.8618141449301174\n",
      "Pert bpr: 0.803852234851407\n",
      "nll: 14.993409339414972\n",
      "Loss: -24.11556704554221\n",
      "EPOCH: 2\n",
      "det bpr: 0.8692492456640573\n",
      "Pert bpr: 0.8062644345674668\n",
      "nll: 14.922312380688332\n",
      "Loss: -24.187933037024003\n",
      "EPOCH: 3\n",
      "det bpr: 0.8824175999394804\n",
      "Pert bpr: 0.8079786282051634\n",
      "nll: 14.765345924330438\n",
      "Loss: -24.239358846154904\n",
      "EPOCH: 4\n",
      "det bpr: 0.8874757805979973\n",
      "Pert bpr: 0.8107082456606465\n",
      "nll: 14.556107902014535\n",
      "Loss: -24.321247369819396\n",
      "EPOCH: 5\n",
      "det bpr: 0.8890512082556646\n",
      "Pert bpr: 0.8127854277897777\n",
      "nll: 14.295174962233537\n",
      "Loss: -24.383562833693333\n",
      "EPOCH: 6\n",
      "det bpr: 0.891919630320086\n",
      "Pert bpr: 0.8152300516925062\n",
      "nll: 14.06423405610141\n",
      "Loss: -24.456901550775186\n",
      "EPOCH: 7\n",
      "det bpr: 0.8948329354103943\n",
      "Pert bpr: 0.8173704148594939\n",
      "nll: 13.886748993050082\n",
      "Loss: -24.521112445784816\n",
      "EPOCH: 8\n",
      "det bpr: 0.9009203799807242\n",
      "Pert bpr: 0.8198912759081133\n",
      "nll: 13.735346206440024\n",
      "Loss: -24.5967382772434\n",
      "EPOCH: 9\n",
      "det bpr: 0.9138399876226114\n",
      "Pert bpr: 0.8221429602786441\n",
      "nll: 13.640481640483499\n",
      "Loss: -24.664288808359323\n",
      "EPOCH: 10\n",
      "det bpr: 0.9272751015482131\n",
      "Pert bpr: 0.8243805474992091\n",
      "nll: 13.507600663792704\n",
      "Loss: -24.731416424976274\n",
      "EPOCH: 11\n",
      "det bpr: 0.9506027644549887\n",
      "Pert bpr: 0.8267326267731081\n",
      "nll: 13.404917916062143\n",
      "Loss: -24.801978803193244\n",
      "EPOCH: 12\n",
      "det bpr: 0.9615136235222108\n",
      "Pert bpr: 0.8286721192816537\n",
      "nll: 13.36223962196953\n",
      "Loss: -24.860163578449612\n",
      "EPOCH: 13\n",
      "det bpr: 0.9717155551307735\n",
      "Pert bpr: 0.8307163835655651\n",
      "nll: 13.26103120831643\n",
      "Loss: -24.92149150696695\n",
      "EPOCH: 14\n",
      "det bpr: 0.9718973804222791\n",
      "Pert bpr: 0.832736495215268\n",
      "nll: 13.120952464995892\n",
      "Loss: -24.98209485645804\n",
      "EPOCH: 15\n",
      "det bpr: 0.9739635697069371\n",
      "Pert bpr: 0.8349301176796134\n",
      "nll: 12.987131299679858\n",
      "Loss: -25.047903530388403\n",
      "EPOCH: 16\n",
      "det bpr: 0.9705807638852451\n",
      "Pert bpr: 0.8370056478954779\n",
      "nll: 12.884310324018346\n",
      "Loss: -25.11016943686434\n",
      "EPOCH: 17\n",
      "det bpr: 0.9663874846250338\n",
      "Pert bpr: 0.8382088577683969\n",
      "nll: 12.820924097236611\n",
      "Loss: -25.14626573305191\n",
      "EPOCH: 18\n",
      "det bpr: 0.9665872552716078\n",
      "Pert bpr: 0.8406650075543785\n",
      "nll: 12.726663966852682\n",
      "Loss: -25.219950226631354\n",
      "EPOCH: 19\n",
      "det bpr: 0.9661256839695536\n",
      "Pert bpr: 0.8421096939147403\n",
      "nll: 12.614971553809072\n",
      "Loss: -25.26329081744221\n",
      "EPOCH: 20\n",
      "det bpr: 0.9621369587318603\n",
      "Pert bpr: 0.8436843125616174\n",
      "nll: 12.554826137577049\n",
      "Loss: -25.31052937684852\n",
      "EPOCH: 21\n",
      "det bpr: 0.9619356810907211\n",
      "Pert bpr: 0.8450145704287124\n",
      "nll: 12.48597972095666\n",
      "Loss: -25.35043711286137\n",
      "EPOCH: 22\n",
      "det bpr: 0.9576661391414409\n",
      "Pert bpr: 0.8467150806696111\n",
      "nll: 12.424137385335078\n",
      "Loss: -25.401452420088333\n",
      "EPOCH: 23\n",
      "det bpr: 0.9577722789646022\n",
      "Pert bpr: 0.8483091031437389\n",
      "nll: 12.348756100771627\n",
      "Loss: -25.449273094312165\n",
      "EPOCH: 24\n",
      "det bpr: 0.9570237433660531\n",
      "Pert bpr: 0.8493711673563614\n",
      "nll: 12.29004830128959\n",
      "Loss: -25.481135020690843\n",
      "EPOCH: 25\n",
      "det bpr: 0.9538314655327929\n",
      "Pert bpr: 0.8509398621988178\n",
      "nll: 12.218094061216547\n",
      "Loss: -25.528195865964534\n",
      "EPOCH: 26\n",
      "det bpr: 0.9537742167896652\n",
      "Pert bpr: 0.8520988497623089\n",
      "nll: 12.115583768208696\n",
      "Loss: -25.562965492869267\n",
      "EPOCH: 27\n",
      "det bpr: 0.9518859336863602\n",
      "Pert bpr: 0.8535978968372915\n",
      "nll: 12.016259954529474\n",
      "Loss: -25.607936905118745\n",
      "EPOCH: 28\n",
      "det bpr: 0.9520163612776269\n",
      "Pert bpr: 0.8540315376907531\n",
      "nll: 11.937183970793436\n",
      "Loss: -25.620946130722594\n",
      "EPOCH: 29\n",
      "det bpr: 0.9457117620467829\n",
      "Pert bpr: 0.8550709767114669\n",
      "nll: 11.853686061492539\n",
      "Loss: -25.652129301344008\n",
      "EPOCH: 30\n",
      "det bpr: 0.9498521776958563\n",
      "Pert bpr: 0.8563307209138284\n",
      "nll: 11.794721015213483\n",
      "Loss: -25.689921627414854\n",
      "EPOCH: 31\n",
      "det bpr: 0.9495940822342953\n",
      "Pert bpr: 0.85728922743733\n",
      "nll: 11.75348736036702\n",
      "Loss: -25.7186768231199\n",
      "EPOCH: 32\n",
      "det bpr: 0.9484052536072477\n",
      "Pert bpr: 0.8586401199718837\n",
      "nll: 11.707695677034105\n",
      "Loss: -25.75920359915651\n",
      "EPOCH: 33\n",
      "det bpr: 0.9484585553381034\n",
      "Pert bpr: 0.859364852060022\n",
      "nll: 11.647267594652924\n",
      "Loss: -25.78094556180066\n",
      "EPOCH: 34\n",
      "det bpr: 0.9484455288493795\n",
      "Pert bpr: 0.8605710608086309\n",
      "nll: 11.598538437055423\n",
      "Loss: -25.817131824258926\n",
      "EPOCH: 35\n",
      "det bpr: 0.9506272703402929\n",
      "Pert bpr: 0.8612251682322838\n",
      "nll: 11.549852376231108\n",
      "Loss: -25.836755046968513\n",
      "EPOCH: 36\n",
      "det bpr: 0.9539504928531121\n",
      "Pert bpr: 0.8624026770913172\n",
      "nll: 11.492756837964317\n",
      "Loss: -25.872080312739516\n",
      "EPOCH: 37\n",
      "det bpr: 0.9514297812595921\n",
      "Pert bpr: 0.8634197429130923\n",
      "nll: 11.448586281473222\n",
      "Loss: -25.90259228739277\n",
      "EPOCH: 38\n",
      "det bpr: 0.9474621358351422\n",
      "Pert bpr: 0.8641919325513239\n",
      "nll: 11.403396913049372\n",
      "Loss: -25.925757976539717\n",
      "EPOCH: 39\n",
      "det bpr: 0.9529288059021072\n",
      "Pert bpr: 0.8652167268200608\n",
      "nll: 11.33762429699721\n",
      "Loss: -25.956501804601825\n",
      "EPOCH: 40\n",
      "det bpr: 0.9521595407725904\n",
      "Pert bpr: 0.8658804548818955\n",
      "nll: 11.265667977698595\n",
      "Loss: -25.976413646456862\n",
      "EPOCH: 41\n",
      "det bpr: 0.9539781819997764\n",
      "Pert bpr: 0.8664026747900541\n",
      "nll: 11.203026213352535\n",
      "Loss: -25.992080243701622\n",
      "EPOCH: 42\n",
      "det bpr: 0.9551774788877697\n",
      "Pert bpr: 0.8676777729323207\n",
      "nll: 11.139754624382956\n",
      "Loss: -26.03033318796962\n",
      "EPOCH: 43\n",
      "det bpr: 0.9552535022607326\n",
      "Pert bpr: 0.8685232997270041\n",
      "nll: 11.107211235225195\n",
      "Loss: -26.055698991810125\n",
      "EPOCH: 44\n",
      "det bpr: 0.9561169661014823\n",
      "Pert bpr: 0.8689823179579739\n",
      "nll: 11.049109639849588\n",
      "Loss: -26.069469538739217\n",
      "EPOCH: 45\n",
      "det bpr: 0.9578851147886576\n",
      "Pert bpr: 0.8697602495404115\n",
      "nll: 10.99405640028225\n",
      "Loss: -26.092807486212347\n",
      "EPOCH: 46\n",
      "det bpr: 0.9614770575708507\n",
      "Pert bpr: 0.8706303515218751\n",
      "nll: 10.932366549225478\n",
      "Loss: -26.118910545656252\n",
      "EPOCH: 47\n",
      "det bpr: 0.9631181261484758\n",
      "Pert bpr: 0.8712768131658455\n",
      "nll: 10.875957379321875\n",
      "Loss: -26.138304394975364\n",
      "EPOCH: 48\n",
      "det bpr: 0.962289996744296\n",
      "Pert bpr: 0.8723010352801205\n",
      "nll: 10.815869715535381\n",
      "Loss: -26.169031058403615\n",
      "EPOCH: 49\n",
      "det bpr: 0.9637453786893867\n",
      "Pert bpr: 0.8734657902110562\n",
      "nll: 10.757847526780937\n",
      "Loss: -26.203973706331684\n",
      "EPOCH: 50\n",
      "det bpr: 0.9658724878968576\n",
      "Pert bpr: 0.873572505680391\n",
      "nll: 10.708765309601835\n",
      "Loss: -26.20717517041173\n",
      "EPOCH: 51\n",
      "det bpr: 0.965066475841573\n",
      "Pert bpr: 0.8744527877835567\n",
      "nll: 10.658574952586537\n",
      "Loss: -26.2335836335067\n",
      "EPOCH: 52\n",
      "det bpr: 0.9662379521851042\n",
      "Pert bpr: 0.8761187395919074\n",
      "nll: 10.613149517308198\n",
      "Loss: -26.283562187757223\n",
      "EPOCH: 53\n",
      "det bpr: 0.9652655852830428\n",
      "Pert bpr: 0.8764684192359651\n",
      "nll: 10.560096704996122\n",
      "Loss: -26.29405257707895\n",
      "EPOCH: 54\n",
      "det bpr: 0.9664947842575857\n",
      "Pert bpr: 0.8770309661872348\n",
      "nll: 10.508374047717462\n",
      "Loss: -26.310928985617043\n",
      "EPOCH: 55\n",
      "det bpr: 0.9652388463632651\n",
      "Pert bpr: 0.8780959404012504\n",
      "nll: 10.455227483067516\n",
      "Loss: -26.342878212037512\n",
      "EPOCH: 56\n",
      "det bpr: 0.9656113924273019\n",
      "Pert bpr: 0.8787924295843175\n",
      "nll: 10.404347075417832\n",
      "Loss: -26.363772887529525\n",
      "EPOCH: 57\n",
      "det bpr: 0.9691991497591582\n",
      "Pert bpr: 0.8794191430471602\n",
      "nll: 10.352286401844959\n",
      "Loss: -26.382574291414805\n",
      "EPOCH: 58\n",
      "det bpr: 0.9670604657341869\n",
      "Pert bpr: 0.8804048252715325\n",
      "nll: 10.301281368072747\n",
      "Loss: -26.412144758145974\n",
      "EPOCH: 59\n",
      "det bpr: 0.9662336434370596\n",
      "Pert bpr: 0.8810978798223886\n",
      "nll: 10.257164897542035\n",
      "Loss: -26.43293639467166\n",
      "EPOCH: 60\n",
      "det bpr: 0.9662775461282269\n",
      "Pert bpr: 0.8819839750514916\n",
      "nll: 10.22102748295437\n",
      "Loss: -26.459519251544748\n",
      "EPOCH: 61\n",
      "det bpr: 0.9644452128270339\n",
      "Pert bpr: 0.8829237282038443\n",
      "nll: 10.184903654241062\n",
      "Loss: -26.48771184611533\n",
      "EPOCH: 62\n",
      "det bpr: 0.9655457583941247\n",
      "Pert bpr: 0.8833346604784865\n",
      "nll: 10.152573244385394\n",
      "Loss: -26.500039814354597\n",
      "EPOCH: 63\n",
      "det bpr: 0.9681081803596083\n",
      "Pert bpr: 0.8846404261117303\n",
      "nll: 10.117724917526221\n",
      "Loss: -26.53921278335191\n",
      "EPOCH: 64\n",
      "det bpr: 0.9650769699973439\n",
      "Pert bpr: 0.8849931105944441\n",
      "nll: 10.082893829283412\n",
      "Loss: -26.549793317833323\n",
      "EPOCH: 65\n",
      "det bpr: 0.9659001954020594\n",
      "Pert bpr: 0.8855083720913952\n",
      "nll: 10.051807050069625\n",
      "Loss: -26.565251162741855\n",
      "EPOCH: 66\n",
      "det bpr: 0.9652953407511415\n",
      "Pert bpr: 0.8864782708609708\n",
      "nll: 10.016491030470668\n",
      "Loss: -26.59434812582912\n",
      "EPOCH: 67\n",
      "det bpr: 0.9666688068656456\n",
      "Pert bpr: 0.887231599881466\n",
      "nll: 9.978563286600428\n",
      "Loss: -26.616947996443983\n",
      "EPOCH: 68\n",
      "det bpr: 0.9658804182751396\n",
      "Pert bpr: 0.8880835951340396\n",
      "nll: 9.949183788138944\n",
      "Loss: -26.642507854021186\n",
      "EPOCH: 69\n",
      "det bpr: 0.9663731037036628\n",
      "Pert bpr: 0.8886135016092348\n",
      "nll: 9.923404492695061\n",
      "Loss: -26.658405048277043\n",
      "EPOCH: 70\n",
      "det bpr: 0.9643150522795569\n",
      "Pert bpr: 0.8894394344198749\n",
      "nll: 9.896696922512417\n",
      "Loss: -26.683183032596247\n",
      "EPOCH: 71\n",
      "det bpr: 0.9665912448129875\n",
      "Pert bpr: 0.8900402166004685\n",
      "nll: 9.865442589952433\n",
      "Loss: -26.701206498014056\n",
      "EPOCH: 72\n",
      "det bpr: 0.9648372073650945\n",
      "Pert bpr: 0.8906352657682696\n",
      "nll: 9.831320735827708\n",
      "Loss: -26.719057973048088\n",
      "EPOCH: 73\n",
      "det bpr: 0.9654365770570998\n",
      "Pert bpr: 0.8910869877072805\n",
      "nll: 9.80286057312746\n",
      "Loss: -26.732609631218413\n",
      "EPOCH: 74\n",
      "det bpr: 0.9654963888774997\n",
      "Pert bpr: 0.8925511829474104\n",
      "nll: 9.770241960225535\n",
      "Loss: -26.77653548842231\n",
      "EPOCH: 75\n",
      "det bpr: 0.965257326478807\n",
      "Pert bpr: 0.8927967979859015\n",
      "nll: 9.73765788647324\n",
      "Loss: -26.783903939577044\n",
      "EPOCH: 76\n",
      "det bpr: 0.9664261263915257\n",
      "Pert bpr: 0.8940427133498147\n",
      "nll: 9.705211438890467\n",
      "Loss: -26.82128140049444\n",
      "EPOCH: 77\n",
      "det bpr: 0.9680544307972163\n",
      "Pert bpr: 0.8944531154486025\n",
      "nll: 9.6785116910252\n",
      "Loss: -26.833593463458076\n",
      "EPOCH: 78\n",
      "det bpr: 0.966455569638421\n",
      "Pert bpr: 0.8951725118007704\n",
      "nll: 9.649466951354166\n",
      "Loss: -26.85517535402311\n",
      "EPOCH: 79\n",
      "det bpr: 0.9655268504523481\n",
      "Pert bpr: 0.896155730211292\n",
      "nll: 9.625181046759456\n",
      "Loss: -26.88467190633876\n",
      "EPOCH: 80\n",
      "det bpr: 0.9647268520643211\n",
      "Pert bpr: 0.8969300180963301\n",
      "nll: 9.602677997509764\n",
      "Loss: -26.9079005428899\n",
      "EPOCH: 81\n",
      "det bpr: 0.9662093273456224\n",
      "Pert bpr: 0.897498207624341\n",
      "nll: 9.581515592394663\n",
      "Loss: -26.924946228730228\n",
      "EPOCH: 82\n",
      "det bpr: 0.9650623293392859\n",
      "Pert bpr: 0.8981576899628343\n",
      "nll: 9.562847684458864\n",
      "Loss: -26.944730698885028\n",
      "EPOCH: 83\n",
      "det bpr: 0.9672694387289362\n",
      "Pert bpr: 0.8983657710002435\n",
      "nll: 9.550038463802368\n",
      "Loss: -26.950973130007306\n",
      "EPOCH: 84\n",
      "det bpr: 0.9674550549813022\n",
      "Pert bpr: 0.8995719736179819\n",
      "nll: 9.53715940348132\n",
      "Loss: -26.987159208539456\n",
      "EPOCH: 85\n",
      "det bpr: 0.9650844162759449\n",
      "Pert bpr: 0.8999127086117632\n",
      "nll: 9.522461691596092\n",
      "Loss: -26.997381258352895\n",
      "EPOCH: 86\n",
      "det bpr: 0.9641638853177926\n",
      "Pert bpr: 0.9009356882500104\n",
      "nll: 9.508434653191353\n",
      "Loss: -27.02807064750031\n",
      "EPOCH: 87\n",
      "det bpr: 0.965855036533311\n",
      "Pert bpr: 0.900916255620597\n",
      "nll: 9.49440867260015\n",
      "Loss: -27.02748766861791\n",
      "EPOCH: 88\n",
      "det bpr: 0.9663828272723444\n",
      "Pert bpr: 0.9016333498503766\n",
      "nll: 9.478506511269586\n",
      "Loss: -27.049000495511297\n",
      "EPOCH: 89\n",
      "det bpr: 0.9666109455439664\n",
      "Pert bpr: 0.9023892589108852\n",
      "nll: 9.463200285418571\n",
      "Loss: -27.071677767326555\n",
      "EPOCH: 90\n",
      "det bpr: 0.9670277265104005\n",
      "Pert bpr: 0.9034628276730109\n",
      "nll: 9.446025858804678\n",
      "Loss: -27.103884830190328\n",
      "EPOCH: 91\n",
      "det bpr: 0.9661146958809037\n",
      "Pert bpr: 0.9040517308119129\n",
      "nll: 9.429245445536154\n",
      "Loss: -27.121551924357387\n",
      "EPOCH: 92\n",
      "det bpr: 0.9677194981727067\n",
      "Pert bpr: 0.904798815030584\n",
      "nll: 9.413910541200357\n",
      "Loss: -27.14396445091752\n",
      "EPOCH: 93\n",
      "det bpr: 0.9680064054098707\n",
      "Pert bpr: 0.9049069842996909\n",
      "nll: 9.398182816164448\n",
      "Loss: -27.147209528990725\n",
      "EPOCH: 94\n",
      "det bpr: 0.9642677940643924\n",
      "Pert bpr: 0.9054927467656373\n",
      "nll: 9.381293387724108\n",
      "Loss: -27.16478240296912\n",
      "EPOCH: 95\n",
      "det bpr: 0.9673103369591611\n",
      "Pert bpr: 0.9064689803043691\n",
      "nll: 9.363832597228827\n",
      "Loss: -27.19406940913107\n",
      "EPOCH: 96\n",
      "det bpr: 0.9652725068402197\n",
      "Pert bpr: 0.9065656359108732\n",
      "nll: 9.348184237630642\n",
      "Loss: -27.196969077326198\n",
      "EPOCH: 97\n",
      "det bpr: 0.9639700213827505\n",
      "Pert bpr: 0.9080493883718966\n",
      "nll: 9.332288813580828\n",
      "Loss: -27.2414816511569\n",
      "EPOCH: 98\n",
      "det bpr: 0.9647582153919543\n",
      "Pert bpr: 0.9078145350112432\n",
      "nll: 9.31819519404937\n",
      "Loss: -27.234436050337298\n",
      "EPOCH: 99\n",
      "det bpr: 0.9637114324162649\n",
      "Pert bpr: 0.9080979345235073\n",
      "nll: 9.30629237458239\n",
      "Loss: -27.24293803570522\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)\n",
    "\n",
    "M_score_func =  100\n",
    "M_action = 100\n",
    "train_T = train_y_TS.shape[0]\n",
    "perturbed_top_K_func = PerturbedBrokenTopK(k=K, sigma=perturbed_noise)\n",
    "losses, bprs, nlls = [], [], []\n",
    "for epoch in range(100):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    loss, bpr, nll, model = train_epoch(model, optimizer, K, threshold, train_T, M_score_func, M_action, train_y_TS, perturbed_top_K_func, bpr_weight, nll_weight)\n",
    "    losses.append(loss)\n",
    "    bprs.append(bpr)\n",
    "    nlls.append(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_177719/3122611628.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y_TS = torch.tensor(train_y_TS, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = torch.mean(-mix_model.log_prob( torch.tensor(train_y_TS)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det bpr: 0.8481752872467041\n",
      "Pert bpr: 0.8023001551628113\n",
      "nll: 14.704272270202637\n",
      "Loss: -24.06900405883789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "det bpr: 0.8586022257804871\n",
      "Pert bpr: 0.8042523264884949\n",
      "nll: 14.994690895080566\n",
      "Loss: -24.1275691986084\n",
      "EPOCH: 2\n",
      "det bpr: 0.8769272565841675\n",
      "Pert bpr: 0.8064742684364319\n",
      "nll: 15.254426002502441\n",
      "Loss: -24.19422721862793\n",
      "EPOCH: 3\n",
      "det bpr: 0.8753347396850586\n",
      "Pert bpr: 0.8080005645751953\n",
      "nll: 15.113702774047852\n",
      "Loss: -24.24001693725586\n",
      "EPOCH: 4\n",
      "det bpr: 0.8871694803237915\n",
      "Pert bpr: 0.8108158111572266\n",
      "nll: 15.023340225219727\n",
      "Loss: -24.324474334716797\n",
      "EPOCH: 5\n",
      "det bpr: 0.890000581741333\n",
      "Pert bpr: 0.8129664659500122\n",
      "nll: 15.006230354309082\n",
      "Loss: -24.388994216918945\n",
      "EPOCH: 6\n",
      "det bpr: 0.8919475674629211\n",
      "Pert bpr: 0.8152533173561096\n",
      "nll: 15.023977279663086\n",
      "Loss: -24.457599639892578\n",
      "EPOCH: 7\n",
      "det bpr: 0.8947763442993164\n",
      "Pert bpr: 0.8175246715545654\n",
      "nll: 14.976813316345215\n",
      "Loss: -24.525739669799805\n",
      "EPOCH: 8\n",
      "det bpr: 0.9001567363739014\n",
      "Pert bpr: 0.8201390504837036\n",
      "nll: 14.867987632751465\n",
      "Loss: -24.604171752929688\n",
      "EPOCH: 9\n",
      "det bpr: 0.9156369566917419\n",
      "Pert bpr: 0.8223062753677368\n",
      "nll: 14.695293426513672\n",
      "Loss: -24.669187545776367\n",
      "EPOCH: 10\n",
      "det bpr: 0.9309176206588745\n",
      "Pert bpr: 0.8240677714347839\n",
      "nll: 14.609060287475586\n",
      "Loss: -24.72203254699707\n",
      "EPOCH: 11\n",
      "det bpr: 0.9489147663116455\n",
      "Pert bpr: 0.8265746235847473\n",
      "nll: 14.50894832611084\n",
      "Loss: -24.797239303588867\n",
      "EPOCH: 12\n",
      "det bpr: 0.9637511968612671\n",
      "Pert bpr: 0.828529417514801\n",
      "nll: 14.476183891296387\n",
      "Loss: -24.85588264465332\n",
      "EPOCH: 13\n",
      "det bpr: 0.9664906859397888\n",
      "Pert bpr: 0.8309738636016846\n",
      "nll: 14.432754516601562\n",
      "Loss: -24.929216384887695\n",
      "EPOCH: 14\n",
      "det bpr: 0.9667613506317139\n",
      "Pert bpr: 0.8330677151679993\n",
      "nll: 14.355267524719238\n",
      "Loss: -24.99203109741211\n",
      "EPOCH: 15\n",
      "det bpr: 0.9673407673835754\n",
      "Pert bpr: 0.8350214958190918\n",
      "nll: 14.252718925476074\n",
      "Loss: -25.050643920898438\n",
      "EPOCH: 16\n",
      "det bpr: 0.9649838805198669\n",
      "Pert bpr: 0.8367435336112976\n",
      "nll: 14.135636329650879\n",
      "Loss: -25.102306365966797\n",
      "EPOCH: 17\n",
      "det bpr: 0.9651092886924744\n",
      "Pert bpr: 0.8390392065048218\n",
      "nll: 14.073680877685547\n",
      "Loss: -25.17117691040039\n",
      "EPOCH: 18\n",
      "det bpr: 0.9612793922424316\n",
      "Pert bpr: 0.8404048681259155\n",
      "nll: 14.062129020690918\n",
      "Loss: -25.212146759033203\n",
      "EPOCH: 19\n",
      "det bpr: 0.9598976969718933\n",
      "Pert bpr: 0.8421204090118408\n",
      "nll: 14.08287525177002\n",
      "Loss: -25.263612747192383\n",
      "EPOCH: 20\n",
      "det bpr: 0.9596630334854126\n",
      "Pert bpr: 0.8440741896629333\n",
      "nll: 14.083100318908691\n",
      "Loss: -25.32222557067871\n",
      "EPOCH: 21\n",
      "det bpr: 0.9576013088226318\n",
      "Pert bpr: 0.8450302481651306\n",
      "nll: 14.062941551208496\n",
      "Loss: -25.350908279418945\n",
      "EPOCH: 22\n",
      "det bpr: 0.9551516175270081\n",
      "Pert bpr: 0.8471207022666931\n",
      "nll: 14.0903959274292\n",
      "Loss: -25.41362190246582\n",
      "EPOCH: 23\n",
      "det bpr: 0.9536108374595642\n",
      "Pert bpr: 0.8484525084495544\n",
      "nll: 14.098973274230957\n",
      "Loss: -25.453575134277344\n",
      "EPOCH: 24\n",
      "det bpr: 0.9525107741355896\n",
      "Pert bpr: 0.8496193885803223\n",
      "nll: 14.070832252502441\n",
      "Loss: -25.488582611083984\n",
      "EPOCH: 25\n",
      "det bpr: 0.9547131061553955\n",
      "Pert bpr: 0.8510025143623352\n",
      "nll: 14.019404411315918\n",
      "Loss: -25.530075073242188\n",
      "EPOCH: 26\n",
      "det bpr: 0.9538648724555969\n",
      "Pert bpr: 0.8523642420768738\n",
      "nll: 13.993926048278809\n",
      "Loss: -25.570926666259766\n",
      "EPOCH: 27\n",
      "det bpr: 0.9509178400039673\n",
      "Pert bpr: 0.8535869717597961\n",
      "nll: 13.974656105041504\n",
      "Loss: -25.607608795166016\n",
      "EPOCH: 28\n",
      "det bpr: 0.9549211263656616\n",
      "Pert bpr: 0.8546736836433411\n",
      "nll: 13.970029830932617\n",
      "Loss: -25.64021110534668\n",
      "EPOCH: 29\n",
      "det bpr: 0.9519263505935669\n",
      "Pert bpr: 0.8557061553001404\n",
      "nll: 13.920129776000977\n",
      "Loss: -25.671184539794922\n",
      "EPOCH: 30\n",
      "det bpr: 0.9533773064613342\n",
      "Pert bpr: 0.8567685484886169\n",
      "nll: 13.926861763000488\n",
      "Loss: -25.70305633544922\n",
      "EPOCH: 31\n",
      "det bpr: 0.9534313678741455\n",
      "Pert bpr: 0.8574007749557495\n",
      "nll: 13.900625228881836\n",
      "Loss: -25.722023010253906\n",
      "EPOCH: 32\n",
      "det bpr: 0.9543578028678894\n",
      "Pert bpr: 0.8587161302566528\n",
      "nll: 13.863370895385742\n",
      "Loss: -25.761484146118164\n",
      "EPOCH: 33\n",
      "det bpr: 0.9522615075111389\n",
      "Pert bpr: 0.8597959280014038\n",
      "nll: 13.812784194946289\n",
      "Loss: -25.79387855529785\n",
      "EPOCH: 34\n",
      "det bpr: 0.9542929530143738\n",
      "Pert bpr: 0.860605001449585\n",
      "nll: 13.729506492614746\n",
      "Loss: -25.81814956665039\n",
      "EPOCH: 35\n",
      "det bpr: 0.9564819931983948\n",
      "Pert bpr: 0.8612782955169678\n",
      "nll: 13.64488410949707\n",
      "Loss: -25.838348388671875\n",
      "EPOCH: 36\n",
      "det bpr: 0.9563217163085938\n",
      "Pert bpr: 0.8625584244728088\n",
      "nll: 13.565414428710938\n",
      "Loss: -25.876752853393555\n",
      "EPOCH: 37\n",
      "det bpr: 0.9569138884544373\n",
      "Pert bpr: 0.8633671998977661\n",
      "nll: 13.518594741821289\n",
      "Loss: -25.901016235351562\n",
      "EPOCH: 38\n",
      "det bpr: 0.9622364640235901\n",
      "Pert bpr: 0.8639533519744873\n",
      "nll: 13.428413391113281\n",
      "Loss: -25.91860008239746\n",
      "EPOCH: 39\n",
      "det bpr: 0.959169328212738\n",
      "Pert bpr: 0.8649770617485046\n",
      "nll: 13.340381622314453\n",
      "Loss: -25.949312210083008\n",
      "EPOCH: 40\n",
      "det bpr: 0.9625399112701416\n",
      "Pert bpr: 0.8657804131507874\n",
      "nll: 13.260432243347168\n",
      "Loss: -25.973411560058594\n",
      "EPOCH: 41\n",
      "det bpr: 0.9632251262664795\n",
      "Pert bpr: 0.8664761781692505\n",
      "nll: 13.172532081604004\n",
      "Loss: -25.994285583496094\n",
      "EPOCH: 42\n",
      "det bpr: 0.9632418155670166\n",
      "Pert bpr: 0.8670772910118103\n",
      "nll: 13.091764450073242\n",
      "Loss: -26.012319564819336\n",
      "EPOCH: 43\n",
      "det bpr: 0.9643374681472778\n",
      "Pert bpr: 0.8685232996940613\n",
      "nll: 13.012214660644531\n",
      "Loss: -26.05569839477539\n",
      "EPOCH: 44\n",
      "det bpr: 0.9648236632347107\n",
      "Pert bpr: 0.8687325119972229\n",
      "nll: 12.945547103881836\n",
      "Loss: -26.061975479125977\n",
      "EPOCH: 45\n",
      "det bpr: 0.9635167717933655\n",
      "Pert bpr: 0.869924783706665\n",
      "nll: 12.850443840026855\n",
      "Loss: -26.09774398803711\n",
      "EPOCH: 46\n",
      "det bpr: 0.9656614065170288\n",
      "Pert bpr: 0.8710615038871765\n",
      "nll: 12.778326034545898\n",
      "Loss: -26.131845474243164\n",
      "EPOCH: 47\n",
      "det bpr: 0.9646039605140686\n",
      "Pert bpr: 0.8716915249824524\n",
      "nll: 12.693476676940918\n",
      "Loss: -26.150745391845703\n",
      "EPOCH: 48\n",
      "det bpr: 0.9652962684631348\n",
      "Pert bpr: 0.8722148537635803\n",
      "nll: 12.610818862915039\n",
      "Loss: -26.166444778442383\n",
      "EPOCH: 49\n",
      "det bpr: 0.967488706111908\n",
      "Pert bpr: 0.873258650302887\n",
      "nll: 12.524813652038574\n",
      "Loss: -26.1977596282959\n",
      "EPOCH: 50\n",
      "det bpr: 0.9679862260818481\n",
      "Pert bpr: 0.8742948770523071\n",
      "nll: 12.445869445800781\n",
      "Loss: -26.228845596313477\n",
      "EPOCH: 51\n",
      "det bpr: 0.9681094288825989\n",
      "Pert bpr: 0.8748692870140076\n",
      "nll: 12.362883567810059\n",
      "Loss: -26.246078491210938\n",
      "EPOCH: 52\n",
      "det bpr: 0.967572033405304\n",
      "Pert bpr: 0.8756586909294128\n",
      "nll: 12.282635688781738\n",
      "Loss: -26.269760131835938\n",
      "EPOCH: 53\n",
      "det bpr: 0.9670920372009277\n",
      "Pert bpr: 0.8765438199043274\n",
      "nll: 12.218971252441406\n",
      "Loss: -26.296314239501953\n",
      "EPOCH: 54\n",
      "det bpr: 0.9664651155471802\n",
      "Pert bpr: 0.8771698474884033\n",
      "nll: 12.157275199890137\n",
      "Loss: -26.315095901489258\n",
      "EPOCH: 55\n",
      "det bpr: 0.967978298664093\n",
      "Pert bpr: 0.8779537081718445\n",
      "nll: 12.106672286987305\n",
      "Loss: -26.338611602783203\n",
      "EPOCH: 56\n",
      "det bpr: 0.9663727879524231\n",
      "Pert bpr: 0.8790314197540283\n",
      "nll: 12.064297676086426\n",
      "Loss: -26.370943069458008\n",
      "EPOCH: 57\n",
      "det bpr: 0.9660523533821106\n",
      "Pert bpr: 0.8796143531799316\n",
      "nll: 12.019405364990234\n",
      "Loss: -26.388431549072266\n",
      "EPOCH: 58\n",
      "det bpr: 0.9665327668190002\n",
      "Pert bpr: 0.8802714943885803\n",
      "nll: 11.985265731811523\n",
      "Loss: -26.408143997192383\n",
      "EPOCH: 59\n",
      "det bpr: 0.9686223268508911\n",
      "Pert bpr: 0.8809776902198792\n",
      "nll: 11.963258743286133\n",
      "Loss: -26.429330825805664\n",
      "EPOCH: 60\n",
      "det bpr: 0.9654310345649719\n",
      "Pert bpr: 0.88176429271698\n",
      "nll: 11.926194190979004\n",
      "Loss: -26.45292854309082\n",
      "EPOCH: 61\n",
      "det bpr: 0.9673897624015808\n",
      "Pert bpr: 0.8828948736190796\n",
      "nll: 11.902007102966309\n",
      "Loss: -26.486846923828125\n",
      "EPOCH: 62\n",
      "det bpr: 0.9652184247970581\n",
      "Pert bpr: 0.883202075958252\n",
      "nll: 11.873774528503418\n",
      "Loss: -26.496063232421875\n",
      "EPOCH: 63\n",
      "det bpr: 0.9659717679023743\n",
      "Pert bpr: 0.8840942978858948\n",
      "nll: 11.839885711669922\n",
      "Loss: -26.522829055786133\n",
      "EPOCH: 64\n",
      "det bpr: 0.9649317264556885\n",
      "Pert bpr: 0.8849871158599854\n",
      "nll: 11.811681747436523\n",
      "Loss: -26.54961395263672\n",
      "EPOCH: 65\n",
      "det bpr: 0.9646318554878235\n",
      "Pert bpr: 0.8855708241462708\n",
      "nll: 11.801095962524414\n",
      "Loss: -26.56712532043457\n",
      "EPOCH: 66\n",
      "det bpr: 0.9669306874275208\n",
      "Pert bpr: 0.8866974115371704\n",
      "nll: 11.783829689025879\n",
      "Loss: -26.600921630859375\n",
      "EPOCH: 67\n",
      "det bpr: 0.9661332964897156\n",
      "Pert bpr: 0.887340784072876\n",
      "nll: 11.765934944152832\n",
      "Loss: -26.620223999023438\n",
      "EPOCH: 68\n",
      "det bpr: 0.9666606187820435\n",
      "Pert bpr: 0.8881722688674927\n",
      "nll: 11.740706443786621\n",
      "Loss: -26.64516830444336\n",
      "EPOCH: 69\n",
      "det bpr: 0.9640415906906128\n",
      "Pert bpr: 0.8884872198104858\n",
      "nll: 11.705480575561523\n",
      "Loss: -26.654617309570312\n",
      "EPOCH: 70\n",
      "det bpr: 0.9669218063354492\n",
      "Pert bpr: 0.8893727660179138\n",
      "nll: 11.664639472961426\n",
      "Loss: -26.681182861328125\n",
      "EPOCH: 71\n",
      "det bpr: 0.9663642048835754\n",
      "Pert bpr: 0.8903360962867737\n",
      "nll: 11.625558853149414\n",
      "Loss: -26.7100830078125\n",
      "EPOCH: 72\n",
      "det bpr: 0.9659920334815979\n",
      "Pert bpr: 0.8907703161239624\n",
      "nll: 11.576205253601074\n",
      "Loss: -26.72311019897461\n",
      "EPOCH: 73\n",
      "det bpr: 0.9674137830734253\n",
      "Pert bpr: 0.8913336992263794\n",
      "nll: 11.5285062789917\n",
      "Loss: -26.74001121520996\n",
      "EPOCH: 74\n",
      "det bpr: 0.9670907855033875\n",
      "Pert bpr: 0.8921775221824646\n",
      "nll: 11.482964515686035\n",
      "Loss: -26.76532554626465\n",
      "EPOCH: 75\n",
      "det bpr: 0.9654291868209839\n",
      "Pert bpr: 0.8927621841430664\n",
      "nll: 11.44390869140625\n",
      "Loss: -26.782865524291992\n",
      "EPOCH: 76\n",
      "det bpr: 0.9658350348472595\n",
      "Pert bpr: 0.8936196565628052\n",
      "nll: 11.406481742858887\n",
      "Loss: -26.808589935302734\n",
      "EPOCH: 77\n",
      "det bpr: 0.9646549224853516\n",
      "Pert bpr: 0.8943501114845276\n",
      "nll: 11.367897987365723\n",
      "Loss: -26.830503463745117\n",
      "EPOCH: 78\n",
      "det bpr: 0.9663742780685425\n",
      "Pert bpr: 0.8949871063232422\n",
      "nll: 11.332645416259766\n",
      "Loss: -26.849613189697266\n",
      "EPOCH: 79\n",
      "det bpr: 0.9646549224853516\n",
      "Pert bpr: 0.8958308696746826\n",
      "nll: 11.295404434204102\n",
      "Loss: -26.87492561340332\n",
      "EPOCH: 80\n",
      "det bpr: 0.9652180671691895\n",
      "Pert bpr: 0.8963594436645508\n",
      "nll: 11.261395454406738\n",
      "Loss: -26.890783309936523\n",
      "EPOCH: 81\n",
      "det bpr: 0.9641203880310059\n",
      "Pert bpr: 0.8969491720199585\n",
      "nll: 11.229569435119629\n",
      "Loss: -26.908475875854492\n",
      "EPOCH: 82\n",
      "det bpr: 0.9659909605979919\n",
      "Pert bpr: 0.8971922397613525\n",
      "nll: 11.190803527832031\n",
      "Loss: -26.915767669677734\n",
      "EPOCH: 83\n",
      "det bpr: 0.9650344252586365\n",
      "Pert bpr: 0.8983091115951538\n",
      "nll: 11.1484375\n",
      "Loss: -26.94927406311035\n",
      "EPOCH: 84\n",
      "det bpr: 0.9644691348075867\n",
      "Pert bpr: 0.8986972570419312\n",
      "nll: 11.104900360107422\n",
      "Loss: -26.960918426513672\n",
      "EPOCH: 85\n",
      "det bpr: 0.9654545783996582\n",
      "Pert bpr: 0.89932781457901\n",
      "nll: 11.068826675415039\n",
      "Loss: -26.979833602905273\n",
      "EPOCH: 86\n",
      "det bpr: 0.9640837907791138\n",
      "Pert bpr: 0.8999673128128052\n",
      "nll: 11.036081314086914\n",
      "Loss: -26.999019622802734\n",
      "EPOCH: 87\n",
      "det bpr: 0.9661161303520203\n",
      "Pert bpr: 0.9010574221611023\n",
      "nll: 10.998627662658691\n",
      "Loss: -27.031723022460938\n",
      "EPOCH: 88\n",
      "det bpr: 0.9666264653205872\n",
      "Pert bpr: 0.901446521282196\n",
      "nll: 10.957098960876465\n",
      "Loss: -27.04339599609375\n",
      "EPOCH: 89\n",
      "det bpr: 0.966126561164856\n",
      "Pert bpr: 0.9024795889854431\n",
      "nll: 10.911543846130371\n",
      "Loss: -27.07438850402832\n",
      "EPOCH: 90\n",
      "det bpr: 0.9635457992553711\n",
      "Pert bpr: 0.9026819467544556\n",
      "nll: 10.870296478271484\n",
      "Loss: -27.08045768737793\n",
      "EPOCH: 91\n",
      "det bpr: 0.9663945436477661\n",
      "Pert bpr: 0.9034779071807861\n",
      "nll: 10.829984664916992\n",
      "Loss: -27.104337692260742\n",
      "EPOCH: 92\n",
      "det bpr: 0.9671972393989563\n",
      "Pert bpr: 0.9040585160255432\n",
      "nll: 10.794435501098633\n",
      "Loss: -27.121755599975586\n",
      "EPOCH: 93\n",
      "det bpr: 0.9663134217262268\n",
      "Pert bpr: 0.9050607085227966\n",
      "nll: 10.767285346984863\n",
      "Loss: -27.15182113647461\n",
      "EPOCH: 94\n",
      "det bpr: 0.9648069143295288\n",
      "Pert bpr: 0.9052968621253967\n",
      "nll: 10.73580265045166\n",
      "Loss: -27.158905029296875\n",
      "EPOCH: 95\n",
      "det bpr: 0.9661341905593872\n",
      "Pert bpr: 0.9056022763252258\n",
      "nll: 10.709943771362305\n",
      "Loss: -27.168067932128906\n",
      "EPOCH: 96\n",
      "det bpr: 0.9653412103652954\n",
      "Pert bpr: 0.9063171744346619\n",
      "nll: 10.682995796203613\n",
      "Loss: -27.189516067504883\n",
      "EPOCH: 97\n",
      "det bpr: 0.965309202671051\n",
      "Pert bpr: 0.9070723056793213\n",
      "nll: 10.652095794677734\n",
      "Loss: -27.212169647216797\n",
      "EPOCH: 98\n",
      "det bpr: 0.9663888812065125\n",
      "Pert bpr: 0.9077454805374146\n",
      "nll: 10.622028350830078\n",
      "Loss: -27.232364654541016\n",
      "EPOCH: 99\n",
      "det bpr: 0.9691198468208313\n",
      "Pert bpr: 0.9083546996116638\n",
      "nll: 10.59304141998291\n",
      "Loss: -27.250640869140625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MixtureOfTruncNormModel(num_components=num_components, S=S, low=0, high=150)\n",
    "if init_idx is not None:\n",
    "    # Reproducibly, randomly generate some numbers using a numpy rng\n",
    "    init_rng = np.random.RandomState(1989)\n",
    "    # generate 20 sets of 2 floats between 0.5 and 60\n",
    "    all_means = init_rng.uniform(8, 102, (20, num_components))\n",
    "    # generate 20 sets of 2 floats between 0.25 and 6\n",
    "    all_scales = init_rng.uniform(0.25, 8, (20, num_components))\n",
    "    # generate 20 lists length S containing lists length 2 which sum to 1\n",
    "    all_mix_weights = init_rng.dirichlet([0.5]*num_components, (20,S))\n",
    "\n",
    "    softinv_means = torch.tensor(all_means[init_idx]) + torch.log(-torch.expm1(torch.tensor(-all_means[init_idx])))\n",
    "    softinv_scales = torch.tensor(all_scales[init_idx]) - 0.2 + torch.log(-torch.expm1(torch.tensor(-all_scales[init_idx] + 0.2)))\n",
    "    mix_weights = torch.log(1e-13 + torch.tensor(all_mix_weights[init_idx], dtype=torch.float32))\n",
    "\n",
    "    # cast to float32\n",
    "    softinv_means = softinv_means.float()\n",
    "    softinv_scales = softinv_scales.float()\n",
    "    mix_weights = mix_weights.float()\n",
    "    model.update_params(torch.cat([softinv_means, softinv_scales, mix_weights.view(-1)]))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)\n",
    "train_y_TS = torch.tensor(train_y_TS, dtype=torch.float32)\n",
    "M_score_func =  100\n",
    "M_action = 100\n",
    "train_T = train_y_TS.shape[0]\n",
    "from functools import partial\n",
    "topk_func = partial(top_k_onehot_indicator, k=K)\n",
    "perturbed_top_K_func = perturbed(topk_func, sigma=perturbed_noise)\n",
    "losses, bprs, nlls = [], [], []\n",
    "for epoch in range(100):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    loss, bpr, nll, model = train_epoch(model, optimizer, K, threshold, train_T, M_score_func, M_action, train_y_TS, perturbed_top_K_func, bpr_weight, nll_weight)\n",
    "    losses.append(loss)\n",
    "    bprs.append(bpr)\n",
    "    nlls.append(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_means.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softinv_scales.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
