{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:46:01.142738: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-29 13:46:01.195150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 13:46:01.195194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 13:46:01.196410: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 13:46:01.205126: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 13:46:02.873100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "# add code directory to path\n",
    "import sys\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from torch_models import NegativeBinomialRegressionModel\n",
    "from metrics import top_k_onehot_indicator\n",
    "from functools import partial\n",
    "from torch_models import NegativeBinomialRegressionModel\n",
    "from metrics import top_k_onehot_indicator\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from torch_models import torch_bpr_uncurried, deterministic_bpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/cluster/home/kheuto01/code/prob_diff_topk'\n",
    "base_dir = '/cluster/tufts/hugheslab/kheuto01/neg_binom_experiments_K100_8000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_3d_array(df):\n",
    "    # Ensure the DataFrame has a MultiIndex with 'geoid' and 'timestep'\n",
    "    if not isinstance(df.index, pd.MultiIndex) or set(df.index.names) != {'geoid', 'timestep'}:\n",
    "        raise ValueError(\"DataFrame must have a MultiIndex with levels 'geoid' and 'timestep'\")\n",
    "\n",
    "    # Get unique geoids and timesteps, sorted\n",
    "    geoids = sorted(df.index.get_level_values('geoid').unique())\n",
    "    timesteps = sorted(df.index.get_level_values('timestep').unique())\n",
    "\n",
    "    # Create a mapping of geoids to indices\n",
    "    geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "\n",
    "    # Initialize the 3D array\n",
    "    num_timesteps = len(timesteps)\n",
    "    num_locations = len(geoids)\n",
    "    num_features = len(df.columns)\n",
    "    X = np.zeros((num_timesteps, num_locations, num_features))\n",
    "\n",
    "    # Fill the 3D array\n",
    "    for (geoid, timestep), row in df.iterrows():\n",
    "        t_idx = timesteps.index(timestep)\n",
    "        g_idx = geoid_to_idx[geoid]\n",
    "        X[t_idx, g_idx, :] = row.values\n",
    "\n",
    "    return X, geoids, timesteps\n",
    "\n",
    "def convert_y_df_to_2d_array(y_df, geoids, timesteps):\n",
    "    # Ensure the DataFrame has a MultiIndex with 'geoid' and 'timestep'\n",
    "    if not isinstance(y_df.index, pd.MultiIndex) or set(y_df.index.names) != {'geoid', 'timestep'}:\n",
    "        raise ValueError(\"DataFrame must have a MultiIndex with levels 'geoid' and 'timestep'\")\n",
    "\n",
    "    # Initialize the 2D array\n",
    "    num_timesteps = len(timesteps)\n",
    "    num_locations = len(geoids)\n",
    "    y = np.zeros((num_timesteps, num_locations))\n",
    "\n",
    "    # Create a mapping of geoids to indices\n",
    "    geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "\n",
    "    # Fill the 2D array\n",
    "    for (geoid, timestep), value in y_df.iloc[:, 0].items():\n",
    "        t_idx = timesteps.index(timestep)\n",
    "        g_idx = geoid_to_idx[geoid]\n",
    "        y[t_idx, g_idx] = value\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_X_df = pd.read_csv(os.path.join(data_dir, 'mass_train_x.csv'), index_col=[0,1])\n",
    "train_Y_df = pd.read_csv(os.path.join(data_dir, 'mass_train_y.csv'), index_col=[0,1])\n",
    "\n",
    "# Load validation data\n",
    "val_X_df = pd.read_csv(os.path.join(data_dir, 'mass_valid_x.csv'), index_col=[0,1])\n",
    "val_Y_df = pd.read_csv(os.path.join(data_dir, 'mass_valid_y.csv'), index_col=[0,1])\n",
    "\n",
    "# Process training data\n",
    "train_X, geoids, timesteps = convert_df_to_3d_array(train_X_df.drop(columns='timestep.1'))\n",
    "train_time_arr = np.array([timesteps] * len(geoids)).T\n",
    "train_y = convert_y_df_to_2d_array(train_Y_df, geoids, timesteps)\n",
    "\n",
    "# Process validation data\n",
    "val_X, _, val_timesteps = convert_df_to_3d_array(val_X_df.drop(columns='timestep.1'))\n",
    "val_time_arr = np.array([val_timesteps] * len(geoids)).T\n",
    "val_y = convert_y_df_to_2d_array(val_Y_df, geoids, val_timesteps)\n",
    "\n",
    "# Convert to tensors and move to device\n",
    "X_train = torch.tensor(train_X, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(train_y, dtype=torch.float32).to(device)\n",
    "time_train = torch.tensor(train_time_arr, dtype=torch.float32).to(device)\n",
    "\n",
    "X_val = torch.tensor(val_X, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(val_y, dtype=torch.float32).to(device)\n",
    "time_val = torch.tensor(val_time_arr, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, S, F = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NegativeBinomialRegressionModel(\n",
    "        num_locations=len(geoids),\n",
    "        num_fixed_effects=train_X.shape[2]\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vec = model.params_to_single_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3262])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3262"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S*2+5+F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
