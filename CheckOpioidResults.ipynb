{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# add code directory to path\n",
    "import sys\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from torch_models import NegativeBinomialRegressionModel\n",
    "from metrics import top_k_onehot_indicator\n",
    "from functools import partial\n",
    "from torch_models import NegativeBinomialRegressionModel\n",
    "from metrics import top_k_onehot_indicator\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from torch_models import torch_bpr_uncurried, deterministic_bpr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Load and process training, validation, and test data.\"\"\"\n",
    "    # Load data\n",
    "    train_X_df = pd.read_csv(os.path.join(data_dir, 'train_x.csv'), index_col=[0,1])\n",
    "    train_Y_df = pd.read_csv(os.path.join(data_dir, 'train_y.csv'), index_col=[0,1])\n",
    "    val_X_df = pd.read_csv(os.path.join(data_dir, 'valid_x.csv'), index_col=[0,1])\n",
    "    val_Y_df = pd.read_csv(os.path.join(data_dir, 'valid_y.csv'), index_col=[0,1])\n",
    "    test_X_df = pd.read_csv(os.path.join(data_dir, 'test_x.csv'), index_col=[0,1])\n",
    "    test_Y_df = pd.read_csv(os.path.join(data_dir, 'test_y.csv'), index_col=[0,1])\n",
    "    \n",
    "    def convert_df_to_3d_array(df):\n",
    "        geoids = sorted(df.index.get_level_values('geoid').unique())\n",
    "        timesteps = sorted(df.index.get_level_values('timestep').unique())\n",
    "        geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "        \n",
    "        num_timesteps = len(timesteps)\n",
    "        num_locations = len(geoids)\n",
    "        num_features = len(df.columns)\n",
    "        X = np.zeros((num_timesteps, num_locations, num_features))\n",
    "        \n",
    "        for (geoid, timestep), row in df.iterrows():\n",
    "            t_idx = timesteps.index(timestep)\n",
    "            g_idx = geoid_to_idx[geoid]\n",
    "            X[t_idx, g_idx, :] = row.values\n",
    "            \n",
    "        return X, geoids, timesteps\n",
    "\n",
    "    def convert_y_df_to_2d_array(y_df, geoids, timesteps):\n",
    "        num_timesteps = len(timesteps)\n",
    "        num_locations = len(geoids)\n",
    "        y = np.zeros((num_timesteps, num_locations))\n",
    "        geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "        \n",
    "        for (geoid, timestep), value in y_df.iloc[:, 0].items():\n",
    "            t_idx = timesteps.index(timestep)\n",
    "            g_idx = geoid_to_idx[geoid]\n",
    "            y[t_idx, g_idx] = value\n",
    "            \n",
    "        return y\n",
    "\n",
    "    # Process training data\n",
    "    train_X, geoids, timesteps = convert_df_to_3d_array(train_X_df.drop(columns='timestep.1'))\n",
    "    train_time = np.array([timesteps] * len(geoids)).T\n",
    "    train_y = convert_y_df_to_2d_array(train_Y_df, geoids, timesteps)\n",
    "\n",
    "    # Process validation data\n",
    "    val_X, val_geoids, val_timesteps = convert_df_to_3d_array(val_X_df.drop(columns='timestep.1'))\n",
    "    val_time = np.array([val_timesteps] * len(val_geoids)).T\n",
    "    val_y = convert_y_df_to_2d_array(val_Y_df, val_geoids, val_timesteps)\n",
    "\n",
    "    # Process test data\n",
    "    test_X, test_geoids, test_timesteps = convert_df_to_3d_array(test_X_df.drop(columns='timestep.1'))\n",
    "    test_time = np.array([test_timesteps] * len(test_geoids)).T\n",
    "    test_y = convert_y_df_to_2d_array(test_Y_df, test_geoids, test_timesteps)\n",
    "\n",
    "    return {\n",
    "        'train': (torch.tensor(train_X, dtype=torch.float32), \n",
    "                 torch.tensor(train_time, dtype=torch.float32),\n",
    "                 torch.tensor(train_y, dtype=torch.float32)),\n",
    "        'val': (torch.tensor(val_X, dtype=torch.float32),\n",
    "               torch.tensor(val_time, dtype=torch.float32),\n",
    "               torch.tensor(val_y, dtype=torch.float32)),\n",
    "        'test': (torch.tensor(test_X, dtype=torch.float32),\n",
    "                torch.tensor(test_time, dtype=torch.float32),\n",
    "                torch.tensor(test_y, dtype=torch.float32))\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, X, time_T, y, K, perturbed_noise=0.01, num_pert_samples=50, num_score_samples=20):\n",
    "    \"\"\"Evaluate model using the same metrics as in training.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        dist = model(X, time_T)\n",
    "        \n",
    "        # Get samples for ratio calculation\n",
    "        y_sample_TMS = dist.sample((num_score_samples,)).permute(1, 0, 2)\n",
    "        ratio_rating_TMS = y_sample_TMS/y_sample_TMS.sum(dim=-1, keepdim=True)\n",
    "        ratio_rating_TS = ratio_rating_TMS.mean(dim=1)\n",
    "        \n",
    "        # Calculate deterministic BPR\n",
    "        det_bpr = deterministic_bpr(ratio_rating_TS, y, K=K)\n",
    "        det_bpr = torch.mean(det_bpr)\n",
    "        \n",
    "        # Calculate perturbed BPR\n",
    "        top_k_func = partial(top_k_onehot_indicator, k=K)\n",
    "        perturbed_top_K_func = perturbed(top_k_func, sigma=perturbed_noise, num_samples=num_pert_samples)\n",
    "        pert_bpr = torch_bpr_uncurried(ratio_rating_TS, y, K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "        pert_bpr = torch.mean(pert_bpr)\n",
    "        \n",
    "        # Calculate NLL\n",
    "        nll = -model.log_likelihood(y, X, time_T)\n",
    "        \n",
    "        return {\n",
    "            'det_bpr': det_bpr.item(),\n",
    "            'pert_bpr': pert_bpr.item(),\n",
    "            'nll': nll.item()\n",
    "        }\n",
    "\n",
    "def find_best_model_and_evaluate(base_dir, data_dir, device='cuda', K=100):\n",
    "    \"\"\"Find the best model based on validation performance and evaluate on test set.\"\"\"\n",
    "    # Load all data\n",
    "    data = load_data(data_dir)\n",
    "    \n",
    "    # Move data to device\n",
    "    val_data = tuple(x.to(device) for x in data['val'])\n",
    "    test_data = tuple(x.to(device) for x in data['test'])\n",
    "    # Find all experiment directories\n",
    "    exp_dirs = glob.glob(os.path.join(base_dir, \"K*\"))\n",
    "    \n",
    "    best_val_score = float('-inf')\n",
    "    best_model_info = None\n",
    "    \n",
    "    results = []\n",
    "    print(exp_dirs)\n",
    "    for exp_dir in exp_dirs:\n",
    "        # Extract hyperparameters from directory name\n",
    "        dir_name = os.path.basename(exp_dir)\n",
    "        params = [param.split('_') for param in dir_name.split('_')]\n",
    "        \n",
    "        # Load model\n",
    "        model_path = os.path.join(exp_dir, 'best_model.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "            \n",
    "        # Initialize model with correct parameters\n",
    "        model = NegativeBinomialRegressionModel(\n",
    "            num_locations=data['train'][0].shape[1],\n",
    "            num_fixed_effects=data['train'][0].shape[2]\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "        # Load saved weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_performance = evaluate_model(\n",
    "            model, *val_data, K=K,\n",
    "        )\n",
    "        \n",
    "        # Track results\n",
    "        result = {\n",
    "            'dir': exp_dir,\n",
    "            **val_performance,\n",
    "            'params':params}\n",
    "\n",
    "        results.append(result)\n",
    "        \n",
    "        # Update best model if this one is better\n",
    "        if val_performance['det_bpr'] > best_val_score:\n",
    "            best_val_score = val_performance['det_bpr']\n",
    "            best_model_info = {\n",
    "                'model': model,\n",
    "                'dir': exp_dir,\n",
    "                'params': params,\n",
    "                'val_performance': val_performance\n",
    "            }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Evaluate best model on test set\n",
    "    if best_model_info is not None:\n",
    "        test_performance = evaluate_model(\n",
    "            best_model_info['model'], *test_data, K=K,\n",
    "        )\n",
    "        \n",
    "        print(\"\\nBest Model Information:\")\n",
    "        print(f\"Directory: {best_model_info['dir']}\")\n",
    "        print(f\"Parameters: {best_model_info['params']}\")\n",
    "        print(\"\\nValidation Performance:\")\n",
    "        print(f\"Deterministic BPR: {best_model_info['val_performance']['det_bpr']:.4f}\")\n",
    "        print(f\"Perturbed BPR: {best_model_info['val_performance']['pert_bpr']:.4f}\")\n",
    "        print(f\"NLL: {best_model_info['val_performance']['nll']:.4f}\")\n",
    "        print(\"\\nTest Performance:\")\n",
    "        print(f\"Deterministic BPR: {test_performance['det_bpr']:.4f}\")\n",
    "        print(f\"Perturbed BPR: {test_performance['pert_bpr']:.4f}\")\n",
    "        print(f\"NLL: {test_performance['nll']:.4f}\")\n",
    "    \n",
    "    return results_df, best_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/cluster/tufts/hugheslab/datasets/NSF_OD/cleaned/cook'\n",
    "base_dir = '/cluster/tufts/hugheslab/kheuto01/opioid_grid_fix_grad/cook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_negative_binomial_report(exp_dir, title=None):\n",
    "    \"\"\"\n",
    "    Generate a report with training metrics from saved CSV files.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir: Directory containing experiment metrics files\n",
    "        title: Title for the report\n",
    "    \"\"\"\n",
    "    # Load metrics from CSV files\n",
    "    train_metrics = pd.read_csv(os.path.join(exp_dir, 'train_metrics.csv'), index_col='epochs')\n",
    "    val_metrics = pd.read_csv(os.path.join(exp_dir, 'val_metrics.csv'), index_col='epochs')\n",
    "    times = pd.read_csv(os.path.join(exp_dir, 'time_metrics.csv'))\n",
    "\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    else:\n",
    "        fig.suptitle(os.path.basename(exp_dir), fontsize=16)\n",
    "\n",
    "    # Plot training and validation metrics\n",
    "    epochs = train_metrics.index\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0, 0].plot(epochs, train_metrics['loss'], 'b-', label='Train Loss')\n",
    "    axes[0, 0].set_title('Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # BPR plot\n",
    "    axes[0, 1].plot(epochs, train_metrics['deterministic_bpr'], 'g-', label='Train BPR')\n",
    "    if 'deterministic_bpr' in val_metrics.columns:\n",
    "        val_epochs = val_metrics.index\n",
    "        axes[0, 1].plot(val_epochs, val_metrics['deterministic_bpr'], 'g--', label='Val BPR')\n",
    "    axes[0, 1].set_title('Deterministic BPR')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('BPR')\n",
    "    axes[0, 1].grid(True)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # NLL plot\n",
    "    axes[1, 0].plot(epochs, train_metrics['nll'], 'r-', label='Train NLL')\n",
    "    if 'nll' in val_metrics.columns:\n",
    "        axes[1, 0].plot(val_epochs, val_metrics['nll'], 'r--', label='Val NLL')\n",
    "    axes[1, 0].set_title('Negative Log Likelihood (NLL)')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('NLL')\n",
    "    axes[1, 0].grid(True)\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Time plot\n",
    "    cumulative_time = np.cumsum(times['times'])\n",
    "    axes[1, 1].plot(np.arange(len(cumulative_time)), cumulative_time, 'm-', label='Cumulative Time')\n",
    "    axes[1, 1].set_title('Cumulative Training Time')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Time (seconds)')\n",
    "    axes[1, 1].grid(True)\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    report_path = os.path.join(exp_dir, 'training_report.png')\n",
    "    plt.savefig(report_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate summary metrics\n",
    "    summary = {\n",
    "        'final_loss': train_metrics['loss'].iloc[-1],\n",
    "        'final_train_bpr': train_metrics['deterministic_bpr'].iloc[-1],\n",
    "        'final_train_nll': train_metrics['nll'].iloc[-1],\n",
    "        'best_train_bpr': train_metrics['deterministic_bpr'].max(),\n",
    "        'best_train_bpr_epoch': train_metrics['deterministic_bpr'].idxmax(),\n",
    "        'min_train_nll': train_metrics['nll'].min(),\n",
    "        'min_train_nll_epoch': train_metrics['nll'].idxmin(),\n",
    "        'total_time': cumulative_time,\n",
    "        'total_epochs': len(epochs)\n",
    "    }\n",
    "\n",
    "    # Add validation metrics if available\n",
    "    if not val_metrics.empty:\n",
    "        summary.update({\n",
    "            'final_val_bpr': val_metrics['deterministic_bpr'].iloc[-1],\n",
    "            'final_val_nll': val_metrics['nll'].iloc[-1],\n",
    "            'best_val_bpr': val_metrics['deterministic_bpr'].max(),\n",
    "            'best_val_bpr_epoch': val_metrics['deterministic_bpr'].idxmax(),\n",
    "            'min_val_nll': val_metrics['nll'].min(),\n",
    "            'min_val_nll_epoch': val_metrics['nll'].idxmin()\n",
    "        })\n",
    "\n",
    "    return summary\n",
    "\n",
    "def generate_reports_for_all_experiments(base_dir):\n",
    "    \"\"\"Generate reports for all experiments in the base directory.\"\"\"\n",
    "    exp_dirs = glob.glob(os.path.join(base_dir, \"K*\"))\n",
    "    summaries = []\n",
    "    \n",
    "    for exp_dir in exp_dirs:\n",
    "        try:\n",
    "            # Extract parameters from directory name\n",
    "            dir_name = os.path.basename(exp_dir)\n",
    "            params = {}\n",
    "            for param in dir_name.split('_'):\n",
    "                if len(param) >= 2:\n",
    "                    key = param[:2]  # Take first two characters as key\n",
    "                    value = param[2:]  # Take rest as value\n",
    "                    params[key] = value\n",
    "            \n",
    "            # Generate report\n",
    "            title = f\"Experiment Results\\n{dir_name}\"\n",
    "            summary = make_negative_binomial_report(exp_dir, title=title)\n",
    "            \n",
    "            if summary is not None:\n",
    "                # Add experiment parameters to summary\n",
    "                summary.update(params)\n",
    "                summary['exp_dir'] = exp_dir\n",
    "                summaries.append(summary)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {exp_dir}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    # Create summary DataFrame and save\n",
    "    if summaries:\n",
    "        summary_df = pd.DataFrame(summaries)\n",
    "        summary_df.to_csv(os.path.join(base_dir, 'all_experiments_summary.csv'), index=False)\n",
    "        \n",
    "        # Print best models according to different metrics\n",
    "        print(\"\\nBest Models:\")\n",
    "        print(\"\\nBy Best Validation BPR:\")\n",
    "        best_val_bpr_idx = summary_df['best_val_bpr'].idxmax()\n",
    "        print(summary_df.loc[best_val_bpr_idx, ['exp_dir', 'best_val_bpr', 'best_val_bpr_epoch']])\n",
    "        \n",
    "        print(\"\\nBy Best Validation NLL:\")\n",
    "        best_val_nll_idx = summary_df['min_val_nll'].idxmin()\n",
    "        print(summary_df.loc[best_val_nll_idx, ['exp_dir', 'min_val_nll', 'min_val_nll_epoch']])\n",
    "        \n",
    "        return summary_df\n",
    "    else:\n",
    "        print(\"No valid summaries generated\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Models:\n",
      "\n",
      "By Best Validation BPR:\n",
      "exp_dir               /cluster/tufts/hugheslab/kheuto01/opioid_grid_...\n",
      "best_val_bpr                                                   0.841167\n",
      "best_val_bpr_epoch                                                 3260\n",
      "Name: 40, dtype: object\n",
      "\n",
      "By Best Validation NLL:\n",
      "exp_dir              /cluster/tufts/hugheslab/kheuto01/opioid_grid_...\n",
      "min_val_nll                                                    1.40218\n",
      "min_val_nll_epoch                                                 1530\n",
      "Name: 46, dtype: object\n"
     ]
    }
   ],
   "source": [
    "results = generate_reports_for_all_experiments(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('~/code/prob_diff_topk/results22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['K100'], ['bw0'], ['nw1'], ['ss0.0001'], ['nss20'], ['nps20'], ['seed420']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.split('_') for param in os.path.basename('/cluster/tufts/hugheslab/kheuto01/neg_binom_experiments_K100_8000/K100_bw0_nw1_ss0.0001_nss20_nps20_seed420').split('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
