{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "\n",
    "from distributions import ZeroInflatedDist, QuantizedNormal\n",
    "from torch_models import MixtureOfTruncNormModel, SpatialWaves\n",
    "from torch_training import train_epoch\n",
    "#from torch_perturb.torch_pert_topk import PerturbedTopK\n",
    "from torch_perturb.perturbations import perturbed\n",
    "import time\n",
    "from torch_training import train_epoch_largesynth, train_epoch_largesynth_loo\n",
    "from torch_models import torch_bpr_uncurried, deterministic_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_hot_indicator(x, k):\n",
    "\n",
    "    topk = torch.topk(x, k=k, dim=-1, sorted=False)\n",
    "    indices = topk.indices\n",
    "    # convert to k-hot indicator with onehot function\n",
    "    one_hot = torch.nn.functional.one_hot(indices, num_classes=x.shape[-1]).float()\n",
    "    #khot = torch.mean(one_hot, dim=-2)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_hot_indicator(torch.tensor([[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/cluster/home/kheuto01/code/prob_diff_topk'\n",
    "\n",
    "step_size=0.4\n",
    "perturbed_noise=0.00001\n",
    "K=25\n",
    "threshold=1\n",
    "rows=27\n",
    "cols=60\n",
    "data_shape=(rows, cols)\n",
    "deaths = pd.read_csv(os.path.join(data_dir,'deaths_band.csv'))\n",
    "pop = pd.read_csv(os.path.join(data_dir, 'pop_band.csv'))\n",
    "num_score_samples = 100\n",
    "num_pert_samples = 100\n",
    "bpr_weight=30\n",
    "nll_weight=0\n",
    "\n",
    "# turn the death column into a time-by-geoid array\n",
    "deaths_TS = deaths.pivot(index='time', columns='geoid', values='death').values\n",
    "pop_S = pop['pop'].values\n",
    "\n",
    "T, S = deaths_TS.shape\n",
    "# create latitude and longitude arrays corresponding to the row and column index of the geoids when reshaped into data_shape\n",
    "lat = np.linspace(-rows/2, rows/2, rows)\n",
    "lon = np.linspace(-cols/2, cols/2, cols)\n",
    "lat_S, lon_S = np.meshgrid(lon, lat)\n",
    "lat_S = lat_S.flatten()\n",
    "lon_S = lon_S.flatten()\n",
    "# create column of time values\n",
    "time_T = np.arange(deaths_TS.shape[0])\n",
    "time_T = torch.tensor(time_T, dtype=torch.float32)\n",
    "lat_S = torch.tensor(lat_S, dtype=torch.float32)\n",
    "lon_S = torch.tensor(lon_S, dtype=torch.float32)\n",
    "pop_S = torch.tensor(pop_S, dtype=torch.float32)\n",
    "deaths_TS = torch.tensor(deaths_TS, dtype=torch.float32)\n",
    "S = pop_S.shape[0]\n",
    "T = time_T.shape[0]\n",
    "\n",
    "\n",
    "model  = SpatialWaves(num_waves=1,low=0, high=1000000)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=step_size)\n",
    "\n",
    "M_score_func =  num_score_samples\n",
    "M_action = M_score_func\n",
    "\n",
    "top_k_func = partial(top_k_hot_indicator, k=K)\n",
    "perturbed_top_K_func = perturbed(top_k_func, sigma=perturbed_noise, num_samples=num_pert_samples)#PerturbedTopK(k=K, sigma=perturbed_noise, num_samples=num_pert_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_speed=torch.tensor([1.0], dtype=torch.float32)\n",
    "\n",
    "lon_coeff = torch.tensor([0.0,], dtype=torch.float32)\n",
    "lat_coeff = torch.tensor([-1.0], dtype=torch.float32)\n",
    "arrival_intercept = torch.tensor([lat_S.view(data_shape)[0,52]], dtype=torch.float32) \n",
    "mag=torch.tensor([0.005], dtype=torch.float32)\n",
    "width=torch.tensor([2.0], dtype=torch.float32)\n",
    "softinv_mags = mag + torch.log(-torch.expm1(-mag))\n",
    "softinv_widths = width + torch.log(-torch.expm1(-width))\n",
    "#model.update_params(torch.cat([arrival_speed, arrival_intercept, lat_coeff, lon_coeff, softinv_mags, softinv_widths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_S.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: WHERE IS THE DOUBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_speed.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = torch.mean(-dist.log_prob( torch.tensor(train_y_TS)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det bpr: 0.09417575597763062\n",
      "Pert bpr: 0.09409095346927643\n",
      "nll: 8.931434631347656\n",
      "Loss: -2.8227286338806152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kheuto01/code/prob_diff_topk/torch_training.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.1063835620880127\n",
      "Pert bpr: 0.10661066323518753\n",
      "nll: 11.188325881958008\n",
      "Loss: -3.198319911956787\n",
      "EPOCH: 2\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.11766377836465836\n",
      "Pert bpr: 0.11754552274942398\n",
      "nll: 10.730494499206543\n",
      "Loss: -3.5263657569885254\n",
      "EPOCH: 3\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.102779820561409\n",
      "Pert bpr: 0.1026943176984787\n",
      "nll: 12.689867973327637\n",
      "Loss: -3.080829620361328\n",
      "EPOCH: 4\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.09538255631923676\n",
      "Pert bpr: 0.09538920223712921\n",
      "nll: 17.261442184448242\n",
      "Loss: -2.861675977706909\n",
      "EPOCH: 5\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.09107986837625504\n",
      "Pert bpr: 0.09105180203914642\n",
      "nll: 19.95462417602539\n",
      "Loss: -2.7315540313720703\n",
      "EPOCH: 6\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08411472290754318\n",
      "Pert bpr: 0.08408990502357483\n",
      "nll: 20.639083862304688\n",
      "Loss: -2.5226972103118896\n",
      "EPOCH: 7\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08774969726800919\n",
      "Pert bpr: 0.08777478337287903\n",
      "nll: 15.88642692565918\n",
      "Loss: -2.6332435607910156\n",
      "EPOCH: 8\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0812070220708847\n",
      "Pert bpr: 0.0812230035662651\n",
      "nll: 12.3178071975708\n",
      "Loss: -2.436690092086792\n",
      "EPOCH: 9\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08153165876865387\n",
      "Pert bpr: 0.08155185729265213\n",
      "nll: 12.073355674743652\n",
      "Loss: -2.4465556144714355\n",
      "EPOCH: 10\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0816614180803299\n",
      "Pert bpr: 0.08164791762828827\n",
      "nll: 11.50598430633545\n",
      "Loss: -2.4494376182556152\n",
      "EPOCH: 11\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08236100524663925\n",
      "Pert bpr: 0.08237074315547943\n",
      "nll: 10.457098960876465\n",
      "Loss: -2.4711222648620605\n",
      "EPOCH: 12\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08147205412387848\n",
      "Pert bpr: 0.08138002455234528\n",
      "nll: 9.538455963134766\n",
      "Loss: -2.4414007663726807\n",
      "EPOCH: 13\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.08456575125455856\n",
      "Pert bpr: 0.08475232124328613\n",
      "nll: 8.818443298339844\n",
      "Loss: -2.542569637298584\n",
      "EPOCH: 14\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0835270881652832\n",
      "Pert bpr: 0.0835597813129425\n",
      "nll: 8.221610069274902\n",
      "Loss: -2.50679349899292\n",
      "EPOCH: 15\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0752846747636795\n",
      "Pert bpr: 0.07529771327972412\n",
      "nll: 7.870077610015869\n",
      "Loss: -2.2589313983917236\n",
      "EPOCH: 16\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.068686842918396\n",
      "Pert bpr: 0.06869558990001678\n",
      "nll: 7.601731777191162\n",
      "Loss: -2.0608677864074707\n",
      "EPOCH: 17\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07874428480863571\n",
      "Pert bpr: 0.0787954330444336\n",
      "nll: 7.38754940032959\n",
      "Loss: -2.363862991333008\n",
      "EPOCH: 18\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07926614582538605\n",
      "Pert bpr: 0.07933200150728226\n",
      "nll: 7.32578182220459\n",
      "Loss: -2.379960060119629\n",
      "EPOCH: 19\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0811137706041336\n",
      "Pert bpr: 0.08108082413673401\n",
      "nll: 7.1446733474731445\n",
      "Loss: -2.432424783706665\n",
      "EPOCH: 20\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07608465850353241\n",
      "Pert bpr: 0.07607217878103256\n",
      "nll: 7.211081504821777\n",
      "Loss: -2.282165288925171\n",
      "EPOCH: 21\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07388830929994583\n",
      "Pert bpr: 0.07386760413646698\n",
      "nll: 7.142979621887207\n",
      "Loss: -2.2160282135009766\n",
      "EPOCH: 22\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07165608555078506\n",
      "Pert bpr: 0.07192860543727875\n",
      "nll: 7.089905261993408\n",
      "Loss: -2.15785813331604\n",
      "EPOCH: 23\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0723336711525917\n",
      "Pert bpr: 0.07239186763763428\n",
      "nll: 7.078110694885254\n",
      "Loss: -2.1717560291290283\n",
      "EPOCH: 24\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07146439701318741\n",
      "Pert bpr: 0.07140669971704483\n",
      "nll: 7.063131809234619\n",
      "Loss: -2.1422009468078613\n",
      "EPOCH: 25\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07139913737773895\n",
      "Pert bpr: 0.0712905079126358\n",
      "nll: 7.047816753387451\n",
      "Loss: -2.1387152671813965\n",
      "EPOCH: 26\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07113801687955856\n",
      "Pert bpr: 0.07125256955623627\n",
      "nll: 7.029787063598633\n",
      "Loss: -2.1375770568847656\n",
      "EPOCH: 27\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.07124844938516617\n",
      "Pert bpr: 0.07071008533239365\n",
      "nll: 7.018404483795166\n",
      "Loss: -2.121302604675293\n",
      "EPOCH: 28\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06936681270599365\n",
      "Pert bpr: 0.0693146139383316\n",
      "nll: 7.0104827880859375\n",
      "Loss: -2.0794384479522705\n",
      "EPOCH: 29\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06694334745407104\n",
      "Pert bpr: 0.06686355173587799\n",
      "nll: 7.005640983581543\n",
      "Loss: -2.005906581878662\n",
      "EPOCH: 30\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06707720458507538\n",
      "Pert bpr: 0.06665566563606262\n",
      "nll: 6.993214130401611\n",
      "Loss: -1.9996700286865234\n",
      "EPOCH: 31\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06557536125183105\n",
      "Pert bpr: 0.06600131094455719\n",
      "nll: 6.988237380981445\n",
      "Loss: -1.980039358139038\n",
      "EPOCH: 32\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06650766730308533\n",
      "Pert bpr: 0.06653943657875061\n",
      "nll: 6.9765214920043945\n",
      "Loss: -1.996183156967163\n",
      "EPOCH: 33\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06604163348674774\n",
      "Pert bpr: 0.06650727987289429\n",
      "nll: 6.9784650802612305\n",
      "Loss: -1.9952183961868286\n",
      "EPOCH: 34\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06620016694068909\n",
      "Pert bpr: 0.06652159243822098\n",
      "nll: 6.967696189880371\n",
      "Loss: -1.9956477880477905\n",
      "EPOCH: 35\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06164753809571266\n",
      "Pert bpr: 0.0614684522151947\n",
      "nll: 6.943455219268799\n",
      "Loss: -1.8440535068511963\n",
      "EPOCH: 36\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06367184221744537\n",
      "Pert bpr: 0.06261588633060455\n",
      "nll: 6.974091529846191\n",
      "Loss: -1.878476619720459\n",
      "EPOCH: 37\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06360923498868942\n",
      "Pert bpr: 0.06416094303131104\n",
      "nll: 7.015614032745361\n",
      "Loss: -1.924828290939331\n",
      "EPOCH: 38\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06508534401655197\n",
      "Pert bpr: 0.06590816378593445\n",
      "nll: 7.005795955657959\n",
      "Loss: -1.9772448539733887\n",
      "EPOCH: 39\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06393372267484665\n",
      "Pert bpr: 0.06551606953144073\n",
      "nll: 6.997743129730225\n",
      "Loss: -1.9654821157455444\n",
      "EPOCH: 40\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.062428973615169525\n",
      "Pert bpr: 0.06261986494064331\n",
      "nll: 6.9800944328308105\n",
      "Loss: -1.8785959482192993\n",
      "EPOCH: 41\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06192631274461746\n",
      "Pert bpr: 0.06164911389350891\n",
      "nll: 6.984811305999756\n",
      "Loss: -1.849473476409912\n",
      "EPOCH: 42\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06368113309144974\n",
      "Pert bpr: 0.06359641253948212\n",
      "nll: 7.006423473358154\n",
      "Loss: -1.9078923463821411\n",
      "EPOCH: 43\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058293189853429794\n",
      "Pert bpr: 0.058934517204761505\n",
      "nll: 6.9845967292785645\n",
      "Loss: -1.7680355310440063\n",
      "EPOCH: 44\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06872457265853882\n",
      "Pert bpr: 0.06579229980707169\n",
      "nll: 6.976688861846924\n",
      "Loss: -1.973768949508667\n",
      "EPOCH: 45\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058479733765125275\n",
      "Pert bpr: 0.058751873672008514\n",
      "nll: 6.963833332061768\n",
      "Loss: -1.7625561952590942\n",
      "EPOCH: 46\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06199755519628525\n",
      "Pert bpr: 0.06167158484458923\n",
      "nll: 6.960092544555664\n",
      "Loss: -1.8501474857330322\n",
      "EPOCH: 47\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06467065960168839\n",
      "Pert bpr: 0.06307019293308258\n",
      "nll: 6.973210334777832\n",
      "Loss: -1.8921058177947998\n",
      "EPOCH: 48\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058828044682741165\n",
      "Pert bpr: 0.05930979922413826\n",
      "nll: 6.987183094024658\n",
      "Loss: -1.7792940139770508\n",
      "EPOCH: 49\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06111960485577583\n",
      "Pert bpr: 0.05976510047912598\n",
      "nll: 6.993253231048584\n",
      "Loss: -1.7929530143737793\n",
      "EPOCH: 50\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06044704467058182\n",
      "Pert bpr: 0.05927090346813202\n",
      "nll: 7.0012006759643555\n",
      "Loss: -1.7781270742416382\n",
      "EPOCH: 51\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06148901581764221\n",
      "Pert bpr: 0.06108623743057251\n",
      "nll: 7.007050514221191\n",
      "Loss: -1.8325871229171753\n",
      "EPOCH: 52\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05929027497768402\n",
      "Pert bpr: 0.059450551867485046\n",
      "nll: 7.011642932891846\n",
      "Loss: -1.783516526222229\n",
      "EPOCH: 53\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06047562509775162\n",
      "Pert bpr: 0.060406580567359924\n",
      "nll: 7.01772403717041\n",
      "Loss: -1.8121974468231201\n",
      "EPOCH: 54\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06180845946073532\n",
      "Pert bpr: 0.06141161546111107\n",
      "nll: 7.006959915161133\n",
      "Loss: -1.8423484563827515\n",
      "EPOCH: 55\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0598217248916626\n",
      "Pert bpr: 0.059608057141304016\n",
      "nll: 7.004814147949219\n",
      "Loss: -1.7882417440414429\n",
      "EPOCH: 56\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.057529859244823456\n",
      "Pert bpr: 0.057818230241537094\n",
      "nll: 7.041072368621826\n",
      "Loss: -1.7345468997955322\n",
      "EPOCH: 57\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058193664997816086\n",
      "Pert bpr: 0.05665075406432152\n",
      "nll: 7.067356109619141\n",
      "Loss: -1.699522614479065\n",
      "EPOCH: 58\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05508183315396309\n",
      "Pert bpr: 0.05480414256453514\n",
      "nll: 7.077923774719238\n",
      "Loss: -1.6441242694854736\n",
      "EPOCH: 59\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05199752375483513\n",
      "Pert bpr: 0.0535445399582386\n",
      "nll: 7.087090015411377\n",
      "Loss: -1.606336236000061\n",
      "EPOCH: 60\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05712495371699333\n",
      "Pert bpr: 0.05710695683956146\n",
      "nll: 7.078975200653076\n",
      "Loss: -1.7132086753845215\n",
      "EPOCH: 61\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.055514104664325714\n",
      "Pert bpr: 0.056009069085121155\n",
      "nll: 7.0658440589904785\n",
      "Loss: -1.680272102355957\n",
      "EPOCH: 62\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05739990249276161\n",
      "Pert bpr: 0.05658513680100441\n",
      "nll: 7.051093578338623\n",
      "Loss: -1.697554111480713\n",
      "EPOCH: 63\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05732327699661255\n",
      "Pert bpr: 0.05741535872220993\n",
      "nll: 7.022488594055176\n",
      "Loss: -1.7224607467651367\n",
      "EPOCH: 64\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.054824165999889374\n",
      "Pert bpr: 0.05587077513337135\n",
      "nll: 6.987939834594727\n",
      "Loss: -1.6761232614517212\n",
      "EPOCH: 65\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05742322653532028\n",
      "Pert bpr: 0.057409413158893585\n",
      "nll: 6.982398509979248\n",
      "Loss: -1.7222824096679688\n",
      "EPOCH: 66\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06042394042015076\n",
      "Pert bpr: 0.060032278299331665\n",
      "nll: 6.959066867828369\n",
      "Loss: -1.8009684085845947\n",
      "EPOCH: 67\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05643017590045929\n",
      "Pert bpr: 0.057465143501758575\n",
      "nll: 6.946498870849609\n",
      "Loss: -1.7239543199539185\n",
      "EPOCH: 68\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06377050280570984\n",
      "Pert bpr: 0.0627761259675026\n",
      "nll: 6.927636623382568\n",
      "Loss: -1.8832837343215942\n",
      "EPOCH: 69\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06250163912773132\n",
      "Pert bpr: 0.06243812292814255\n",
      "nll: 6.935199737548828\n",
      "Loss: -1.8731436729431152\n",
      "EPOCH: 70\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.059431806206703186\n",
      "Pert bpr: 0.0595695823431015\n",
      "nll: 6.939435005187988\n",
      "Loss: -1.7870874404907227\n",
      "EPOCH: 71\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05582410469651222\n",
      "Pert bpr: 0.055453550070524216\n",
      "nll: 6.947046756744385\n",
      "Loss: -1.6636065244674683\n",
      "EPOCH: 72\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0576242133975029\n",
      "Pert bpr: 0.05760922655463219\n",
      "nll: 6.9474406242370605\n",
      "Loss: -1.7282768487930298\n",
      "EPOCH: 73\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0584445521235466\n",
      "Pert bpr: 0.05727745592594147\n",
      "nll: 6.977602958679199\n",
      "Loss: -1.7183237075805664\n",
      "EPOCH: 74\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06391289830207825\n",
      "Pert bpr: 0.0617404580116272\n",
      "nll: 6.9802422523498535\n",
      "Loss: -1.852213740348816\n",
      "EPOCH: 75\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.056490663439035416\n",
      "Pert bpr: 0.056059595197439194\n",
      "nll: 6.989134788513184\n",
      "Loss: -1.6817878484725952\n",
      "EPOCH: 76\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06433793157339096\n",
      "Pert bpr: 0.06359272450208664\n",
      "nll: 6.9621262550354\n",
      "Loss: -1.907781720161438\n",
      "EPOCH: 77\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05421896278858185\n",
      "Pert bpr: 0.05340804532170296\n",
      "nll: 7.013427734375\n",
      "Loss: -1.6022413969039917\n",
      "EPOCH: 78\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05970757082104683\n",
      "Pert bpr: 0.060496509075164795\n",
      "nll: 6.989092826843262\n",
      "Loss: -1.8148952722549438\n",
      "EPOCH: 79\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05717144161462784\n",
      "Pert bpr: 0.05651979148387909\n",
      "nll: 7.005560874938965\n",
      "Loss: -1.6955937147140503\n",
      "EPOCH: 80\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05897318944334984\n",
      "Pert bpr: 0.05808354169130325\n",
      "nll: 7.004981517791748\n",
      "Loss: -1.7425062656402588\n",
      "EPOCH: 81\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.057810403406620026\n",
      "Pert bpr: 0.056513577699661255\n",
      "nll: 6.9875807762146\n",
      "Loss: -1.6954073905944824\n",
      "EPOCH: 82\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058978740125894547\n",
      "Pert bpr: 0.059714626520872116\n",
      "nll: 7.002991676330566\n",
      "Loss: -1.7914388179779053\n",
      "EPOCH: 83\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05770566686987877\n",
      "Pert bpr: 0.05738568305969238\n",
      "nll: 7.017988681793213\n",
      "Loss: -1.7215704917907715\n",
      "EPOCH: 84\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05239367485046387\n",
      "Pert bpr: 0.05427078902721405\n",
      "nll: 7.033828258514404\n",
      "Loss: -1.6281236410140991\n",
      "EPOCH: 85\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05948847532272339\n",
      "Pert bpr: 0.06078989803791046\n",
      "nll: 7.045709609985352\n",
      "Loss: -1.8236969709396362\n",
      "EPOCH: 86\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.058901332318782806\n",
      "Pert bpr: 0.05798621475696564\n",
      "nll: 7.044591903686523\n",
      "Loss: -1.7395864725112915\n",
      "EPOCH: 87\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.055513761937618256\n",
      "Pert bpr: 0.05590067058801651\n",
      "nll: 7.034119606018066\n",
      "Loss: -1.6770200729370117\n",
      "EPOCH: 88\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.053933147341012955\n",
      "Pert bpr: 0.0545191653072834\n",
      "nll: 7.073678493499756\n",
      "Loss: -1.6355749368667603\n",
      "EPOCH: 89\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.0607038252055645\n",
      "Pert bpr: 0.060065701603889465\n",
      "nll: 7.0567450523376465\n",
      "Loss: -1.8019710779190063\n",
      "EPOCH: 90\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05832856893539429\n",
      "Pert bpr: 0.05822541564702988\n",
      "nll: 7.052272796630859\n",
      "Loss: -1.7467625141143799\n",
      "EPOCH: 91\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05339309200644493\n",
      "Pert bpr: 0.053641654551029205\n",
      "nll: 7.100619792938232\n",
      "Loss: -1.6092495918273926\n",
      "EPOCH: 92\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.059598393738269806\n",
      "Pert bpr: 0.058690764009952545\n",
      "nll: 7.0715203285217285\n",
      "Loss: -1.7607228755950928\n",
      "EPOCH: 93\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05647154152393341\n",
      "Pert bpr: 0.057737935334444046\n",
      "nll: 7.049845218658447\n",
      "Loss: -1.7321380376815796\n",
      "EPOCH: 94\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.051365241408348083\n",
      "Pert bpr: 0.05154084414243698\n",
      "nll: 7.097332000732422\n",
      "Loss: -1.5462253093719482\n",
      "EPOCH: 95\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.04870320111513138\n",
      "Pert bpr: 0.049068860709667206\n",
      "nll: 7.148153781890869\n",
      "Loss: -1.472065806388855\n",
      "EPOCH: 96\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.06108477711677551\n",
      "Pert bpr: 0.05960753187537193\n",
      "nll: 7.124800682067871\n",
      "Loss: -1.7882260084152222\n",
      "EPOCH: 97\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05311726778745651\n",
      "Pert bpr: 0.0524948313832283\n",
      "nll: 7.2214202880859375\n",
      "Loss: -1.5748449563980103\n",
      "EPOCH: 98\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05433141812682152\n",
      "Pert bpr: 0.0543280653655529\n",
      "nll: 7.279514312744141\n",
      "Loss: -1.629841923713684\n",
      "EPOCH: 99\n",
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n",
      "det bpr: 0.05392177402973175\n",
      "Pert bpr: 0.052809495478868484\n",
      "nll: 7.364622592926025\n",
      "Loss: -1.5842849016189575\n"
     ]
    }
   ],
   "source": [
    "losses, bprs, nlls, times = [], [], [], []\n",
    "for epoch in range(100):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    start = time.time()\n",
    "    loss, bpr, nll, model = train_epoch_largesynth_loo(model, optimizer, K, threshold, T,\n",
    "                                        M_score_func, M_action,time_T,pop_S,\n",
    "                                        lat_S, lon_S, deaths_TS, \n",
    "                                        perturbed_top_K_func, bpr_weight, \n",
    "                                        nll_weight)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    losses.append(loss)\n",
    "    bprs.append(bpr)\n",
    "    nlls.append(nll)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_TS = deaths_TS\n",
    "update=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/autograd/profiler.py:228: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2024-09-11 13:57:23 158313:158313 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y_TS size: torch.Size([64, 1620])\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158313/1790547008.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
      "/tmp/ipykernel_158313/1790547008.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = torch.mean(-dist.log_prob( torch.tensor(train_y_TS)))\n",
      "STAGE:2024-09-11 13:57:25 158313:158313 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-09-11 13:57:25 158313:158313 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              loss calc         0.05%     895.000us        46.55%     878.043ms     878.043ms     181.14 Mb      -3.97 Mb             1  \n",
      "                                   jacobian calculation         0.41%       7.733ms        45.56%     859.399ms     859.399ms     338.26 Mb    -873.76 Mb             1  \n",
      "                                          PerturbedFunc         5.95%     112.246ms        42.44%     800.551ms     800.551ms      59.72 Mb      -1.47 Gb             1  \n",
      "                                              aten::sub         6.37%     120.107ms        37.60%     709.265ms      12.443ms       1.43 Gb     110.35 Mb            57  \n",
      "                                              aten::mul        15.58%     293.933ms        24.40%     460.337ms       2.692ms       1.03 Gb     559.09 Mb           171  \n",
      "                                            aten::copy_        23.80%     449.056ms        23.82%     449.395ms       1.783ms           0 b           0 b           252  \n",
      "                                         aten::_to_copy         0.07%       1.293ms        22.88%     431.589ms       1.876ms    1018.11 Mb     404.83 Kb           230  \n",
      "                                            aten::fill_        17.02%     321.023ms        17.02%     321.023ms       9.442ms           0 b           0 b            34  \n",
      "                                          aten::one_hot         0.00%      59.000us        15.49%     292.133ms     292.133ms     988.77 Mb          -8 b             1  \n",
      "                                            aten::zeros         0.01%     202.000us        15.33%     289.250ms       6.026ms     988.77 Mb           8 b            48  \n",
      "                                            aten::zero_         0.00%      13.000us        15.32%     288.905ms       5.896ms           0 b           0 b            49  \n",
      "                                              aten::div         5.79%     109.197ms        14.94%     281.762ms       6.709ms     460.77 Mb      50.23 Mb            42  \n",
      "                                               aten::to         0.04%     708.000us        13.39%     252.623ms       1.057ms     495.97 Mb           0 b           239  \n",
      "                                              aten::sum         8.18%     154.226ms         9.91%     186.949ms       6.924ms       5.17 Mb       2.79 Mb            27  \n",
      "                                             aten::mean         0.01%     208.000us         8.20%     154.604ms      25.767ms      22.94 Mb      22.94 Mb             6  \n",
      "                                              aten::add         2.15%      40.492ms         8.19%     154.537ms       2.493ms     387.92 Mb      72.08 Mb            62  \n",
      "                                              aten::pow         2.72%      51.220ms         7.68%     144.909ms       6.300ms     197.36 Mb      26.50 Mb            23  \n",
      "                                        model_inference         0.14%       2.598ms         7.17%     135.169ms     135.169ms      11.47 Mb     -10.41 Mb             1  \n",
      "                                         aten::uniform_         3.21%      60.635ms         3.21%      60.635ms      60.635ms           0 b           0 b             1  \n",
      "                                           aten::normal         1.47%      27.734ms         2.02%      38.138ms      38.138ms      19.78 Mb         -14 b             1  \n",
      "                                              aten::exp         1.77%      33.388ms         1.84%      34.627ms       3.463ms      11.07 Mb       3.96 Mb            10  \n",
      "                                              aten::neg         1.15%      21.644ms         1.22%      22.978ms     741.226us      32.83 Mb      23.34 Mb            31  \n",
      "                                           aten::erfinv         0.97%      18.324ms         0.97%      18.324ms      18.324ms      19.78 Mb      19.78 Mb             1  \n",
      "                                             aten::topk         0.86%      16.280ms         0.86%      16.280ms       8.140ms     956.25 Kb     956.25 Kb             2  \n",
      "                                               backward         0.05%     914.000us         0.63%      11.945ms      11.945ms     -62.10 Mb    -405.00 Kb             1  \n",
      "                                             aten::div_         0.49%       9.257ms         0.50%       9.424ms       1.346ms          24 b         -12 b             7  \n",
      "                                               aten::ge         0.46%       8.680ms         0.46%       8.735ms       1.456ms     405.01 Kb     404.99 Kb             6  \n",
      "                                              aten::min         0.13%       2.365ms         0.44%       8.306ms       2.769ms          16 b     -39.55 Mb             3  \n",
      "                                            aten::clone         0.00%      21.000us         0.33%       6.201ms       2.067ms      41.92 Mb           0 b             3  \n",
      "                                       aten::contiguous         0.00%       6.000us         0.31%       5.930ms       2.965ms      39.55 Mb           0 b             2  \n",
      "autograd::engine::evaluate_function: PerturbedFuncBa...         0.00%      17.000us         0.29%       5.539ms       5.539ms     -59.33 Mb     -59.72 Mb             1  \n",
      "                                  PerturbedFuncBackward         0.01%     160.000us         0.29%       5.522ms       5.522ms     405.00 Kb     -12.50 Kb             1  \n",
      "                                           aten::einsum         0.00%      81.000us         0.28%       5.306ms       2.653ms     417.50 Kb           0 b             2  \n",
      "                                              aten::bmm         0.27%       5.161ms         0.27%       5.161ms       2.580ms     417.50 Kb     417.50 Kb             2  \n",
      "                                              aten::erf         0.03%     600.000us         0.22%       4.153ms       1.038ms       7.91 Mb           0 b             4  \n",
      "                                         aten::scatter_         0.16%       3.042ms         0.16%       3.042ms       3.042ms           0 b           0 b             1  \n",
      "      autograd::engine::evaluate_function: ErfBackward0         0.00%      22.000us         0.15%       2.759ms       1.379ms    -810.00 Kb      -1.58 Mb             2  \n",
      "                                           ErfBackward0         0.00%      43.000us         0.15%       2.737ms       1.369ms     810.00 Kb      -3.16 Mb             2  \n",
      "                                             aten::add_         0.06%       1.181ms         0.13%       2.440ms     221.818us           0 b      -4.75 Mb            11  \n",
      "                                       aten::nan_to_num         0.02%     286.000us         0.12%       2.330ms     291.250us       6.53 Mb           0 b             8  \n",
      "                                        gradient update         0.00%      91.000us         0.10%       1.859ms       1.859ms       2.37 Mb           0 b             1  \n",
      "                                            aten::where         0.04%     752.000us         0.10%       1.803ms     225.375us       5.14 Mb     405.00 Kb             8  \n",
      "                                             prims::mul         0.07%       1.337ms         0.08%       1.486ms      57.154us         -40 b         -40 b            26  \n",
      "                                             prims::add         0.07%       1.264ms         0.07%       1.407ms      50.250us           0 b           0 b            28  \n",
      "                                    aten::empty_strided         0.07%       1.403ms         0.07%       1.403ms       5.945us    1021.67 Mb    1021.67 Mb           236  \n",
      "                                             aten::rsub         0.01%      97.000us         0.07%       1.330ms     332.500us       6.33 Mb          -4 b             4  \n",
      "                                        aten::clamp_min         0.01%     123.000us         0.07%       1.326ms     663.000us       3.26 Mb     810.00 Kb             2  \n",
      "                                             aten::mul_         0.06%       1.135ms         0.06%       1.135ms       1.135ms           0 b           0 b             1  \n",
      "                                              aten::log         0.02%     413.000us         0.05%     914.000us     228.500us       3.96 Mb       1.58 Mb             4  \n",
      "                                           aten::expand         0.03%     510.000us         0.04%     746.000us       4.494us           0 b           0 b           166  \n",
      "                                         aten::isfinite         0.00%      28.000us         0.04%     689.000us     344.500us     202.50 Kb      -1.19 Mb             2  \n",
      "      autograd::engine::evaluate_function: MulBackward0         0.00%      87.000us         0.04%     667.000us      47.643us        -548 b      -3.57 Mb            14  \n",
      "      autograd::engine::evaluate_function: DivBackward0         0.00%      13.000us         0.03%     529.000us     105.800us    -405.25 Kb      -2.37 Mb             5  \n",
      "                                           MulBackward0         0.00%      45.000us         0.03%     513.000us      36.643us       3.57 Mb         244 b            14  \n",
      "                                             aten::view         0.02%     470.000us         0.02%     470.000us       4.434us           0 b           0 b           106  \n",
      "                                           DivBackward0         0.00%      61.000us         0.02%     440.000us      88.000us       1.98 Mb    -810.00 Kb             5  \n",
      "                                            aten::stack         0.00%      32.000us         0.02%     412.000us     137.333us       2.37 Mb           0 b             3  \n",
      "                                              aten::cat         0.02%     388.000us         0.02%     399.000us      99.750us       2.37 Mb       2.37 Mb             4  \n",
      "                                         aten::softplus         0.01%     109.000us         0.02%     362.000us      90.500us          64 b          12 b             4  \n",
      "      autograd::engine::evaluate_function: PowBackward0         0.00%      19.000us         0.02%     356.000us     178.000us    -810.00 Kb      -1.58 Mb             2  \n",
      "                                           PowBackward0         0.00%      20.000us         0.02%     337.000us     168.500us     810.00 Kb      -1.58 Mb             2  \n",
      "                                               aten::ne         0.02%     309.000us         0.02%     326.000us     163.000us     202.50 Kb     202.49 Kb             2  \n",
      "                                       aten::_fw_primal         0.01%     268.000us         0.02%     325.000us       5.328us           0 b           0 b            61  \n",
      "                                aten::softplus_backward         0.01%     171.000us         0.02%     310.000us      19.375us         108 b          12 b            16  \n",
      "                                   aten::empty_permuted         0.01%     234.000us         0.02%     292.000us       5.407us           0 b           0 b            54  \n",
      "      autograd::engine::evaluate_function: SubBackward0         0.00%      45.000us         0.02%     290.000us      36.250us       6.58 Kb      -2.37 Mb             8  \n",
      "                                            aten::empty         0.01%     276.000us         0.01%     276.000us       2.107us       1.02 Gb       1.02 Gb           131  \n",
      "                                              aten::abs         0.01%     124.000us         0.01%     234.000us      58.500us       1.58 Mb     810.00 Kb             4  \n",
      "autograd::engine::evaluate_function: ClampMinBackwar...         0.00%      10.000us         0.01%     209.000us     209.000us    -405.00 Kb    -810.00 Kb             1  \n",
      "                                      ClampMinBackward0         0.00%      13.000us         0.01%     199.000us     199.000us     405.00 Kb    -101.25 Kb             1  \n",
      "                                       aten::as_strided         0.01%     193.000us         0.01%     193.000us       0.617us           0 b           0 b           313  \n",
      "                                               aten::eq         0.01%     171.000us         0.01%     171.000us      57.000us     202.50 Kb     202.50 Kb             3  \n",
      "                                            aten::slice         0.01%     126.000us         0.01%     163.000us       8.150us           0 b           0 b            20  \n",
      "                                           SubBackward0         0.00%      17.000us         0.01%     162.000us      20.250us       2.37 Mb           0 b             8  \n",
      "     autograd::engine::evaluate_function: MeanBackward0         0.00%       8.000us         0.01%     150.000us      75.000us     405.24 Kb          -8 b             2  \n",
      "                                          MeanBackward0         0.00%      12.000us         0.01%     142.000us      71.000us     405.25 Kb         -16 b             2  \n",
      "                                           aten::select         0.01%     135.000us         0.01%     137.000us       4.152us           0 b           0 b            33  \n",
      "                                          aten::permute         0.01%      99.000us         0.01%     126.000us       8.400us           0 b           0 b            15  \n",
      "      autograd::engine::evaluate_function: ExpBackward0         0.00%       6.000us         0.01%     110.000us     110.000us    -405.00 Kb    -810.00 Kb             1  \n",
      "                                        aten::unsqueeze         0.00%      91.000us         0.01%     106.000us       5.579us           0 b           0 b            19  \n",
      "                                           ExpBackward0         0.00%       5.000us         0.01%     104.000us     104.000us     405.00 Kb           0 b             1  \n",
      "                                          aten::reshape         0.00%      41.000us         0.00%      88.000us       7.333us           0 b           0 b            12  \n",
      "      autograd::engine::evaluate_function: NegBackward0         0.00%      21.000us         0.00%      82.000us      27.333us           0 b    -810.25 Kb             3  \n",
      "autograd::engine::evaluate_function: ExpandBackward0...         0.00%      20.000us         0.00%      82.000us      11.714us      -6.32 Kb     -12.68 Kb             7  \n",
      "                             aten::_efficientzerotensor         0.00%      77.000us         0.00%      77.000us       1.638us           0 b           0 b            47  \n",
      "      autograd::engine::evaluate_function: LogBackward0         0.00%       6.000us         0.00%      72.000us      72.000us           0 b    -405.00 Kb             1  \n",
      "                                           LogBackward0         0.00%       4.000us         0.00%      66.000us      66.000us     405.00 Kb           0 b             1  \n",
      "                                           NegBackward0         0.00%       6.000us         0.00%      61.000us      20.333us     810.25 Kb           0 b             3  \n",
      "                                            aten::alias         0.00%      59.000us         0.00%      59.000us       0.952us           0 b           0 b            62  \n",
      "                                        ExpandBackward0         0.00%      24.000us         0.00%      59.000us       8.429us       6.35 Kb           0 b             7  \n",
      "                                       aten::empty_like         0.00%      26.000us         0.00%      58.000us       8.286us      41.13 Mb      19.78 Mb             7  \n",
      "autograd::engine::evaluate_function: torch::autograd...         0.00%      15.000us         0.00%      51.000us       7.286us         -24 b          -4 b             7  \n",
      "     autograd::engine::evaluate_function: RsubBackward1         0.00%       5.000us         0.00%      44.000us      44.000us           0 b    -405.00 Kb             1  \n",
      "                                          RsubBackward1         0.00%       3.000us         0.00%      39.000us      39.000us     405.00 Kb           0 b             1  \n",
      "                        torch::autograd::AccumulateGrad         0.00%      23.000us         0.00%      36.000us       5.143us         -20 b         -20 b             7  \n",
      "                                aten::broadcast_tensors         0.00%      13.000us         0.00%      33.000us       6.600us           0 b           0 b             5  \n",
      "                                       aten::_make_dual         0.00%      29.000us         0.00%      32.000us      32.000us           0 b           0 b             1  \n",
      "      autograd::engine::evaluate_function: SumBackward1         0.00%       6.000us         0.00%      31.000us      15.500us           0 b           0 b             2  \n",
      "                                           aten::detach         0.00%      12.000us         0.00%      27.000us       9.000us           0 b           0 b             3  \n",
      "                                              aten::all         0.00%      17.000us         0.00%      26.000us      13.000us           2 b           2 b             2  \n",
      "                                           SumBackward1         0.00%       9.000us         0.00%      25.000us      12.500us           0 b           0 b             2  \n",
      "                                              aten::max         0.00%      23.000us         0.00%      24.000us      24.000us           8 b           0 b             1  \n",
      "      autograd::engine::evaluate_function: AddBackward0         0.00%      20.000us         0.00%      24.000us       4.000us           0 b           0 b             6  \n",
      "                                          aten::detach_         0.00%      21.000us         0.00%      23.000us       2.300us           0 b           0 b            10  \n",
      "                                             aten::item         0.00%      17.000us         0.00%      22.000us       3.667us          -8 b          -8 b             6  \n",
      "                                               aten::gt         0.00%      10.000us         0.00%      22.000us      22.000us           1 b          -3 b             1  \n",
      "                                          aten::view_as         0.00%       7.000us         0.00%      20.000us       6.667us           0 b           0 b             3  \n",
      "autograd::engine::evaluate_function: SoftplusBackwar...         0.00%       6.000us         0.00%      20.000us      10.000us           0 b          -8 b             2  \n",
      "                                        aten::new_zeros         0.00%      10.000us         0.00%      19.000us      19.000us         144 b           0 b             1  \n",
      "                                               aten::lt         0.00%      11.000us         0.00%      16.000us      16.000us          64 b          60 b             1  \n",
      "                                        aten::ones_like         0.00%       4.000us         0.00%      16.000us      16.000us           4 b           0 b             1  \n",
      "                                                 detach         0.00%      15.000us         0.00%      15.000us       5.000us           0 b           0 b             3  \n",
      "                                     aten::is_same_size         0.00%      14.000us         0.00%      14.000us       0.169us           0 b           0 b            83  \n",
      "                                     aten::_unpack_dual         0.00%       4.000us         0.00%      14.000us      14.000us           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.00%       6.000us         0.00%      14.000us       7.000us           0 b           0 b             2  \n",
      "                                      SoftplusBackward0         0.00%       5.000us         0.00%      14.000us       7.000us           8 b           0 b             2  \n",
      "                                 aten::split_with_sizes         0.00%      10.000us         0.00%      12.000us      12.000us           0 b           0 b             1  \n",
      "                                   aten::_reshape_alias         0.00%      12.000us         0.00%      12.000us       4.000us           0 b           0 b             3  \n",
      "                                           aten::narrow         0.00%       7.000us         0.00%      11.000us      11.000us           0 b           0 b             1  \n",
      "                                         aten::diagonal         0.00%       8.000us         0.00%      10.000us      10.000us           0 b           0 b             1  \n",
      "                                        aten::new_empty         0.00%       4.000us         0.00%       9.000us       9.000us         144 b           0 b             1  \n",
      "                                    aten::scalar_tensor         0.00%       7.000us         0.00%       7.000us       3.500us           8 b           8 b             2  \n",
      "                              aten::_local_scalar_dense         0.00%       5.000us         0.00%       5.000us       0.833us           0 b           0 b             6  \n",
      "                                   aten::_add_batch_dim         0.00%       4.000us         0.00%       4.000us       4.000us           0 b           0 b             1  \n",
      "                                           AddBackward0         0.00%       4.000us         0.00%       4.000us       0.667us           0 b           0 b             6  \n",
      "                                      aten::result_type         0.00%       3.000us         0.00%       3.000us       0.130us           0 b           0 b            23  \n",
      "                                                detach_         0.00%       2.000us         0.00%       2.000us       0.200us           0 b           0 b            10  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             8  \n",
      "                                     aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             6  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             2  \n",
      "                          aten::_has_same_storage_numel         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b            83  \n",
      "                                aten::_remove_batch_dim         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.886s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import profiler\n",
    "with profiler.profile(use_cuda=True, profile_memory=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        dist = model(time_T,pop_S, lat_S, lon_S)\n",
    "    with profiler.record_function(\"jacobian calculation\"):\n",
    "        y_sample_TMS = dist.sample((M_score_func,)).permute(1, 0, 2)\n",
    "        y_sample_action_TMS = y_sample_TMS\n",
    "\n",
    "        ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "        ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "        ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "        def get_log_probs_baked(param):\n",
    "            distribution = model.build_from_single_tensor(param, time_T, pop_S, lat_S, lon_S)\n",
    "            log_probs_TMS = distribution.log_prob(y_sample_TMS.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "\n",
    "            return log_probs_TMS\n",
    "\n",
    "        jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n",
    "    with profiler.record_function(\"loss calc\"):\n",
    "        \n",
    "        score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "        score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "        # get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "        print(f'train_y_TS size: {train_y_TS.shape}')\n",
    "        print(f'ratio_rating_TS size: {ratio_rating_TS.shape}')\n",
    "        positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "        if nll_weight>0:\n",
    "            bpr_threshold_diff_T = positive_bpr_T - threshold\n",
    "            violate_threshold_flag = bpr_threshold_diff_T < 0\n",
    "            negative_bpr_loss = torch.mean(-bpr_threshold_diff_T*violate_threshold_flag)\n",
    "        else:\n",
    "            negative_bpr_loss = torch.mean(-positive_bpr_T)\n",
    "\n",
    "        nll = torch.mean(-dist.log_prob( torch.tensor(train_y_TS)))\n",
    "\n",
    "        loss = bpr_weight*negative_bpr_loss + nll_weight*nll\n",
    "    with profiler.record_function(\"backward\"):\n",
    "        loss.backward()\n",
    "    with profiler.record_function(\"gradient update\"):\n",
    "        loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "        gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "        gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "        gradient_tuple = model.single_tensor_to_params(gradient_P)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.6183e+04, 0.0000e+00, 3.1380e+03, 0.0000e+00, 1.2090e+03,\n",
       "        0.0000e+00, 6.0500e+02, 0.0000e+00, 3.6800e+02, 0.0000e+00,\n",
       "        2.1400e+02, 0.0000e+00, 1.5000e+02, 5.2000e+01, 5.3000e+01,\n",
       "        1.3000e+01, 5.2000e+01, 3.0000e+00, 5.9000e+01, 2.0000e+00,\n",
       "        4.4000e+01, 1.9000e+01, 1.5000e+01, 0.0000e+00, 3.9000e+01,\n",
       "        0.0000e+00, 2.1000e+01, 1.0000e+01, 1.2000e+01, 1.4000e+01,\n",
       "        0.0000e+00, 1.0000e+00, 1.4000e+01, 0.0000e+00, 1.2000e+01,\n",
       "        4.0000e+00, 7.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00,\n",
       "        6.0000e+00, 7.0000e+00, 2.0000e+00, 6.0000e+00, 0.0000e+00,\n",
       "        6.0000e+00, 0.0000e+00, 4.0000e+00, 6.0000e+00, 3.0000e+00,\n",
       "        3.0000e+00, 4.0000e+00, 1.0000e+00, 3.0000e+00, 2.0000e+00,\n",
       "        4.0000e+00, 0.0000e+00, 6.0000e+00, 0.0000e+00, 8.0000e+00,\n",
       "        0.0000e+00, 7.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00,\n",
       "        8.0000e+00, 0.0000e+00, 4.0000e+00, 2.0000e+00, 8.0000e+00,\n",
       "        0.0000e+00, 7.0000e+00, 2.0000e+00, 4.0000e+00, 0.0000e+00,\n",
       "        5.0000e+00, 0.0000e+00, 1.0000e+01, 0.0000e+00, 9.0000e+00,\n",
       "        5.0000e+00, 2.0000e+00, 0.0000e+00, 8.0000e+00, 3.0000e+00,\n",
       "        0.0000e+00, 7.0000e+00, 1.4000e+01, 0.0000e+00, 1.0000e+00,\n",
       "        1.9000e+01, 1.3000e+01, 1.0000e+00, 5.0000e+00, 1.0000e+01,\n",
       "        0.0000e+00, 1.8000e+01, 1.7000e+01, 2.9000e+01, 1.0630e+03]),\n",
       " array([0.    , 0.0004, 0.0008, 0.0012, 0.0016, 0.002 , 0.0024, 0.0028,\n",
       "        0.0032, 0.0036, 0.004 , 0.0044, 0.0048, 0.0052, 0.0056, 0.006 ,\n",
       "        0.0064, 0.0068, 0.0072, 0.0076, 0.008 , 0.0084, 0.0088, 0.0092,\n",
       "        0.0096, 0.01  , 0.0104, 0.0108, 0.0112, 0.0116, 0.012 , 0.0124,\n",
       "        0.0128, 0.0132, 0.0136, 0.014 , 0.0144, 0.0148, 0.0152, 0.0156,\n",
       "        0.016 , 0.0164, 0.0168, 0.0172, 0.0176, 0.018 , 0.0184, 0.0188,\n",
       "        0.0192, 0.0196, 0.02  , 0.0204, 0.0208, 0.0212, 0.0216, 0.022 ,\n",
       "        0.0224, 0.0228, 0.0232, 0.0236, 0.024 , 0.0244, 0.0248, 0.0252,\n",
       "        0.0256, 0.026 , 0.0264, 0.0268, 0.0272, 0.0276, 0.028 , 0.0284,\n",
       "        0.0288, 0.0292, 0.0296, 0.03  , 0.0304, 0.0308, 0.0312, 0.0316,\n",
       "        0.032 , 0.0324, 0.0328, 0.0332, 0.0336, 0.034 , 0.0344, 0.0348,\n",
       "        0.0352, 0.0356, 0.036 , 0.0364, 0.0368, 0.0372, 0.0376, 0.038 ,\n",
       "        0.0384, 0.0388, 0.0392, 0.0396, 0.04  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(perturbed_top_K_func(ratio_rating_TS).detach().numpy().flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-09-10 15:42:00 33778:33778 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y_TS size: (64, 1620)\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-09-10 15:42:32 33778:33778 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-09-10 15:42:32 33778:33778 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import profiler\n",
    "optimizer.zero_grad()\n",
    "with torch.profiler.profile(profile_memory=True,\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "    ]\n",
    ") as p:\n",
    "        dist = model(time_T,pop_S, lat_S, lon_S)\n",
    "\n",
    "        y_sample_TMS = dist.sample((M_score_func,)).permute(1, 0, 2)\n",
    "        y_sample_action_TMS = y_sample_TMS\n",
    "\n",
    "        ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "        ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "        ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "        def get_log_probs_baked(param):\n",
    "            distribution = model.build_from_single_tensor(param, time_T, pop_S, lat_S, lon_S)\n",
    "            log_probs_TMS = distribution.log_prob(y_sample_TMS.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "\n",
    "            return log_probs_TMS\n",
    "\n",
    "        jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n",
    "\n",
    "        \n",
    "        score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "        score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "        # get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "        print(f'train_y_TS size: {train_y_TS.shape}')\n",
    "        print(f'ratio_rating_TS size: {ratio_rating_TS.shape}')\n",
    "        positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "        if nll_weight>0:\n",
    "            bpr_threshold_diff_T = positive_bpr_T - threshold\n",
    "            violate_threshold_flag = bpr_threshold_diff_T < 0\n",
    "            negative_bpr_loss = torch.mean(-bpr_threshold_diff_T*violate_threshold_flag)\n",
    "        else:\n",
    "            negative_bpr_loss = torch.mean(-positive_bpr_T)\n",
    "\n",
    "        nll = torch.mean(-dist.log_prob( torch.tensor(train_y_TS)))\n",
    "\n",
    "        loss = bpr_weight*negative_bpr_loss + nll_weight*nll\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "        gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "        gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "        gradient_tuple = model.single_tensor_to_params(gradient_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                         aten::softplus         0.00%     112.000us         0.00%     319.000us      79.750us         128 b          32 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us      -1.77 Gb      -1.77 Gb           250  \n",
      "                                              aten::add         0.17%      49.527ms         0.85%     242.356ms       3.909ms     775.84 Mb     104.61 Mb            62  \n",
      "                                           aten::expand         0.00%     422.000us         0.00%     605.000us       3.667us           0 b           0 b           165  \n",
      "                                       aten::as_strided         0.00%     214.000us         0.00%     214.000us       0.673us           0 b           0 b           318  \n",
      "                                        aten::unsqueeze         0.00%     121.000us         0.00%     152.000us       6.909us           0 b           0 b            22  \n",
      "                                              aten::mul        14.67%        4.176s        15.79%        4.496s      26.137ms      17.68 Gb      16.68 Gb           172  \n",
      "                                               aten::to         0.00%     867.000us         0.74%     209.320ms       1.131ms     578.78 Mb       1.58 Mb           185  \n",
      "                                         aten::_to_copy         0.00%       1.130ms         1.64%     467.480ms       2.555ms       1.59 Gb       5.58 Mb           183  \n",
      "                                    aten::empty_strided         0.00%     680.000us         0.00%     680.000us       3.598us       1.59 Gb       1.59 Gb           189  \n",
      "                                            aten::copy_        15.30%        4.357s        15.30%        4.358s      21.257ms           0 b           0 b           205  \n",
      "                                              aten::sub         0.53%     149.652ms         3.38%     961.805ms      16.874ms       2.85 Gb     220.69 Mb            57  \n",
      "                                              aten::div        26.52%        7.550s        27.27%        7.764s     176.457ms      32.19 Gb      31.38 Gb            44  \n",
      "                                              aten::pow         0.06%      17.192ms         0.50%     142.617ms       6.201ms     394.72 Mb      53.00 Mb            23  \n",
      "                                      aten::result_type         0.00%      19.000us         0.00%      19.000us       0.826us           0 b           0 b            23  \n",
      "                                              aten::neg         0.03%       8.217ms         0.04%      10.780ms     347.742us      65.66 Mb      46.67 Mb            31  \n",
      "                                              aten::exp         0.04%      11.279ms         0.05%      13.768ms       1.377ms      22.15 Mb       7.91 Mb            10  \n",
      "                                              aten::sum         0.38%     107.109ms         0.39%     109.669ms       4.062ms      11.52 Mb       6.77 Mb            27  \n",
      "                                            aten::fill_         0.76%     217.678ms         0.76%     217.678ms       6.802ms           0 b           0 b            32  \n",
      "                                            aten::empty         0.00%     299.000us         0.00%     299.000us       2.336us      16.66 Gb      16.66 Gb           128  \n",
      "                                       aten::lift_fresh         0.00%       6.000us         0.00%       6.000us       0.750us           0 b           0 b             8  \n",
      "                                          aten::detach_         0.00%      24.000us         0.00%      28.000us       3.500us           0 b           0 b             8  \n",
      "                                                detach_         0.00%       4.000us         0.00%       4.000us       0.500us           0 b           0 b             8  \n",
      "                                aten::broadcast_tensors         0.00%      15.000us         0.00%      33.000us       8.250us           0 b           0 b             4  \n",
      "                                               aten::ge         0.00%     530.000us         0.00%     530.000us     132.500us     405.01 Kb     405.01 Kb             4  \n",
      "                                             aten::view         0.00%     585.000us         0.00%     585.000us       6.094us           0 b           0 b            96  \n",
      "                                     aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             6  \n",
      "                                      aten::resolve_neg         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b             2  \n",
      "                                              aten::erf         0.00%     932.000us         0.02%       5.552ms       1.388ms      15.82 Mb           0 b             4  \n",
      "                                        aten::clamp_min         0.00%     272.000us         0.01%       1.642ms     821.000us       6.43 Mb       1.58 Mb             2  \n",
      "                                              aten::log         0.00%     864.000us         0.01%       1.807ms     451.750us       7.91 Mb       3.16 Mb             4  \n",
      "                                       aten::nan_to_num         0.00%     482.000us         0.01%       3.710ms     463.750us      12.85 Mb           0 b             8  \n",
      "                                       aten::empty_like         0.00%      31.000us         0.00%     131.000us      18.714us      15.66 Gb           0 b             7  \n",
      "                                             aten::rsub         0.00%     139.000us         0.03%       9.328ms       2.332ms      12.66 Mb           0 b             4  \n",
      "                                             aten::add_         0.00%     955.000us         0.01%       3.770ms     942.500us           0 b      -9.49 Mb             4  \n",
      "                                         aten::uniform_         0.12%      33.904ms         0.12%      33.904ms      33.904ms           0 b           0 b             1  \n",
      "                                           aten::erfinv         0.05%      14.666ms         0.05%      14.666ms      14.666ms      39.55 Mb      39.55 Mb             1  \n",
      "                                          aten::permute         0.00%     146.000us         0.00%     192.000us      12.800us           0 b           0 b            15  \n",
      "                                             aten::mean         0.00%     223.000us         0.37%     104.956ms      20.991ms      15.42 Mb      15.42 Mb             5  \n",
      "                                             aten::div_         0.00%       1.294ms         0.00%       1.422ms     284.400us          24 b         -12 b             5  \n",
      "                                              aten::cat         0.00%     432.000us         0.00%     443.000us     110.750us       4.75 Mb       4.75 Mb             4  \n",
      "                                        aten::new_zeros         0.00%      10.000us         0.00%      19.000us      19.000us         288 b           0 b             1  \n",
      "                                        aten::new_empty         0.00%       6.000us         0.00%       8.000us       8.000us         288 b         288 b             1  \n",
      "                                            aten::zero_         0.00%      19.000us         0.76%     216.017ms       4.409ms           0 b           0 b            49  \n",
      "                                         aten::diagonal         0.00%       8.000us         0.00%      11.000us      11.000us           0 b           0 b             1  \n",
      "                                   aten::_add_batch_dim         0.00%       4.000us         0.00%       4.000us       4.000us           0 b           0 b             1  \n",
      "                                          aten::view_as         0.00%       2.000us         0.00%       8.000us       8.000us           0 b           0 b             1  \n",
      "                                       aten::_make_dual         0.00%      25.000us         0.00%      29.000us      29.000us           0 b           0 b             1  \n",
      "                                            aten::alias         0.00%      86.000us         0.00%      86.000us       1.387us           0 b           0 b            62  \n",
      "                                     aten::is_same_size         0.00%      19.000us         0.00%      19.000us       0.229us           0 b           0 b            83  \n",
      "                          aten::_has_same_storage_numel         0.00%       0.000us         0.00%       0.000us       0.000us           0 b           0 b            83  \n",
      "                                            aten::slice         0.00%     130.000us         0.00%     162.000us       7.714us           0 b           0 b            21  \n",
      "                                       aten::_fw_primal         0.00%     294.000us         0.00%     377.000us       6.180us           0 b           0 b            61  \n",
      "                                aten::softplus_backward         0.00%     153.000us         0.00%     264.000us      16.500us         208 b          16 b            16  \n",
      "                                           aten::select         0.00%     137.000us         0.00%     139.000us       4.212us           0 b           0 b            33  \n",
      "                                            aten::stack         0.00%      32.000us         0.00%     455.000us     151.667us       4.75 Mb           0 b             3  \n",
      "                             aten::_efficientzerotensor         0.00%      81.000us         0.00%      81.000us       1.723us           0 b           0 b            47  \n",
      "                                            aten::zeros         0.00%     171.000us         0.76%     216.321ms       4.507ms     988.77 Mb          32 b            48  \n",
      "                                             prims::add         0.00%       1.145ms         0.00%       1.251ms      44.679us           0 b           0 b            28  \n",
      "                                   aten::empty_permuted         0.00%     203.000us         0.00%     253.000us       4.685us           0 b           0 b            54  \n",
      "                                             prims::mul         0.00%       1.299ms         0.01%       1.446ms      55.615us         -48 b         -48 b            26  \n",
      "                                    aten::scalar_tensor         0.00%      13.000us         0.00%      13.000us       6.500us          16 b          16 b             2  \n",
      "                                            aten::where         0.00%     868.000us         0.01%       2.048ms     256.000us      10.28 Mb     810.00 Kb             8  \n",
      "                                           aten::narrow         0.00%       7.000us         0.00%      11.000us      11.000us           0 b           0 b             1  \n",
      "                                         aten::isfinite         0.00%      39.000us         0.00%     730.000us     365.000us     202.50 Kb      -1.88 Mb             2  \n",
      "                                              aten::abs         0.00%     199.000us         0.00%     380.000us      95.000us       3.16 Mb       1.58 Mb             4  \n",
      "                                               aten::ne         0.00%     229.000us         0.00%     229.000us     114.500us     202.50 Kb     202.50 Kb             2  \n",
      "                                               aten::eq         0.00%     211.000us         0.00%     211.000us     105.500us     202.50 Kb     202.50 Kb             2  \n",
      "                                            aten::clone         0.00%      44.000us        13.63%        3.880s        1.293s      15.66 Gb           0 b             3  \n",
      "                                     aten::_unpack_dual         0.00%       3.000us         0.00%      14.000us      14.000us           0 b           0 b             1  \n",
      "                                aten::_remove_batch_dim         0.00%       1.000us         0.00%       1.000us       1.000us           0 b           0 b             1  \n",
      "                                 aten::split_with_sizes         0.00%      12.000us         0.00%      13.000us      13.000us           0 b           0 b             1  \n",
      "                                          aten::reshape         0.00%      76.000us        13.63%        3.880s     775.916ms      15.65 Gb           0 b             5  \n",
      "                                   aten::_reshape_alias         0.00%      10.000us         0.00%      10.000us       5.000us           0 b           0 b             2  \n",
      "                                  PerturbedTopKFunction         0.27%      76.136ms         2.14%     608.343ms     608.343ms     524.05 Mb      -1.03 Gb             1  \n",
      "                                           aten::normal         0.00%      15.000us         0.11%      30.304ms      30.304ms      19.78 Mb           0 b             1  \n",
      "                                          aten::normal_         0.11%      30.276ms         0.11%      30.276ms      30.276ms           0 b           0 b             1  \n",
      "                                             aten::topk         0.06%      17.973ms         0.06%      17.973ms       8.986ms       1.25 Mb       1.25 Mb             2  \n",
      "                                             aten::sort         0.00%       1.025ms         0.00%       1.286ms       1.286ms       1.22 Mb       1.22 Mb             1  \n",
      "                                           aten::arange         0.00%      26.000us         0.00%      54.000us      27.000us         400 b           0 b             2  \n",
      "                                          aten::resize_         0.00%       5.000us         0.00%       5.000us       5.000us         200 b         200 b             1  \n",
      "                                          aten::one_hot         0.00%      65.000us         0.77%     218.472ms     218.472ms     988.77 Mb         -16 b             1  \n",
      "                                              aten::min         0.00%      57.000us         0.00%      61.000us      61.000us           8 b           0 b             1  \n",
      "                                             aten::item         0.00%       7.000us         0.00%       9.000us       4.500us           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.00%       2.000us         0.00%       2.000us       1.000us           0 b           0 b             2  \n",
      "                                              aten::max         0.00%      23.000us         0.00%      24.000us      24.000us           8 b           0 b             1  \n",
      "                                         aten::scatter_         0.01%       2.259ms         0.01%       2.259ms       2.259ms           0 b           0 b             1  \n",
      "                                               aten::lt         0.00%      14.000us         0.00%      22.000us      22.000us          64 b          56 b             1  \n",
      "                                        aten::ones_like         0.00%      10.000us         0.00%      32.000us      32.000us           8 b           0 b             1  \n",
      "      autograd::engine::evaluate_function: AddBackward0         0.00%      26.000us         0.00%      31.000us       5.167us           0 b           0 b             6  \n",
      "                                           AddBackward0         0.00%       5.000us         0.00%       5.000us       0.833us           0 b           0 b             6  \n",
      "      autograd::engine::evaluate_function: MulBackward0         0.00%      66.000us         0.00%       1.267ms      90.500us    -406.02 Kb      -7.94 Mb            14  \n",
      "                                           MulBackward0         0.00%     121.000us         0.00%       1.000ms      71.429us       7.14 Mb     -13.16 Kb            14  \n",
      "     autograd::engine::evaluate_function: MeanBackward0         0.00%       8.000us         0.00%     218.000us     109.000us     810.48 Kb         -16 b             2  \n",
      "                                          MeanBackward0         0.00%      12.000us         0.00%     210.000us     105.000us     810.50 Kb           0 b             2  \n",
      "      autograd::engine::evaluate_function: NegBackward0         0.00%      14.000us         0.00%     168.000us      56.000us           0 b      -1.58 Mb             3  \n",
      "                                           NegBackward0         0.00%       7.000us         0.00%     154.000us      51.333us       1.58 Mb           0 b             3  \n",
      "      autograd::engine::evaluate_function: SubBackward0         0.00%      61.000us         0.00%     639.000us      79.875us    -796.84 Kb      -5.54 Mb             8  \n",
      "                                           SubBackward0         0.00%      22.000us         0.00%     345.000us      43.125us       4.75 Mb           0 b             8  \n",
      "      autograd::engine::evaluate_function: PowBackward0         0.00%      23.000us         0.00%     633.000us     316.500us      -1.58 Mb      -3.16 Mb             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 28.474s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p.key_averages().table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'profile' object has no attribute 'events'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevents\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'profile' object has no attribute 'events'"
     ]
    }
   ],
   "source": [
    "prof.events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nCppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_kheuto01/jx/cjxsoagrmkidzkunygyxu3rchf4elvvcoicae6bthfbiteejr4vc.cpp -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -Wno-unknown-pragmas -D_GLIBCXX_USE_CXX11_ABI=0 -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/TH -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/THC -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/include/python3.11 -L/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/lib -lgomp -lc10 -O3 -DNDEBUG -ffast-math -fno-finite-math-only -fno-unsafe-math-optimizations -ffp-contract=off -march=native -fopenmp -D C10_USING_CUSTOM_GENERATED_MACROS -o /tmp/torchinductor_kheuto01/jx/cjxsoagrmkidzkunygyxu3rchf4elvvcoicae6bthfbiteejr4vc.so\n\nOutput:\ng++: error: unrecognized command line option -std=c++17\n\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 2\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_T\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpop_S\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_S\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon_S\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_sample_TMS \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample((M_score_func,))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m y_sample_action_TMS \u001b[38;5;241m=\u001b[39m y_sample_TMS\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:921\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_entry, hooks, frame_state)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:786\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    784\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:400\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    386\u001b[0m compile_id \u001b[38;5;241m=\u001b[39m CompileId(frame_id, frame_compile_id)\n\u001b[1;32m    388\u001b[0m signpost_event(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_frame_assert._compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     },\n\u001b[1;32m    398\u001b[0m )\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:676\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[1;32m    674\u001b[0m fail_user_frame_lineno: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m     guarded_code \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    679\u001b[0m     Unsupported,\n\u001b[1;32m    680\u001b[0m     TorchRuntimeError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m     BisectValidationException,\n\u001b[1;32m    688\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:535\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    533\u001b[0m CompileContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mattempt \u001b[38;5;241m=\u001b[39m attempt\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mRestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py:1036\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1033\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m   1034\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1036\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:165\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m cleanup \u001b[38;5;241m=\u001b[39m setup_compile_debug()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:500\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[0;32m--> 500\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[1;32m    502\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2149\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2149\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:810\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 810\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m     ):\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:773\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    770\u001b[0m     TracingContext\u001b[38;5;241m.\u001b[39mset_current_loc(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_filename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[1;32m    772\u001b[0m     )\n\u001b[0;32m--> 773\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:484\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m speculation\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m speculation\u001b[38;5;241m.\u001b[39mreason \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_graph_break\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeculation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreason\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     TracingContext\u001b[38;5;241m.\u001b[39mset_current_loc(\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_filename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[1;32m    488\u001b[0m     )\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:548\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.handle_graph_break\u001b[0;34m(self, inst, reason)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_graph_break\u001b[39m(\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructionTranslatorBase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m     inst: Instruction,\n\u001b[1;32m    546\u001b[0m     reason: GraphCompileReason,\n\u001b[1;32m    547\u001b[0m ):\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreason\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     cg \u001b[38;5;241m=\u001b[39m PyCodegen(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    550\u001b[0m     cleanup: List[Instruction] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1001\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    998\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1000\u001b[0m     output\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m-> 1001\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     )\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1005\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(pass2\u001b[38;5;241m.\u001b[39mcreate_store(graph_output_var))\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1178\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_context\u001b[38;5;241m.\u001b[39mfake_mode \u001b[38;5;241m=\u001b[39m backend_fake_mode\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_global_state():\n\u001b[0;32m-> 1178\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m   1181\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1251\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler_fn, e)\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[1;32m   1252\u001b[0m         e\u001b[38;5;241m.\u001b[39m__traceback__\n\u001b[1;32m   1253\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m signpost_event(\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputGraph.call_user_compiler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     },\n\u001b[1;32m   1264\u001b[0m )\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1232\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverify_correctness:\n\u001b[1;32m   1231\u001b[0m     compiler_fn \u001b[38;5;241m=\u001b[39m WrapperBackend(compiler_fn)\n\u001b[0;32m-> 1232\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_fn did not return callable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/repro/after_dynamo.py:117\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/__init__.py:1731\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[1;32m   1729\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 1731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1330\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_fake_mode(fake_mode), torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mtracing(\n\u001b[1;32m   1328\u001b[0m     tracing_context\n\u001b[1;32m   1329\u001b[0m ), compiled_autograd\u001b[38;5;241m.\u001b[39mdisable():\n\u001b[0;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py:58\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[0;32m---> 58\u001b[0m         cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:903\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler)\u001b[0m\n\u001b[1;32m    887\u001b[0m aot_config \u001b[38;5;241m=\u001b[39m AOTConfig(\n\u001b[1;32m    888\u001b[0m     fw_compiler\u001b[38;5;241m=\u001b[39mfw_compiler,\n\u001b[1;32m    889\u001b[0m     bw_compiler\u001b[38;5;241m=\u001b[39mbw_compiler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     no_tangents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m )\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd\u001b[38;5;241m.\u001b[39mdisable():\n\u001b[0;32m--> 903\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;66;03m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;66;03m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;66;03m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# convention.  This should get fixed...\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39mruntime_args):\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:628\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m    625\u001b[0m compiler_fn \u001b[38;5;241m=\u001b[39m partial(aot_wrapper_dedupe, compiler_fn\u001b[38;5;241m=\u001b[39mcompiler_fn)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;66;03m# You can put more passes here\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aot_config\u001b[38;5;241m.\u001b[39mis_export:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# During export, we don't get back a callable - we get back the raw fx graph\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# (either a joint or an inference-only graph)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:443\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn, fw_metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m requires_subclass_dispatch(leaf_flat_args, fw_metadata):\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mEncountered duplicate inputs that are mutated in the graph, but at least one input/output\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03mto the graph is a tensor subclass. This is not supported today. You can try to\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03mremove the aliasing yourself as a workaround, or otherwise file an issue on github.\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m         )\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:648\u001b[0m, in \u001b[0;36maot_wrapper_synthetic_base\u001b[0;34m(flat_fn, flat_args, aot_config, fw_metadata, needs_autograd, compiler_fn)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Happy path: we don't need synthetic bases\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synthetic_base_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# export path: ban synthetic bases for now, add later if requested.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requires_subclass_dispatch(flat_args, fw_metadata):\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:352\u001b[0m, in \u001b[0;36maot_dispatch_autograd\u001b[0;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[0m\n\u001b[1;32m    349\u001b[0m     tracing_context\u001b[38;5;241m.\u001b[39mfw_metadata \u001b[38;5;241m=\u001b[39m inner_meta\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext\u001b[38;5;241m.\u001b[39mreport_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[0;32m--> 352\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m \u001b[43maot_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fw_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    354\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m make_boxed_func(compiled_fw_func)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1257\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler_base\u001b[0;34m(model, example_inputs, is_inference)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m orig_output_end_idx \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_model_outputs\n\u001b[1;32m   1251\u001b[0m     user_visible_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1252\u001b[0m         n\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs[original_output_start_index:orig_output_end_idx]\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mNode)\n\u001b[1;32m   1255\u001b[0m     }\n\u001b[0;32m-> 1257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py:83\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     inner_compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/debug.py:304\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:438\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[0m\n\u001b[1;32m    434\u001b[0m     compiled_graph \u001b[38;5;241m=\u001b[39m FxGraphCache\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    435\u001b[0m         fx_codegen_and_compile, gm, example_inputs, graph_kwargs\n\u001b[1;32m    436\u001b[0m     )\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     compiled_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFX codegen and compilation took \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# check cudagraph disabling reasons from inductor lowering\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:714\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[0m\n\u001b[1;32m    711\u001b[0m             output_strides\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    713\u001b[0m metrics_helper \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mCachedMetricsHelper()\n\u001b[0;32m--> 714\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m V\u001b[38;5;241m.\u001b[39maot_compilation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/graph.py:1307\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AotCodeCompiler\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28mself\u001b[39m, code, serialized_extern_kernel_nodes, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcall\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/graph.py:1254\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1252\u001b[0m linemap \u001b[38;5;241m=\u001b[39m [(line_no, node\u001b[38;5;241m.\u001b[39mstack_trace) \u001b[38;5;28;01mfor\u001b[39;00m line_no, node \u001b[38;5;129;01min\u001b[39;00m linemap]\n\u001b[1;32m   1253\u001b[0m key, path \u001b[38;5;241m=\u001b[39m PyCodeCache\u001b[38;5;241m.\u001b[39mwrite(code)\n\u001b[0;32m-> 1254\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mPyCodeCache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_by_key_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinemap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinemap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_key \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_path \u001b[38;5;241m=\u001b[39m path\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/codecache.py:2160\u001b[0m, in \u001b[0;36mPyCodeCache.load_by_key_path\u001b[0;34m(cls, key, path, linemap, attrs)\u001b[0m\n\u001b[1;32m   2158\u001b[0m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m   2159\u001b[0m mod\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 2160\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2161\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m mod\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;66;03m# another thread might set this first\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/torchinductor_kheuto01/lf/clfcmbz6cwmfxzy6xbw5xt3wxzuwp73ytgh4fbwey6543sjsmawd.py:117\u001b[0m\n\u001b[1;32m     25\u001b[0m async_compile \u001b[38;5;241m=\u001b[39m AsyncCompile()\n\u001b[1;32m     28\u001b[0m cpp_fused_add_div_exp_mul_neg_pow_softplus_sub_sum_0 \u001b[38;5;241m=\u001b[39m async_compile\u001b[38;5;241m.\u001b[39mcpp_pybinding([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst float*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst float*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst float*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst double*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst float*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble*\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m#include \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/torchinductor_kheuto01/wy/cwyvgno7oj63mpe36f4v6pizgeyvccmavffogp6xnqv56a32gbwo.h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mextern \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m void kernel(const double* in_ptr0,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m \u001b[43masync_compile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m async_compile\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(args):\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/codecache.py:2715\u001b[0m, in \u001b[0;36mAsyncCompile.wait\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m   2713\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(key)\n\u001b[1;32m   2714\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, (Future, TritonFuture)):\n\u001b[0;32m-> 2715\u001b[0m             scope[key] \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2716\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2718\u001b[0m _compile_end()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/codecache.py:2074\u001b[0m, in \u001b[0;36mCppPythonBindingsCodeCache.load_pybinding\u001b[0;34m(cls, argtypes, source_code, cuda, num_outputs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m parseargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparse_arg<\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margtype\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>(args, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2060\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n, argtype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(argtypes)\n\u001b[1;32m   2061\u001b[0m )\n\u001b[1;32m   2062\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msuffix_template \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m   2063\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mentry_function,\n\u001b[1;32m   2064\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mextra_parse_arg \u001b[38;5;241m%\u001b[39m num_outputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mextra_parse_arg \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2072\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mentry_function,\n\u001b[1;32m   2073\u001b[0m )\n\u001b[0;32m-> 2074\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, ModuleType)\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mentry_function)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/codecache.py:1948\u001b[0m, in \u001b[0;36mCppCodeCache.load\u001b[0;34m(cls, source_code, cuda)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_path):\n\u001b[1;32m   1940\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m   1941\u001b[0m         cpp_compile_command(\n\u001b[1;32m   1942\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         )\n\u001b[1;32m   1947\u001b[0m     )\n\u001b[0;32m-> 1948\u001b[0m     \u001b[43mcompile_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_load_library(output_path, key)\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcache[key]\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/_inductor/codecache.py:1888\u001b[0m, in \u001b[0;36mcompile_file\u001b[0;34m(input_path, output_path, cmd)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     instruction \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1879\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOpenMP support not found. Please try one of the following solutions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(1) Set the `CXX` environment variable to a compiler other than Apple clang++/g++ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with `include/omp.h` under it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1886\u001b[0m     )\n\u001b[1;32m   1887\u001b[0m     output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m instruction\n\u001b[0;32m-> 1888\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mCppCompileError(cmd, output) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m: backend='inductor' raised:\nCppCompileError: C++ compile error\n\nCommand:\ng++ /tmp/torchinductor_kheuto01/jx/cjxsoagrmkidzkunygyxu3rchf4elvvcoicae6bthfbiteejr4vc.cpp -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -Wno-unknown-pragmas -D_GLIBCXX_USE_CXX11_ABI=0 -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/TH -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/include/THC -I/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/include/python3.11 -L/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k3/lib/python3.11/site-packages/torch/lib -lgomp -lc10 -O3 -DNDEBUG -ffast-math -fno-finite-math-only -fno-unsafe-math-optimizations -ffp-contract=off -march=native -fopenmp -D C10_USING_CUSTOM_GENERATED_MACROS -o /tmp/torchinductor_kheuto01/jx/cjxsoagrmkidzkunygyxu3rchf4elvvcoicae6bthfbiteejr4vc.so\n\nOutput:\ng++: error: unrecognized command line option -std=c++17\n\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "dist = model(time_T,pop_S, lat_S, lon_S)\n",
    "\n",
    "y_sample_TMS = dist.sample((M_score_func,)).permute(1, 0, 2)\n",
    "y_sample_action_TMS = y_sample_TMS\n",
    "\n",
    "ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "def get_log_probs_baked(param):\n",
    "    distribution = model.build_from_single_tensor(param, time_T, pop_S, lat_S, lon_S)\n",
    "    log_probs_TMS = distribution.log_prob(y_sample_TMS.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "\n",
    "    return log_probs_TMS\n",
    "\n",
    "jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y_TS size: (64, 1620)\n",
      "ratio_rating_TS size: torch.Size([64, 1620])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "# get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "print(f'train_y_TS size: {train_y_TS.shape}')\n",
    "print(f'ratio_rating_TS size: {ratio_rating_TS.shape}')\n",
    "positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "if nll_weight>0:\n",
    "    bpr_threshold_diff_T = positive_bpr_T - threshold\n",
    "    violate_threshold_flag = bpr_threshold_diff_T < 0\n",
    "    negative_bpr_loss = torch.mean(-bpr_threshold_diff_T*violate_threshold_flag)\n",
    "else:\n",
    "    negative_bpr_loss = torch.mean(-positive_bpr_T)\n",
    "\n",
    "nll = torch.mean(-dist.log_prob( torch.tensor(train_y_TS)))\n",
    "\n",
    "loss = bpr_weight*negative_bpr_loss + nll_weight*nll\n",
    "loss.backward()\n",
    "loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "gradient_tuple = model.single_tensor_to_params(gradient_P)\n",
    "\n",
    "for param, gradient in zip(model.parameters(), gradient_tuple):\n",
    "    if nll_weight>0:\n",
    "        gradient = gradient + param.grad\n",
    "    param.grad = gradient\n",
    "if update:\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_rating_TS.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2b33aabcced0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = model(time_T,pop_S, lat_S, lon_S)\n",
    "y_sample_TMS = dist.sample((20, )).permute(1, 0, 2)\n",
    "plt.imshow(y_sample_TMS.mean(1)[5,:].view(data_shape))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
