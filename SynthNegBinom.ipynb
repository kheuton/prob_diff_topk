{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 14:47:58.064990: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 14:47:58.115792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 14:47:58.115827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 14:47:58.117164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 14:47:58.125687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 14:47:59.709097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Poisson, MixtureSameFamily\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import partial\n",
    "from distributions import QuantizedNormal\n",
    "from torch_models import  MixtureOfTruncNormModel, torch_bpr_uncurried, deterministic_bpr, SpatialWaves\n",
    "#from torch_perturb.torch_pert_topk import PerturbedTopK\n",
    "from metrics import top_k_onehot_indicator\n",
    "from torch_training import train_epoch_largesynth\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from torch_models import NegativeBinomialRegressionModel, MixtureOfTruncNormModel, torch_bpr_uncurried, deterministic_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic_data(num_locations=10, num_time_points=50, num_fixed_effects=3, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate time points\n",
    "    time = torch.linspace(0, 1, num_time_points).unsqueeze(1).expand(-1, num_locations)\n",
    "\n",
    "    # Generate fixed effects\n",
    "    X = torch.randn(num_time_points, num_locations, num_fixed_effects)\n",
    "\n",
    "    # Set true parameter values\n",
    "    true_beta_0 = 1.0\n",
    "    true_beta = torch.tensor([0.5, -0.3, 0.7])\n",
    "    true_sigma_0 = 0.2\n",
    "    true_sigma_1 = 0.1\n",
    "    true_rho = 0.3\n",
    "    true_theta = 5.0\n",
    "\n",
    "    # Generate random effects\n",
    "    cov_matrix = torch.tensor([\n",
    "        [true_sigma_0**2, true_rho * true_sigma_0 * true_sigma_1],\n",
    "        [true_rho * true_sigma_0 * true_sigma_1, true_sigma_1**2]\n",
    "    ])\n",
    "    random_effects = torch.distributions.MultivariateNormal(\n",
    "        loc=torch.zeros(2),\n",
    "        covariance_matrix=cov_matrix\n",
    "    ).sample((num_locations,))\n",
    "    b_0 = random_effects[:, 0]\n",
    "    b_1 = random_effects[:, 1]\n",
    "\n",
    "    # Calculate log_mu\n",
    "    fixed_effects = true_beta_0 + torch.einsum('tli,i->tl', X, true_beta)\n",
    "    random_intercepts = b_0.expand(num_time_points, -1)\n",
    "    random_slopes = b_1.expand(num_time_points, -1)\n",
    "    log_mu = fixed_effects + random_intercepts + random_slopes * time\n",
    "\n",
    "    # Generate y using the NegativeBinomial distribution\n",
    "    mu = torch.exp(log_mu)\n",
    "    y = torch.distributions.NegativeBinomial(\n",
    "        total_count=true_theta,\n",
    "        probs=true_theta / (true_theta + mu)\n",
    "    ).sample()\n",
    "\n",
    "    return X, y, time, {\n",
    "        'beta_0': true_beta_0,\n",
    "        'beta': true_beta,\n",
    "        'sigma_0': true_sigma_0,\n",
    "        'sigma_1': true_sigma_1,\n",
    "        'rho': true_rho,\n",
    "        'theta': true_theta,\n",
    "        'b_0': b_0,\n",
    "        'b_1': b_1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([50, 10, 3])\n",
      "y shape: torch.Size([50, 10])\n",
      "time shape: torch.Size([50, 10])\n",
      "\n",
      "True parameters:\n",
      "beta_0: 1.0\n",
      "beta: tensor([ 0.5000, -0.3000,  0.7000])\n",
      "sigma_0: 0.2\n",
      "sigma_1: 0.1\n",
      "rho: 0.3\n",
      "theta: 5.0\n",
      "b_0: tensor([-0.2883, -0.3926, -0.1699, -0.0410,  0.1375, -0.2222, -0.1980, -0.1431,\n",
      "         0.1103,  0.2116])\n",
      "b_1: tensor([-0.1037, -0.1209, -0.0921, -0.0807,  0.0954, -0.3297, -0.0871, -0.0660,\n",
      "         0.2698,  0.0177])\n"
     ]
    }
   ],
   "source": [
    "X, y, time, true_params = generate_synthetic_data()\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"time shape:\", time.shape)\n",
    "print(\"\\nTrue parameters:\")\n",
    "for key, value in true_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "num_locations, num_fixed_effects = X.shape[1], X.shape[2]\n",
    "model = NegativeBinomialRegressionModel(num_locations, num_fixed_effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rho.data = torch.tensor([0.02], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-15.0671, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_likelihood(y, X, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = model.get_covariance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cov.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_gradients(model, X, y, time):\n",
    "    # Ensure gradients are being tracked\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass to compute log-likelihood\n",
    "    log_likelihood = model.log_likelihood(y, X, time)\n",
    "    \n",
    "    # Compute gradients\n",
    "    log_likelihood.backward()\n",
    "    \n",
    "    # Store gradients in a dictionary\n",
    "    gradients = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            gradients[name] = param.grad.clone()\n",
    "        else:\n",
    "            gradients[name] = torch.zeros_like(param)\n",
    "    \n",
    "    return gradients\n",
    "\n",
    "# Assuming you have already initialized the model and generated synthetic data\n",
    "# model = NegativeBinomialRegressionModel(...)\n",
    "# X, y, time, true_params = generate_synthetic_data(...)\n",
    "\n",
    "# Calculate gradients\n",
    "gradients = calculate_log_likelihood_gradients(model, X, y, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta_0': tensor([5.3865]),\n",
       " 'beta': tensor([-3.1868,  2.5952, -2.8444]),\n",
       " 'b_0': tensor([1.1078, 0.4994, 0.4833, 0.6514, 0.2354, 0.3962, 0.3264, 0.7953, 0.3361,\n",
       "         0.5203]),\n",
       " 'b_1': tensor([ 0.3960,  0.3276, -0.0294,  0.3470,  0.4248,  0.6551, -0.3307,  0.2029,\n",
       "          0.3313,  0.8706]),\n",
       " 'log_sigma_0': tensor([0.1867]),\n",
       " 'log_sigma_1': tensor([2.4988]),\n",
       " 'rho': tensor([-0.4146]),\n",
       " 'log_theta': tensor([-5.8018])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single tensor with all the true parameters\n",
    "true_params_tensor = torch.cat([\n",
    "    torch.tensor([true_params['beta_0']]),\n",
    "    true_params['beta'],\n",
    "    true_params['b_0'],\n",
    "    true_params['b_1'],\n",
    "    torch.log(torch.tensor([true_params['sigma_0']])),\n",
    "    torch.log(torch.tensor([true_params['sigma_1']])),\n",
    "    torch.atanh(torch.tensor([true_params['rho']])),\n",
    "    torch.log(torch.tensor([true_params['theta']]))\n",
    "])\n",
    "\n",
    "# Update the model parameters with the true values\n",
    "model.update_params(true_params_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.0503, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_likelihood(y, X, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
