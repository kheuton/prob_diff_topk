{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functools import partial\n",
    "\n",
    "import keras\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from models import mixture_poissons,location_specific_linear, CustomPenalizedMixtureDecisionModel\n",
    "from metrics import mixture_poi_loss, get_bpr_loss_func, mix_bpr, get_penalized_bpr_loss_func_mix, cross_ratio_decision, get_perturbed_bpr_func\n",
    "from experiments import training_loop, training_loop_score_function_trick, score_function_trick, overall_gradient_calculation\n",
    "from plotting_funcs import plot_losses, plot_frontier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "num_components=4\n",
    "learning_rate = 0.005\n",
    "epochs=500\n",
    "outdir = '/cluster/home/kheuto01/testdir'\n",
    "penalty = 5000\n",
    "threshold = 0.55\n",
    "K=4\n",
    "do_only=True\n",
    "# tracts/distributions\n",
    "S=12\n",
    "# history/features\n",
    "H = 3\n",
    "# total timepoints\n",
    "T= 500\n",
    "perturbed_sigma=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = example_datasets(H, T, seed=seed)\n",
    "train_X_THS, train_y_TS = to_numpy(train_dataset)\n",
    "val_X_THS, val_y_TS = to_numpy(val_dataset)\n",
    "input_shape = (H,S)\n",
    "\n",
    "bpr_K = get_perturbed_bpr_func(K, sigma=perturbed_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomPenalizedMixtureDecisionModel(num_features=H, num_locations=S,\n",
    "                 member_model=location_specific_linear,\n",
    "                 member_distribution=tfp.distributions.Poisson,\n",
    "                 decision_func=cross_ratio_decision,\n",
    "                 bpr_func=bpr_K,\n",
    "                 bpr_threshold=threshold,\n",
    "                 penalty=penalty,\n",
    "                 objective_includes_likelihood=True,\n",
    "                 objective_includes_bpr=True,\n",
    "                 num_components=4,\n",
    "                 num_score_func_samples=50,\n",
    "                 seed=360,)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(50, 300, 12), dtype=tf.float32, name=None), name='tf.reshape_32/Reshape:0', description=\"created by layer 'tf.reshape_32'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m sample_y_MBS \u001b[38;5;241m=\u001b[39m mixture_distribution\u001b[38;5;241m.\u001b[39msample(model\u001b[38;5;241m.\u001b[39mnum_score_func_samples)\n\u001b[1;32m      7\u001b[0m sample_log_likelihood_MBS \u001b[38;5;241m=\u001b[39m mixture_distribution\u001b[38;5;241m.\u001b[39mlog_prob(sample_y_MBS)\n\u001b[0;32m----> 9\u001b[0m sample_decisions_MBS \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_y_MBS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m expected_decisions_BS \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(sample_decisions_MBS, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m loss_B, metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalc_loss_and_metrics(y_BS, mixture_distribution, expected_decisions_BS)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    577\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[1;32m    579\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[1;32m    580\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[1;32m    581\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 583\u001b[0m         \u001b[43m_make_validated_mono_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[1;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[1;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[1;32m    521\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mAttrs\u001b[38;5;241m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    179\u001b[0m       \u001b[38;5;28mtype\u001b[39m(value),\n\u001b[1;32m    180\u001b[0m       \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    181\u001b[0m           from_value(\u001b[38;5;28mgetattr\u001b[39m(value, a\u001b[38;5;241m.\u001b[39mname), context)\n\u001b[1;32m    182\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__attrs_attrs__))\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_np_ndarray(value):\n\u001b[0;32m--> 185\u001b[0m   ndarray \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTENSOR(ndarray\u001b[38;5;241m.\u001b[39mshape, ndarray\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, custom_nest_protocol\u001b[38;5;241m.\u001b[39mCustomNestProtocol):\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/keras_tensor.py:285\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are passing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an intermediate Keras symbolic \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.reshape`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs/outputs. You can work around \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call` and calling that layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon this symbolic input/output.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(50, 300, 12), dtype=tf.float32, name=None), name='tf.reshape_32/Reshape:0', description=\"created by layer 'tf.reshape_32'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "for step, (x_BHS, y_BS) in enumerate(train_dataset):\n",
    "\n",
    "    with tf.GradientTape() as jacobian_tape, tf.GradientTape() as loss_tape:\n",
    "        mixture_distribution = model._get_mixture_distribution(x_BHS)\n",
    "        sample_y_MBS = mixture_distribution.sample(model.num_score_func_samples)\n",
    "\n",
    "        sample_log_likelihood_MBS = mixture_distribution.log_prob(sample_y_MBS)\n",
    "\n",
    "        sample_decisions_MBS = model.decision_func(sample_y_MBS)\n",
    "        expected_decisions_BS = tf.reduce_mean(sample_decisions_MBS, axis=0)\n",
    "\n",
    "        loss_B, metrics = model.calc_loss_and_metrics(y_BS, mixture_distribution, expected_decisions_BS)\n",
    "\n",
    "\n",
    "    # The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\n",
    "    jacobian_pMBS = jacobian_tape.jacobian(sample_log_likelihood_MBS, model.trainable_variables)\n",
    "    param_gradient_pBS = score_function_trick(jacobian_pMBS, sample_decisions_MBS)\n",
    "    loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)\n",
    "    overall_gradient_p = [overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]\n",
    "    optimizer.apply_gradients(overall_gradient_p, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample_y_MBS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "sample_y_MBS.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.MixtureSameFamily 'MixtureSameFamily' batch_shape=[300, 12] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_score_func_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(50, 300, 12) dtype=float32 (created by layer 'tf.reshape_18')>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_dist.sample(model.num_score_func_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 3, 12), dtype=float32, numpy=\n",
       "array([[[  7.,   7.,   7., ...,   0., 100.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ..., 100.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0., 100.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ..., 100.,   0.,   0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ..., 100.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 3, 12), dtype=tf.float32, name=None), TensorSpec(shape=(None, 12), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  7.,   7.,   7., ..., 100.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0., 100.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.],\n",
       "        [  7.,   7.,   7., ...,   0.,   0.,   0.]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_THS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/cluster/home/kheuto01/code/prob_diff_topk/models.py\u001b[0m(210)\u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    208 \u001b[0;31m            \u001b[0mmixture_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_mixture_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_BHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    209 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 210 \u001b[0;31m            \u001b[0msample_y_MBS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixture_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_score_func_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    211 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    212 \u001b[0;31m            \u001b[0msample_log_likelihood_MBS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixture_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_y_MBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<tf.Tensor 'IteratorGetNext:0' shape=(None, 3, 12) dtype=float32>\n",
      "<tf.Tensor 'IteratorGetNext:0' shape=(None, 3, 12) dtype=float32>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/models.py\", line 210, in train_step\n        sample_y_MBS = mixture_distribution.sample(self.num_score_func_samples)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1205, in sample\n        return self._call_sample_n(sample_shape, seed, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1182, in _call_sample_n\n        samples = self._sample_n(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 295, in _sample_n\n        mix_sample = mixture_distribution.sample(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1205, in sample\n        return self._call_sample_n(sample_shape, seed, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1182, in _call_sample_n\n        samples = self._sample_n(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/categorical.py\", line 266, in _sample_n\n        shape=ps.concat([[n], self._batch_shape_tensor(logits=logits)], axis=0))\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 984, in _batch_shape_tensor\n        return batch_shape_lib.inferred_batch_shape_tensor(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 110, in inferred_batch_shape_tensor\n        batch_shapes = map_fn_over_parameters_with_event_ndims(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 367, in map_fn_over_parameters_with_event_ndims\n        results[param_name] = nest.map_structure_up_to(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 139, in get_batch_shape_tensor_part\n        return _truncate_shape_tensor(base_shape, event_ndims)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 176, in _truncate_shape_tensor\n        shape = ps.convert_to_shape_tensor(shape, dtype_hint=np.int32)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/layers/core/tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 72, in error_handler\n        del filtered_tb\n\n    TypeError: Dimension value must be integer or None or have an __index__ method, got value '<attribute 'shape' of 'numpy.generic' objects>' with type '<class 'getset_descriptor'>'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filenrlnqqpa.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/code/prob_diff_topk/models.py:210\u001b[0m, in \u001b[0;36mCustomPenalizedMixtureDecisionModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    208\u001b[0m mixture_distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_mixture_distribution(x_BHS)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m;pdb\u001b[38;5;241m.\u001b[39mset_trace();\n\u001b[0;32m--> 210\u001b[0m sample_y_MBS \u001b[38;5;241m=\u001b[39m \u001b[43mmixture_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_score_func_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m sample_log_likelihood_MBS \u001b[38;5;241m=\u001b[39m mixture_distribution\u001b[38;5;241m.\u001b[39mlog_prob(sample_y_MBS)\n\u001b[1;32m    214\u001b[0m sample_decisions_MBS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_func(sample_y_MBS)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py:295\u001b[0m, in \u001b[0;36m_MixtureSameFamily._sample_n\u001b[0;34m(self, n, seed)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# TODO(jvdillon): Consider using tf.gather (by way of index unrolling).\u001b[39;00m\n\u001b[1;32m    294\u001b[0m npdt \u001b[38;5;241m=\u001b[39m dtype_util\u001b[38;5;241m.\u001b[39mas_numpy_dtype(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 295\u001b[0m mix_sample \u001b[38;5;241m=\u001b[39m \u001b[43mmixture_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmix_seed\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n, B]\u001b[39;00m\n\u001b[1;32m    297\u001b[0m mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(\n\u001b[1;32m    298\u001b[0m     indices\u001b[38;5;241m=\u001b[39mmix_sample,  \u001b[38;5;66;03m# [n, B]\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     depth\u001b[38;5;241m=\u001b[39mnum_components,\n\u001b[1;32m    300\u001b[0m     on_value\u001b[38;5;241m=\u001b[39mnpdt(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    301\u001b[0m     off_value\u001b[38;5;241m=\u001b[39mnpdt(\u001b[38;5;241m0\u001b[39m))    \u001b[38;5;66;03m# [n, B, k]\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Pad `mask` to [n, B, k, [1]*e].\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/categorical.py:266\u001b[0m, in \u001b[0;36mCategorical._sample_n\u001b[0;34m(self, n, seed)\u001b[0m\n\u001b[1;32m    261\u001b[0m   draws \u001b[38;5;241m=\u001b[39m samplers\u001b[38;5;241m.\u001b[39mcategorical(\n\u001b[1;32m    262\u001b[0m       logits_2d, n, dtype\u001b[38;5;241m=\u001b[39msample_dtype, seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    263\u001b[0m draws \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(draws, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    265\u001b[0m     tf\u001b[38;5;241m.\u001b[39mtranspose(draws),\n\u001b[0;32m--> 266\u001b[0m     shape\u001b[38;5;241m=\u001b[39mps\u001b[38;5;241m.\u001b[39mconcat([[n], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:984\u001b[0m, in \u001b[0;36mDistribution._batch_shape_tensor\u001b[0;34m(self, **parameter_kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Infers batch shape from parameters.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03mThe overall batch shape is inferred by broadcasting the batch shapes of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;124;03m  batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 984\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m batch_shape_lib\u001b[38;5;241m.\u001b[39minferred_batch_shape_tensor(\n\u001b[1;32m    985\u001b[0m       \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_kwargs)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot compute batch shape of distribution \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    988\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: you must implement at least one of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    989\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`_batch_shape_tensor` or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    990\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`_parameter_properties`.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py:110\u001b[0m, in \u001b[0;36minferred_batch_shape_tensor\u001b[0;34m(batch_object, bijector_x_event_ndims, **parameter_kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minferred_batch_shape_tensor\u001b[39m(batch_object,\n\u001b[1;32m     79\u001b[0m                                 bijector_x_event_ndims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m                                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_kwargs):\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Infers an object's batch shape from its  parameters.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m  Each parameter contributes a batch shape of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    batch_shape_tensor: `Tensor` broadcast batch shape of all parameters.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m   batch_shapes \u001b[38;5;241m=\u001b[39m \u001b[43mmap_fn_over_parameters_with_event_ndims\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m      \u001b[49m\u001b[43mget_batch_shape_tensor_part\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbijector_x_event_ndims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbijector_x_event_ndims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m      \u001b[49m\u001b[43mrequire_static\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameter_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mreduce(ps\u001b[38;5;241m.\u001b[39mbroadcast_shape, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(batch_shapes), [])\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py:367\u001b[0m, in \u001b[0;36mmap_fn_over_parameters_with_event_ndims\u001b[0;34m(batch_object, fn, bijector_x_event_ndims, require_static, **parameter_kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (properties\u001b[38;5;241m.\u001b[39mis_tensor\n\u001b[1;32m    362\u001b[0m           \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(param)\n\u001b[1;32m    363\u001b[0m           \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(param_event_ndims)):\n\u001b[1;32m    364\u001b[0m       \u001b[38;5;66;03m# As a last resort, try an explicit conversion.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m       param \u001b[38;5;241m=\u001b[39m tensor_util\u001b[38;5;241m.\u001b[39mconvert_nonref_to_tensor(param, name\u001b[38;5;241m=\u001b[39mparam_name)\n\u001b[0;32m--> 367\u001b[0m   results[param_name] \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_event_ndims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py:139\u001b[0m, in \u001b[0;36mget_batch_shape_tensor_part\u001b[0;34m(x, event_ndims)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m   base_shape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(x)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_truncate_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_ndims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py:176\u001b[0m, in \u001b[0;36m_truncate_shape_tensor\u001b[0;34m(shape, rightmost_ndims_to_truncate)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_truncate_shape_tensor\u001b[39m(shape, rightmost_ndims_to_truncate):\n\u001b[0;32m--> 176\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_shape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m   rightmost_ndims_to_truncate \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m    178\u001b[0m       rightmost_ndims_to_truncate, dtype_hint\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m    179\u001b[0m   base_rank \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mrank_from_shape(shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/models.py\", line 210, in train_step\n        sample_y_MBS = mixture_distribution.sample(self.num_score_func_samples)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1205, in sample\n        return self._call_sample_n(sample_shape, seed, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1182, in _call_sample_n\n        samples = self._sample_n(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/mixture_same_family.py\", line 295, in _sample_n\n        mix_sample = mixture_distribution.sample(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1205, in sample\n        return self._call_sample_n(sample_shape, seed, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 1182, in _call_sample_n\n        samples = self._sample_n(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/categorical.py\", line 266, in _sample_n\n        shape=ps.concat([[n], self._batch_shape_tensor(logits=logits)], axis=0))\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py\", line 984, in _batch_shape_tensor\n        return batch_shape_lib.inferred_batch_shape_tensor(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 110, in inferred_batch_shape_tensor\n        batch_shapes = map_fn_over_parameters_with_event_ndims(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 367, in map_fn_over_parameters_with_event_ndims\n        results[param_name] = nest.map_structure_up_to(\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 139, in get_batch_shape_tensor_part\n        return _truncate_shape_tensor(base_shape, event_ndims)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow_probability/python/internal/batch_shape_lib.py\", line 176, in _truncate_shape_tensor\n        shape = ps.convert_to_shape_tensor(shape, dtype_hint=np.int32)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/layers/core/tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 72, in error_handler\n        del filtered_tb\n\n    TypeError: Dimension value must be integer or None or have an __index__ method, got value '<attribute 'shape' of 'numpy.generic' objects>' with type '<class 'getset_descriptor'>'\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, verbose=1, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_X_THS, train_y_TS = to_numpy(train_dataset)\n",
    "    val_X_THS, val_y_TS = to_numpy(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mix_model_penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as jacobian_tape, tf.GradientTape() as loss_tape:\n",
    "                prob_params_BSK, mixture_weights_KS = model(x_batch_train, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_weights_SK = tf.transpose(mixture_weights_KS, perm=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = tfp.distributions.MixtureSameFamily(\n",
    "    mixture_distribution=tfp.distributions.Categorical(probs=mixture_weights_SK),\n",
    "    components_distribution = tfp.distributions.Poisson(rate=prob_params_BSK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y_MBS = mix.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_MBS = mix.log_prob(sample_y_MBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 300, 12), dtype=float32, numpy=\n",
       "array([[[-0.70101863, -3.49464   , -0.6986769 , ..., -0.6931472 ,\n",
       "         -0.6931473 , -1.0596601 ],\n",
       "        [-3.5308998 , -4.944219  , -0.6986769 , ..., -4.9409027 ,\n",
       "         -1.0596601 , -0.6931472 ],\n",
       "        [-4.0951333 , -0.7111152 , -3.7875445 , ..., -0.6931472 ,\n",
       "         -0.6981911 , -0.6931472 ],\n",
       "        ...,\n",
       "        [-0.70101863, -3.4190197 , -0.6986769 , ..., -0.6931472 ,\n",
       "         -0.6931473 , -0.6931472 ],\n",
       "        [-3.981664  , -4.2890096 , -0.6986769 , ..., -1.0596602 ,\n",
       "         -1.3627218 , -1.0596601 ],\n",
       "        [-4.0275745 , -0.7111152 , -3.8916945 , ..., -2.1193204 ,\n",
       "         -6.206031  , -1.0596601 ]],\n",
       "\n",
       "       [[-0.70101863, -0.7111152 , -0.6986769 , ..., -0.6931472 ,\n",
       "         -0.6931473 , -2.1193204 ],\n",
       "        [-3.9768908 , -3.4446435 , -4.548599  , ..., -5.537909  ,\n",
       "         -0.6931473 , -0.6931472 ],\n",
       "        [-0.70101863, -0.7111152 , -0.6986769 , ..., -0.6931472 ,\n",
       "         -4.6353803 , -2.1193204 ],\n",
       "        ...,\n",
       "        [-0.70101863, -4.2614584 , -3.5542488 , ..., -2.1193204 ,\n",
       "         -2.1193202 , -1.0596601 ],\n",
       "        [-0.70101863, -3.9054954 , -0.6986769 , ..., -0.6931472 ,\n",
       "         -5.809651  , -0.6931472 ],\n",
       "        [-0.70101863, -3.9482121 , -3.7875445 , ..., -0.6931472 ,\n",
       "         -0.6981911 , -2.1193204 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs_MBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 12), dtype=float32, numpy=\n",
       "array([[ 7.8314114,  7.820159 ,  7.870078 , ...,  0.6931473,  0.6931472,\n",
       "         0.6931472],\n",
       "       [ 7.8314114,  7.820159 ,  7.870078 , ..., 31.709133 ,  0.6931472,\n",
       "         0.6931472],\n",
       "       [ 7.8314114,  7.820159 ,  7.870078 , ...,  0.6931473, 31.864498 ,\n",
       "         0.6931472],\n",
       "       ...,\n",
       "       [ 7.8314114,  7.820159 ,  7.870078 , ...,  0.6931473,  0.6931472,\n",
       "         0.6931472],\n",
       "       [ 7.8314114,  7.820159 ,  7.870078 , ...,  0.6931473, 48.643055 ,\n",
       "         0.6931472],\n",
       "       [ 7.8314114,  7.820159 ,  7.870078 , ...,  0.6931473, 31.864498 ,\n",
       "         0.6931472]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/metrics.py\", line 150, in uncurried_penalized_mix_bpr  *\n        mixture_bpr_loss_val = mix_bpr(y_true, y_pred, negative_bpr_K_func=negative_bpr_K_func)\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/metrics.py\", line 138, in mix_bpr  *\n        component_preds, mixture_weights = y_pred\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses_penalized \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop_score_function_trick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmix_model_penalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalized_bpr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_bpr_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcross_ratio_decision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnum_score_func_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcomponent_likelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPoisson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/prob_diff_topk/experiments.py:133\u001b[0m, in \u001b[0;36mtraining_loop_score_function_trick\u001b[0;34m(model, loss_func, optimizer, num_epochs, train_dataset, val_dataset, negative_bpr_K, decision_func, num_score_func_samples, component_likelihood, verbose)\u001b[0m\n\u001b[1;32m    130\u001b[0m     sample_decisions_MBS \u001b[38;5;241m=\u001b[39m decision_func(sample_y_MBS)\n\u001b[1;32m    132\u001b[0m     expected_decisions_BS \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(sample_decisions_MBS, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m     model_loss \u001b[38;5;241m=\u001b[39m  \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_decisions_BS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\u001b[39;00m\n\u001b[1;32m    137\u001b[0m jacobian_pMBS \u001b[38;5;241m=\u001b[39m jacobian_tape\u001b[38;5;241m.\u001b[39mjacobian(log_probs_MBS, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/metrics.py\", line 150, in uncurried_penalized_mix_bpr  *\n        mixture_bpr_loss_val = mix_bpr(y_true, y_pred, negative_bpr_K_func=negative_bpr_K_func)\n    File \"/cluster/home/kheuto01/code/prob_diff_topk/metrics.py\", line 138, in mix_bpr  *\n        component_preds, mixture_weights = y_pred\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
     ]
    }
   ],
   "source": [
    "losses_penalized = training_loop_score_function_trick(mix_model_penalized, penalized_bpr_loss, optimizer,\n",
    "                                    epochs, train_dataset, val_dataset, negative_bpr_K,\n",
    "                                    cross_ratio_decision,\n",
    "                                    num_score_func_samples=10,\n",
    "                                    component_likelihood=tfp.distributions.Poisson,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k2_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
