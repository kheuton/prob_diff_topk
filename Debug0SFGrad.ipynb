{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "from functools import partial\n",
    "\n",
    "# add code directory to path\n",
    "import sys\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from metrics import top_k_onehot_indicator\n",
    "from torch_perturb.perturbations import perturbed\n",
    "from torch_models import NegativeBinomialRegressionModel, torch_bpr_uncurried, deterministic_bpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"Load and process training, validation, and test data.\"\"\"\n",
    "    # Load data\n",
    "    train_X_df = pd.read_csv(os.path.join(data_dir, 'train_x.csv'), index_col=[0,1])\n",
    "    train_Y_df = pd.read_csv(os.path.join(data_dir, 'train_y.csv'), index_col=[0,1])\n",
    "    val_X_df = pd.read_csv(os.path.join(data_dir, 'valid_x.csv'), index_col=[0,1])\n",
    "    val_Y_df = pd.read_csv(os.path.join(data_dir, 'valid_y.csv'), index_col=[0,1])\n",
    "    test_X_df = pd.read_csv(os.path.join(data_dir, 'test_x.csv'), index_col=[0,1])\n",
    "    test_Y_df = pd.read_csv(os.path.join(data_dir, 'test_y.csv'), index_col=[0,1])\n",
    "    \n",
    "    def convert_df_to_3d_array(df):\n",
    "        geoids = sorted(df.index.get_level_values('geoid').unique())\n",
    "        timesteps = sorted(df.index.get_level_values('timestep').unique())\n",
    "        geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "        \n",
    "        num_timesteps = len(timesteps)\n",
    "        num_locations = len(geoids)\n",
    "        num_features = len(df.columns)\n",
    "        X = np.zeros((num_timesteps, num_locations, num_features))\n",
    "        \n",
    "        for (geoid, timestep), row in df.iterrows():\n",
    "            t_idx = timesteps.index(timestep)\n",
    "            g_idx = geoid_to_idx[geoid]\n",
    "            X[t_idx, g_idx, :] = row.values\n",
    "            \n",
    "        return X, geoids, timesteps\n",
    "\n",
    "    def convert_y_df_to_2d_array(y_df, geoids, timesteps):\n",
    "        num_timesteps = len(timesteps)\n",
    "        num_locations = len(geoids)\n",
    "        y = np.zeros((num_timesteps, num_locations))\n",
    "        geoid_to_idx = {geoid: idx for idx, geoid in enumerate(geoids)}\n",
    "        \n",
    "        for (geoid, timestep), value in y_df.iloc[:, 0].items():\n",
    "            t_idx = timesteps.index(timestep)\n",
    "            g_idx = geoid_to_idx[geoid]\n",
    "            y[t_idx, g_idx] = value\n",
    "            \n",
    "        return y\n",
    "\n",
    "    # Process training data\n",
    "    train_X, geoids, timesteps = convert_df_to_3d_array(train_X_df)\n",
    "    train_time = np.array([timesteps] * len(geoids)).T\n",
    "    train_y = convert_y_df_to_2d_array(train_Y_df, geoids, timesteps)\n",
    "\n",
    "    # Process validation data\n",
    "    val_X, val_geoids, val_timesteps = convert_df_to_3d_array(val_X_df)\n",
    "    val_time = np.array([val_timesteps] * len(val_geoids)).T\n",
    "    val_y = convert_y_df_to_2d_array(val_Y_df, val_geoids, val_timesteps)\n",
    "\n",
    "    # Process test data\n",
    "    test_X, test_geoids, test_timesteps = convert_df_to_3d_array(test_X_df)\n",
    "    test_time = np.array([test_timesteps] * len(test_geoids)).T\n",
    "    test_y = convert_y_df_to_2d_array(test_Y_df, test_geoids, test_timesteps)\n",
    "\n",
    "    return {\n",
    "        'train': (torch.tensor(train_X, dtype=torch.float32), \n",
    "                 torch.tensor(train_time, dtype=torch.float32),\n",
    "                 torch.tensor(train_y, dtype=torch.float32),\n",
    "                 geoids, timesteps),\n",
    "        'val': (torch.tensor(val_X, dtype=torch.float32),\n",
    "               torch.tensor(val_time, dtype=torch.float32),\n",
    "               torch.tensor(val_y, dtype=torch.float32)),\n",
    "        'test': (torch.tensor(test_X, dtype=torch.float32),\n",
    "                torch.tensor(test_time, dtype=torch.float32),\n",
    "                torch.tensor(test_y, dtype=torch.float32))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_nll_model = '/cluster/tufts/hugheslab/kheuto01/opioid_grid_try_fix_params/cook/K100_bw30_nw1_ss0.001_nss100_nps100_seed123_sig0.001_tr0.5'\n",
    "data_dir = '/cluster/tufts/hugheslab/datasets/NSF_OD/cleaned/cook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "data = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NegativeBinomialRegressionModel()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = os.path.join(good_nll_model, 'best_model.pth')\n",
    "\n",
    "    \n",
    "# Initialize model with correct parameters\n",
    "model = NegativeBinomialRegressionModel(\n",
    "    num_locations=data['train'][0].shape[1],\n",
    "    num_fixed_effects=data['train'][0].shape[2]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Load saved weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('beta_0', tensor([-0.1400], device='cuda:0')),\n",
       "             ('beta',\n",
       "              tensor([ 0.6625, -0.4004, -0.2112, -0.6044,  0.7179, -0.4108, -0.4261,  0.7077,\n",
       "                       0.3924,  0.2103,  0.2493,  0.3929,  0.1892, -0.1764], device='cuda:0')),\n",
       "             ('b_0',\n",
       "              tensor([ 1.0817,  0.0412,  0.1494,  ...,  0.2998, -0.9449,  0.9793],\n",
       "                     device='cuda:0')),\n",
       "             ('b_1',\n",
       "              tensor([0.1904, 0.4757, 0.2961,  ..., 0.1005, 0.0554, 0.9847], device='cuda:0')),\n",
       "             ('log_sigma_0', tensor([2.4615], device='cuda:0')),\n",
       "             ('log_sigma_1', tensor([1.3859], device='cuda:0')),\n",
       "             ('rho', tensor([0.0228], device='cuda:0')),\n",
       "             ('softinv_theta', tensor([-0.9522], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data['train'][0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1421/133345967.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(train_X, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(train_X, dtype=torch.float32).to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoids = data['train'][3]\n",
    "timesteps = data['train'][4]\n",
    "train_time_arr = np.array([timesteps] * len(geoids)).T\n",
    "time_train = torch.tensor(train_time_arr, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_score_samples = 100\n",
    "num_pert_samples = 100\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.,  ..., 2., 2., 2.],\n",
       "        [3., 3., 3.,  ..., 3., 3., 3.],\n",
       "        [4., 4., 4.,  ..., 4., 4., 4.],\n",
       "        [5., 5., 5.,  ..., 5., 5., 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unconstrained theta: Parameter containing:\n",
      "tensor([-0.9522], device='cuda:0', requires_grad=True)\n",
      "Theta: tensor([0.3264], device='cuda:0', grad_fn=<SoftplusBackward0>)\n",
      "unconstrained theta: Parameter containing:\n",
      "tensor([-0.9522], device='cuda:0', requires_grad=True)\n",
      "Theta: tensor([0.3264], device='cuda:0', grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dist = model(X_train, time_train)\n",
    "\n",
    "y_sample_TMS = dist.sample((num_score_samples,)).permute(1, 0, 2)\n",
    "y_sample_action_TMS = y_sample_TMS\n",
    "\n",
    "ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "ratio_rating_TS = ratio_rating_TMS.mean(dim=1)\n",
    "ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "def get_log_probs_baked(param):\n",
    "    distribution = model.build_from_single_tensor(param, X_train, time_train)\n",
    "    log_probs_TMS = distribution.log_prob(y_sample_TMS.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "    return log_probs_TMS\n",
    "\n",
    "jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, \n",
    "                                            (model.params_to_single_tensor()), \n",
    "                                            strategy='forward-mode', \n",
    "                                            vectorize=True)\n",
    "\n",
    "score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_TMSP.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unconstrained theta: Parameter containing:\n",
      "tensor([-0.9522], device='cuda:0', requires_grad=True)\n",
      "Theta: tensor([0.3264], device='cuda:0', grad_fn=<SoftplusBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6192, -1.1911, -2.4130,  ..., -0.8027, -0.3322, -1.4380],\n",
       "         [-1.2150, -0.9942, -1.1915,  ..., -0.8027, -0.3322, -1.5018],\n",
       "         [-1.2113, -0.9942, -1.7219,  ..., -1.2135, -0.3322, -1.8762],\n",
       "         ...,\n",
       "         [-1.6192, -0.9942, -1.0293,  ..., -0.8027, -0.3322, -2.2692],\n",
       "         [-1.2113, -0.9942, -1.1915,  ..., -0.8027, -0.3322, -1.8762],\n",
       "         [-2.2131, -2.4571, -1.1915,  ..., -1.9173, -0.3322, -1.4380]],\n",
       "\n",
       "        [[-2.2596, -1.6920, -1.6904,  ..., -2.0296, -0.4506, -1.5144],\n",
       "         [-1.2037, -1.1938, -1.0786,  ..., -0.7086, -1.4389, -1.5144],\n",
       "         [-1.2037, -1.0760, -2.3548,  ..., -0.7086, -0.4506, -1.5144],\n",
       "         ...,\n",
       "         [-1.1674, -1.0760, -1.0786,  ..., -0.7086, -0.4506, -2.0603],\n",
       "         [-2.9814, -2.3577, -3.1151,  ..., -1.2441, -0.4506, -2.1567],\n",
       "         [-1.1674, -1.0760, -1.0786,  ..., -2.0296, -0.4506, -1.5285]],\n",
       "\n",
       "        [[-1.4204, -1.1933, -1.0183,  ..., -1.2826, -1.6508, -2.3823],\n",
       "         [-1.2605, -1.0682, -1.7294,  ..., -3.0795, -2.8706, -1.7031],\n",
       "         [-1.2605, -1.1933, -1.1912,  ..., -0.6309, -2.8706, -1.7053],\n",
       "         ...,\n",
       "         [-2.0447, -1.1933, -1.7294,  ..., -0.6309, -0.3198, -2.0086],\n",
       "         [-1.4204, -1.0682, -1.7294,  ..., -0.6309, -0.3198, -2.9430],\n",
       "         [-3.3661, -1.6968, -1.0183,  ..., -0.6309, -0.3198, -2.0086]],\n",
       "\n",
       "        [[-1.3046, -1.1932, -1.2262,  ..., -1.2375, -0.1421, -2.2884],\n",
       "         [-3.1852, -1.0671, -1.2262,  ..., -0.7252, -0.1421, -1.8325],\n",
       "         [-1.9582, -2.3681, -0.7576,  ..., -2.0082, -0.1421, -1.8325],\n",
       "         ...,\n",
       "         [-1.3046, -1.0671, -0.7576,  ..., -1.2375, -0.1421, -2.3725],\n",
       "         [-3.1852, -2.3681, -1.2262,  ..., -2.8822, -0.1421, -1.8689],\n",
       "         [-1.5551, -1.1932, -0.7576,  ..., -0.7252, -0.1421, -3.2463]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_log_probs_baked(model.params_to_single_tensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
