{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 22:10:53.797480: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 22:10:53.854404: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-11 22:10:53.854436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-11 22:10:53.855582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-11 22:10:53.863716: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 22:11:01.345429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functools import partial\n",
    "\n",
    "import keras\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from models import mixture_poissons,location_specific_linear, CustomPenalizedMixtureDecisionModel\n",
    "from metrics import mixture_poi_loss, get_bpr_loss_func, mix_bpr, get_penalized_bpr_loss_func_mix, cross_ratio_decision, get_perturbed_bpr_func\n",
    "from experiments import training_loop, training_loop_score_function_trick, score_function_trick, overall_gradient_calculation\n",
    "from plotting_funcs import plot_losses, plot_frontier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=360\n",
    "num_components=4\n",
    "learning_rate = 0.005\n",
    "epochs=500\n",
    "outdir = '/cluster/home/kheuto01/testdir'\n",
    "penalty = 5000\n",
    "threshold = 0.55\n",
    "K=4\n",
    "do_only=True\n",
    "# tracts/distributions\n",
    "S=12\n",
    "# history/features\n",
    "H = 3\n",
    "# total timepoints\n",
    "T= 500\n",
    "perturbed_sigma=0.1\n",
    "num_score_func_samples=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = example_datasets(H, T, seed=seed)\n",
    "train_X_THS, train_y_TS = to_numpy(train_dataset)\n",
    "val_X_THS, val_y_TS = to_numpy(val_dataset)\n",
    "input_shape = (H,S)\n",
    "\n",
    "bpr_K = get_perturbed_bpr_func(K, sigma=perturbed_sigma)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, mix_weights  = mixture_poissons(location_specific_linear, input_shape, num_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss: 655.6746215820312\n",
      "NLL: -133.47491455078125\n",
      "BPR: 0.5035321712493896\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "training_loop_score_function_trick(model, optimizer, epochs, train_dataset, val_dataset,\n",
    "                                       cross_ratio_decision, bpr_K,\n",
    "                                       objective_includes_likelihood=True,\n",
    "                                       objective_includes_bpr=True,\n",
    "                                       bpr_threshold=threshold,\n",
    "                                       penalty=penalty,\n",
    "                                       num_score_func_samples=num_score_func_samples,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled check-numerics callback in thread MainThread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss: 667.5817260742188\n",
      "NLL: -133.47491455078125\n",
      "BPR: 0.5065986514091492\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/MixtureSameFamily/log_prob/Poisson/log_prob/Shape_2/CheckNumericsV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_33876/463751284.py\", line 65, in <module>\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 212, in f\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/core/function/capture/capture_container.py\", line 125, in capture_by_value\n\n!!! Detected Infinity or NaN in output 0 of graph op \"Const\" (# of outputs: 1) !!!\n  dtype: <dtype: 'float32'>\n  shape: ()\n  Graph name: \"f\"\n\n  Stack trace of op's creation (\"->\": inferred user code):\n    + ... (Omitted 29 frames)\n    + .../eager/polymorphic_function/tracing_compilation.py (L178) trace_function\n    |   \n    + .../eager/polymorphic_function/tracing_compilation.py (L283) _maybe_define_function\n    |   \n    + .../eager/polymorphic_function/tracing_compilation.py (L310) _create_concrete_function\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L1059) func_graph_from_py_func\n    |   \n    + ...eager/polymorphic_function/polymorphic_function.py (L598) wrapped_fn\n    |   \n    + ...ython/eager/polymorphic_function/autograph_util.py (L41) autograph_handler\n    |   \n    + ...orflow/python/ops/parallel_for/control_flow_ops.py (L212) f\n    |   \n    + ...orflow/python/ops/parallel_for/control_flow_ops.py (L309) _pfor_impl\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L1160) loop_fn\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L1066) gradient\n    |   \n    + ...ackages/tensorflow/python/eager/imperative_grad.py (L67) imperative_grad\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L148) _gradient_function\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L1657) _SelectGradV2\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L142) _ReduceGradientArgs\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L75) SmartBroadcastGradientArgs\n    |   \n    + ...packages/tensorflow/python/util/traceback_utils.py (L150) error_handler\n    |   \n    + ...1/site-packages/tensorflow/python/util/dispatch.py (L1260) op_dispatch_handler\n    |   \n    + ...1/site-packages/tensorflow/python/ops/array_ops.py (L688) shape\n    |   \n    + ...1/site-packages/tensorflow/python/ops/array_ops.py (L718) shape_internal\n    |   \n    + .../site-packages/tensorflow/python/profiler/trace.py (L183) wrapped\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L696) convert_to_tensor\n    |   \n    + ...low/python/framework/tensor_conversion_registry.py (L209) convert\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L590) __tf_tensor__\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L675) capture\n    |   \n    + ...sorflow/core/function/capture/capture_container.py (L125) capture_by_value\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L603) _capture_as_const\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L268) _create_graph_constant\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L670) _create_op_internal\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L2652) _create_op_internal\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L1160) from_node_def\n    |   \n\n : Tensor had -Inf values\n\t [[{{node gradient_tape/MixtureSameFamily/log_prob/Poisson/log_prob/Shape_2/CheckNumericsV2}}]] [Op:__inference_f_5832]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbpr\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m jacobian_pMBS \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian_tape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_log_probs_MBS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m param_gradient_pBS \u001b[38;5;241m=\u001b[39m [score_function_trick(j, sample_decisions_MBS) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m jacobian_pMBS]\n\u001b[1;32m     68\u001b[0m loss_gradients_BS \u001b[38;5;241m=\u001b[39m loss_tape\u001b[38;5;241m.\u001b[39mgradient(loss_B, expected_decisions_BS)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1170\u001b[0m, in \u001b[0;36mGradientTape.jacobian\u001b[0;34m(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experimental_use_pfor:\n\u001b[1;32m   1169\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpfor_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpfor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an exception while vectorizing the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian computation. Vectorization can be disabled by setting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m experimental_use_pfor to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:228\u001b[0m, in \u001b[0;36mpfor\u001b[0;34m(loop_fn, iters, fallback_to_while_loop, parallel_iterations, warn)\u001b[0m\n\u001b[1;32m    225\u001b[0m     def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    226\u001b[0m   f \u001b[38;5;241m=\u001b[39m def_function\u001b[38;5;241m.\u001b[39mfunction(f)\n\u001b[0;32m--> 228\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functions_run_eagerly \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m   def_function\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(functions_run_eagerly)\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/MixtureSameFamily/log_prob/Poisson/log_prob/Shape_2/CheckNumericsV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_33876/463751284.py\", line 65, in <module>\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 212, in f\n\n  File \"/cluster/tufts/hugheslab/kheuto01/mambaforge/envs/pip_k2_tf/lib/python3.11/site-packages/tensorflow/core/function/capture/capture_container.py\", line 125, in capture_by_value\n\n!!! Detected Infinity or NaN in output 0 of graph op \"Const\" (# of outputs: 1) !!!\n  dtype: <dtype: 'float32'>\n  shape: ()\n  Graph name: \"f\"\n\n  Stack trace of op's creation (\"->\": inferred user code):\n    + ... (Omitted 29 frames)\n    + .../eager/polymorphic_function/tracing_compilation.py (L178) trace_function\n    |   \n    + .../eager/polymorphic_function/tracing_compilation.py (L283) _maybe_define_function\n    |   \n    + .../eager/polymorphic_function/tracing_compilation.py (L310) _create_concrete_function\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L1059) func_graph_from_py_func\n    |   \n    + ...eager/polymorphic_function/polymorphic_function.py (L598) wrapped_fn\n    |   \n    + ...ython/eager/polymorphic_function/autograph_util.py (L41) autograph_handler\n    |   \n    + ...orflow/python/ops/parallel_for/control_flow_ops.py (L212) f\n    |   \n    + ...orflow/python/ops/parallel_for/control_flow_ops.py (L309) _pfor_impl\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L1160) loop_fn\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L1066) gradient\n    |   \n    + ...ackages/tensorflow/python/eager/imperative_grad.py (L67) imperative_grad\n    |   \n    + .../site-packages/tensorflow/python/eager/backprop.py (L148) _gradient_function\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L1657) _SelectGradV2\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L142) _ReduceGradientArgs\n    |   \n    + ...1/site-packages/tensorflow/python/ops/math_grad.py (L75) SmartBroadcastGradientArgs\n    |   \n    + ...packages/tensorflow/python/util/traceback_utils.py (L150) error_handler\n    |   \n    + ...1/site-packages/tensorflow/python/util/dispatch.py (L1260) op_dispatch_handler\n    |   \n    + ...1/site-packages/tensorflow/python/ops/array_ops.py (L688) shape\n    |   \n    + ...1/site-packages/tensorflow/python/ops/array_ops.py (L718) shape_internal\n    |   \n    + .../site-packages/tensorflow/python/profiler/trace.py (L183) wrapped\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L696) convert_to_tensor\n    |   \n    + ...low/python/framework/tensor_conversion_registry.py (L209) convert\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L590) __tf_tensor__\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L675) capture\n    |   \n    + ...sorflow/core/function/capture/capture_container.py (L125) capture_by_value\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L603) _capture_as_const\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L268) _create_graph_constant\n    |   \n    + ...packages/tensorflow/python/framework/func_graph.py (L670) _create_op_internal\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L2652) _create_op_internal\n    |   \n    + ...1/site-packages/tensorflow/python/framework/ops.py (L1160) from_node_def\n    |   \n\n : Tensor had -Inf values\n\t [[{{node gradient_tape/MixtureSameFamily/log_prob/Poisson/log_prob/Shape_2/CheckNumericsV2}}]] [Op:__inference_f_5832]"
     ]
    }
   ],
   "source": [
    "#check numerics\n",
    "tf.debugging.enable_check_numerics()\n",
    "\n",
    "losses = {}\n",
    "losses['train'] = {}\n",
    "losses['val'] ={}\n",
    "losses['train']['loss']=[]\n",
    "losses['train']['nll']=[]\n",
    "losses['train']['bpr']=[]\n",
    "losses['val']['loss']=[]\n",
    "losses['val']['nll']=[]\n",
    "losses['val']['bpr']=[]\n",
    "verbose=True\n",
    "for epoch in range(1):\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch}')\n",
    "        else:\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}')\n",
    "\n",
    "        for step, (x_BHS, y_BS) in enumerate(train_dataset):\n",
    "            \n",
    "            with tf.GradientTape() as jacobian_tape, tf.GradientTape() as loss_tape:\n",
    "                prob_params_BSK, mixture_weights_KS = model(x_BHS, training=True)\n",
    "\n",
    "                # my fault that model returns KS instead of SK\n",
    "                mixture_weights_SK = tf.transpose(mixture_weights_KS, perm=[1,0])\n",
    "\n",
    "                #  could create a custom model class that returns \n",
    "                # the appropriate tfp.dist given outputs\n",
    "                mix = tfp.distributions.MixtureSameFamily(\n",
    "                    mixture_distribution=tfp.distributions.Categorical(probs=mixture_weights_SK),\n",
    "                    components_distribution = tfp.distributions.Poisson(rate=prob_params_BSK+1e-13))\n",
    "\n",
    "                # add constant to avoid log 0\n",
    "                sample_y_MBS = mix.sample(num_score_func_samples)+1e-13\n",
    "\n",
    "                sample_log_probs_MBS = mix.log_prob(sample_y_MBS)\n",
    "                sample_decisions_MBS = cross_ratio_decision(sample_y_MBS)\n",
    "                expected_decisions_BS = tf.reduce_mean(sample_decisions_MBS, axis=0)\n",
    "                bpr_B = bpr_K(y_BS, expected_decisions_BS)\n",
    "                observed_log_prob_BS = mix.log_prob(y_BS)\n",
    "\n",
    "                loss_B = tf.zeros_like(bpr_B)\n",
    "\n",
    "                if True:\n",
    "                    loss_B -= tf.reduce_sum(observed_log_prob_BS, axis=-1)\n",
    "                if True:\n",
    "                    violate_threshold_flag_B = tf.cast(tf.greater(threshold,\n",
    "                                                                bpr_B),\n",
    "                                                        tf.float32)\n",
    "                    loss_B += penalty * violate_threshold_flag_B *(threshold - bpr_B)\n",
    "\n",
    "            losses['train']['loss'].append(tf.reduce_mean(loss_B))\n",
    "            losses['train']['nll'].append(tf.reduce_mean(tf.reduce_sum(observed_log_prob_BS, axis=-1)))\n",
    "            losses['train']['bpr'].append(tf.reduce_mean(bpr_B))\n",
    "            \n",
    "            if verbose:\n",
    "                # print all metrics\n",
    "                print(f'Loss: {losses[\"train\"][\"loss\"][-1]}')\n",
    "                print(f'NLL: {losses[\"train\"][\"nll\"][-1]}')\n",
    "                print(f'BPR: {losses[\"train\"][\"bpr\"][-1]}')\n",
    "            \n",
    "            # The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\n",
    "            jacobian_pMBS = jacobian_tape.jacobian(sample_log_probs_MBS, model.trainable_weights)\n",
    "            param_gradient_pBS = [score_function_trick(j, sample_decisions_MBS) for j in jacobian_pMBS]\n",
    "\n",
    "            loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)\n",
    "            overall_gradient = [overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]\n",
    "\n",
    "            # Run one step of gradient descent by updating\n",
    "            # the value of the variables to minimize the loss.\n",
    "            optimizer.apply_gradients(zip(overall_gradient, model.trainable_weights))\n",
    "\n",
    "            \n",
    "                \n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[ 0.33118924],\n",
       "         [-0.46106085],\n",
       "         [-0.2423242 ]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.00499997], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[1.176708  ],\n",
       "         [0.85288453],\n",
       "         [1.1648061 ]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([-0.00499997], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[ 0.47222552],\n",
       "         [-0.03634611],\n",
       "         [ 0.96142197]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.00499997], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[nan],\n",
       "         [nan],\n",
       "         [nan]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([nan], dtype=float32)>,\n",
       " <tf.Variable 'shared_mix_weights:0' shape=(4, 12) dtype=float32, numpy=\n",
       " array([[-0.00753931,  0.04140931,  0.02127313, -0.00664703,  0.00728092,\n",
       "         -0.03138736, -0.00405064,  0.00291569,  0.01632748, -0.032806  ,\n",
       "         -0.03485059,  0.01941011],\n",
       "        [-0.02803491, -0.01148996,  0.00693231, -0.0079584 ,  0.03636416,\n",
       "         -0.00148434,  0.04144203,  0.02340915,  0.00176061, -0.04569011,\n",
       "         -0.04252014, -0.05215028],\n",
       "        [-0.01849982,  0.04280168, -0.04391516, -0.04431397,  0.0112157 ,\n",
       "         -0.00527929, -0.03875327, -0.03039983, -0.03891236,  0.02623072,\n",
       "          0.00621123, -0.04248647],\n",
       "        [ 0.04329732,  0.02666374,  0.03696346, -0.03572372, -0.00672281,\n",
       "          0.01561751,  0.03259334,  0.00375888,  0.04284676, -0.00845261,\n",
       "          0.00151045,  0.04476148]], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab3e23a1150>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train']['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1432462443.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    jacobian_pMBS = jacobian_tape.jacobian(sample_log_probs_MBS, model.trainable_weights)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\n",
    "jacobian_pMBS = jacobian_tape.jacobian(sample_log_probs_MBS, model.trainable_weights)\n",
    "param_gradient_pBS = [score_function_trick(j, sample_decisions_MBS) for j in jacobian_pMBS]\n",
    "\n",
    "loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)\n",
    "overall_gradient = [overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]\n",
    "\n",
    "# Run one step of gradient descent by updating\n",
    "# the value of the variables to minimize the loss.\n",
    "optimizer.apply_gradients(zip(overall_gradient, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lowercase \"p\" signifies that these are lists of length P, P = number of trainable variables\n",
    "jacobian_pMBS = jacobian_tape.jacobian(sample_log_probs_MBS, model.trainable_weights)\n",
    "param_gradient_pBS = [score_function_trick(j, sample_decisions_MBS) for j in jacobian_pMBS]\n",
    "\n",
    "\n",
    "loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gradients_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[43moverall_gradient_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_gradients_BS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam_gradient_pBS\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[43moverall_gradient_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_gradients_BS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m param_gradient_pBS]\n",
      "File \u001b[0;32m~/code/prob_diff_topk/experiments.py:68\u001b[0m, in \u001b[0;36moverall_gradient_calculation\u001b[0;34m(gradient_BSp, decision_gradient_BS)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moverall_gradient_calculation\u001b[39m(gradient_BSp, decision_gradient_BS):\n\u001b[1;32m     66\u001b[0m     num_param_dims \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrank(gradient_BSp)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 68\u001b[0m     decision_gradient_BSp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(decision_gradient_BS, \u001b[43mdecision_gradient_BS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mnum_param_dims\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     70\u001b[0m     overall_gradient_BSp \u001b[38;5;241m=\u001b[39m gradient_BSp\u001b[38;5;241m*\u001b[39mdecision_gradient_BSp\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# sum over batch and location\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "[overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gradients_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_gradients_BS \u001b[38;5;241m=\u001b[39m loss_tape\u001b[38;5;241m.\u001b[39mgradient(loss_B, expected_decisions_BS)\n\u001b[0;32m----> 2\u001b[0m overall_gradient \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43moverall_gradient_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_gradients_BS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam_gradient_pBS\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_gradients_BS \u001b[38;5;241m=\u001b[39m loss_tape\u001b[38;5;241m.\u001b[39mgradient(loss_B, expected_decisions_BS)\n\u001b[0;32m----> 2\u001b[0m overall_gradient \u001b[38;5;241m=\u001b[39m [\u001b[43moverall_gradient_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_gradients_BS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m param_gradient_pBS]\n",
      "File \u001b[0;32m~/code/prob_diff_topk/experiments.py:68\u001b[0m, in \u001b[0;36moverall_gradient_calculation\u001b[0;34m(gradient_BSp, decision_gradient_BS)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moverall_gradient_calculation\u001b[39m(gradient_BSp, decision_gradient_BS):\n\u001b[1;32m     66\u001b[0m     num_param_dims \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrank(gradient_BSp)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 68\u001b[0m     decision_gradient_BSp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(decision_gradient_BS, \u001b[43mdecision_gradient_BS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mnum_param_dims\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     70\u001b[0m     overall_gradient_BSp \u001b[38;5;241m=\u001b[39m gradient_BSp\u001b[38;5;241m*\u001b[39mdecision_gradient_BSp\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# sum over batch and location\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_gradients_BS = loss_tape.gradient(loss_B, expected_decisions_BS)\n",
    "overall_gradient = [overall_gradient_calculation(g, loss_gradients_BS) for g in param_gradient_pBS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_farction_trick(jacobian_MBSp, decision_MBS):\n",
    "    num_param_dims = tf.rank(jacobian_MBSp)-3\n",
    "    # expand decision to match jacobian\n",
    "    decision_MBSp = tf.reshape(decision_MBS, decision_MBS.shape + [1]*num_param_dims.numpy())\n",
    "\n",
    "    scaled_jacobian_MBSp = jacobian_MBSp*decision_MBSp\n",
    "\n",
    "    # average over sample dims\n",
    "    param_gradient_BSp = tf.reduce_mean(scaled_jacobian_MBSp, axis=0)\n",
    "\n",
    "    return param_gradient_BSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(300, 12, 1, 3, 1), dtype=float32, numpy=\n",
       " array([[[[[-9.8181177e-17],\n",
       "           [-9.8181177e-17],\n",
       "           [-9.8181177e-17]]],\n",
       " \n",
       " \n",
       "         [[[ 4.7618383e-14],\n",
       "           [ 4.7618383e-14],\n",
       "           [ 4.7618383e-14]]],\n",
       " \n",
       " \n",
       "         [[[-5.6410694e-17],\n",
       "           [-5.6410694e-17],\n",
       "           [-5.6410694e-17]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1194237e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-7.8514343e-17],\n",
       "           [-7.8514343e-17],\n",
       "           [-7.8514343e-17]]],\n",
       " \n",
       " \n",
       "         [[[-3.3463604e-16],\n",
       "           [-3.3463604e-16],\n",
       "           [-3.3463604e-16]]],\n",
       " \n",
       " \n",
       "         [[[ 3.6076076e-11],\n",
       "           [ 3.6076076e-11],\n",
       "           [ 3.6076076e-11]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [-2.1486676e-24]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[ 1.1691131e-11],\n",
       "           [ 1.1691131e-11],\n",
       "           [ 1.1691131e-11]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-9.4384769e-17],\n",
       "           [-9.4384769e-17],\n",
       "           [-9.4384769e-17]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 2.2126395e-27],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-2.5177750e-16],\n",
       "           [-2.5177750e-16],\n",
       "           [-2.5177750e-16]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6597620e-15],\n",
       "           [ 1.6597620e-15],\n",
       "           [ 1.6597620e-15]]],\n",
       " \n",
       " \n",
       "         [[[-2.5646112e-16],\n",
       "           [-2.5646112e-16],\n",
       "           [-2.5646112e-16]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 4.0933831e-27],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[ 1.2570779e-15],\n",
       "           [ 1.2570779e-15],\n",
       "           [ 1.2570779e-15]]],\n",
       " \n",
       " \n",
       "         [[[ 7.9637936e-14],\n",
       "           [ 7.9637936e-14],\n",
       "           [ 7.9637936e-14]]],\n",
       " \n",
       " \n",
       "         [[[ 8.4394324e-14],\n",
       "           [ 8.4394324e-14],\n",
       "           [ 8.4394324e-14]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8747600e-01],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-8.6031548e-17],\n",
       "           [-8.6031548e-17],\n",
       "           [-8.6031548e-17]]],\n",
       " \n",
       " \n",
       "         [[[-3.4442027e-17],\n",
       "           [-3.4442027e-17],\n",
       "           [-3.4442027e-17]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7515465e-14],\n",
       "           [ 6.7515465e-14],\n",
       "           [ 6.7515465e-14]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [-7.5484177e-25]]],\n",
       " \n",
       " \n",
       "         [[[-1.4445145e-01],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1), dtype=float32, numpy=\n",
       " array([[[-1.40258813e-17],\n",
       "         [ 6.80262578e-15],\n",
       "         [-8.05867063e-18],\n",
       "         ...,\n",
       "         [-5.83015160e-17],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 1.11942375e-02]],\n",
       " \n",
       "        [[-1.12163342e-17],\n",
       "         [-4.78051466e-17],\n",
       "         [ 5.15372510e-12],\n",
       "         ...,\n",
       "         [-2.14866759e-26],\n",
       "         [ 2.06450772e-04],\n",
       "         [ 6.74634357e-04]],\n",
       " \n",
       "        [[ 1.67016162e-12],\n",
       "         [ 0.00000000e+00],\n",
       "         [-1.34835378e-17],\n",
       "         ...,\n",
       "         [ 2.07481906e-03],\n",
       "         [ 2.21263952e-29],\n",
       "         [ 7.32786674e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-3.59682152e-17],\n",
       "         [ 2.37108874e-16],\n",
       "         [-3.66373017e-17],\n",
       "         ...,\n",
       "         [-1.49509415e-16],\n",
       "         [ 4.09338324e-29],\n",
       "         [ 2.21364389e-04]],\n",
       " \n",
       "        [[ 1.79582552e-16],\n",
       "         [ 1.13768476e-14],\n",
       "         [ 1.20563324e-14],\n",
       "         ...,\n",
       "         [ 1.47631357e-03],\n",
       "         [-1.15526202e-16],\n",
       "         [ 7.87475985e-03]],\n",
       " \n",
       "        [[-1.22902198e-17],\n",
       "         [-4.92028949e-18],\n",
       "         [ 9.64506591e-15],\n",
       "         ...,\n",
       "         [-7.54841818e-27],\n",
       "         [-1.44451461e-03],\n",
       "         [ 0.00000000e+00]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1, 3, 1), dtype=float32, numpy=\n",
       " array([[[[[-3.3127627e-25],\n",
       "           [-3.3127627e-25],\n",
       "           [-3.3127627e-25]]],\n",
       " \n",
       " \n",
       "         [[[-1.6763281e-04],\n",
       "           [-1.6763281e-04],\n",
       "           [-1.6763281e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.0432426e-03],\n",
       "           [-1.0432426e-03],\n",
       "           [-1.0432426e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 8.0270070e-01],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-2.2206739e-01],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[ 5.7800747e-02],\n",
       "           [ 5.7800747e-02],\n",
       "           [ 5.7800747e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0822285e-24],\n",
       "           [-1.0822285e-24],\n",
       "           [-1.0822285e-24]]],\n",
       " \n",
       " \n",
       "         [[[-4.6540526e-04],\n",
       "           [-4.6540526e-04],\n",
       "           [-4.6540526e-04]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [-1.7545382e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-1.5140510e-04],\n",
       "           [-1.5140510e-04],\n",
       "           [-1.5140510e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.2061441e-01],\n",
       "           [-1.2061441e-01],\n",
       "           [-1.2061441e-01]]],\n",
       " \n",
       " \n",
       "         [[[-9.0337088e-03],\n",
       "           [-9.0337088e-03],\n",
       "           [-9.0337088e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [-3.9255701e-06],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-8.4953062e-25],\n",
       "           [-8.4953062e-25],\n",
       "           [-8.4953062e-25]]],\n",
       " \n",
       " \n",
       "         [[[-1.7550858e-03],\n",
       "           [-1.7550858e-03],\n",
       "           [-1.7550858e-03]]],\n",
       " \n",
       " \n",
       "         [[[-8.6201316e-25],\n",
       "           [-8.6201316e-25],\n",
       "           [-8.6201316e-25]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [-3.0512512e-01],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-1.3899617e-03],\n",
       "           [-1.3899617e-03],\n",
       "           [-1.3899617e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.8046258e-04],\n",
       "           [-2.8046258e-04],\n",
       "           [-2.8046258e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 2.4699086e-01],\n",
       "           [ 2.4699086e-01],\n",
       "           [ 2.4699086e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-2.7112439e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-2.9028183e-25],\n",
       "           [-2.9028183e-25],\n",
       "           [-2.9028183e-25]]],\n",
       " \n",
       " \n",
       "         [[[-2.5223447e-02],\n",
       "           [-2.5223447e-02],\n",
       "           [-2.5223447e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3778989e-02],\n",
       "           [ 6.3778989e-02],\n",
       "           [ 6.3778989e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-1.5041111e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 0.0000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000000e+00],\n",
       "           [ 0.0000000e+00],\n",
       "           [ 5.4571843e-01]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1), dtype=float32, numpy=\n",
       " array([[[-4.7325183e-26],\n",
       "         [-2.3947543e-05],\n",
       "         [-1.4903466e-04],\n",
       "         ...,\n",
       "         [-5.8133605e-17],\n",
       "         [ 8.0270078e-03],\n",
       "         [-2.2206740e-03]],\n",
       " \n",
       "        [[ 8.2572494e-03],\n",
       "         [-1.5460407e-25],\n",
       "         [-6.6486464e-05],\n",
       "         ...,\n",
       "         [-1.7545383e-02],\n",
       "         [ 2.0487346e-04],\n",
       "         [ 6.3435599e-04]],\n",
       " \n",
       "        [[-2.1629299e-05],\n",
       "         [-1.7230630e-02],\n",
       "         [-1.2905300e-03],\n",
       "         ...,\n",
       "         [ 2.0688432e-03],\n",
       "         [-3.9255703e-08],\n",
       "         [ 6.8903631e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.2136152e-25],\n",
       "         [-2.5072653e-04],\n",
       "         [-1.2314474e-25],\n",
       "         ...,\n",
       "         [-1.4907882e-16],\n",
       "         [-3.0512512e-03],\n",
       "         [ 2.0814805e-04]],\n",
       " \n",
       "        [[-1.9856595e-04],\n",
       "         [-4.0066083e-05],\n",
       "         [ 3.5284407e-02],\n",
       "         ...,\n",
       "         [ 1.4720616e-03],\n",
       "         [-1.1464358e-16],\n",
       "         [-2.7112439e-02]],\n",
       " \n",
       "        [[-4.1468834e-26],\n",
       "         [-3.6033494e-03],\n",
       "         [ 9.1112843e-03],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [-1.5041110e-02],\n",
       "         [ 5.4571852e-03]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1, 3, 1), dtype=float32, numpy=\n",
       " array([[[[[-1.03185896e-19],\n",
       "           [-1.03185896e-19],\n",
       "           [-1.03185896e-19]]],\n",
       " \n",
       " \n",
       "         [[[-1.85372904e-02],\n",
       "           [-1.85372904e-02],\n",
       "           [-1.85372904e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.42432566e-03],\n",
       "           [ 4.42432566e-03],\n",
       "           [ 4.42432566e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-7.60089755e-01],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[ 3.65532539e-03],\n",
       "           [ 3.65532539e-03],\n",
       "           [ 3.65532539e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.56065271e-19],\n",
       "           [-3.56065271e-19],\n",
       "           [-3.56065271e-19]]],\n",
       " \n",
       " \n",
       "         [[[-1.61136895e-01],\n",
       "           [-1.61136895e-01],\n",
       "           [-1.61136895e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 2.15900731e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-5.45811243e-02],\n",
       "           [-5.45811243e-02],\n",
       "           [-5.45811243e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.83809714e-02],\n",
       "           [ 2.83809714e-02],\n",
       "           [ 2.83809714e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.42326409e-03],\n",
       "           [ 2.42326409e-03],\n",
       "           [ 2.42326409e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [-3.61122306e-16],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-2.64611692e-19],\n",
       "           [-2.64611692e-19],\n",
       "           [-2.64611692e-19]]],\n",
       " \n",
       " \n",
       "         [[[-3.64793055e-02],\n",
       "           [-3.64793055e-02],\n",
       "           [-3.64793055e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.57872806e-19],\n",
       "           [-2.57872806e-19],\n",
       "           [-2.57872806e-19]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [-6.68076273e-16],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-2.73508653e-02],\n",
       "           [-2.73508653e-02],\n",
       "           [-2.73508653e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.10143139e-02],\n",
       "           [-3.10143139e-02],\n",
       "           [-3.10143139e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.09073906e-02],\n",
       "           [-3.09073906e-02],\n",
       "           [-3.09073906e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-7.21873343e-01],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[-9.04169479e-20],\n",
       "           [-9.04169479e-20],\n",
       "           [-9.04169479e-20]]],\n",
       " \n",
       " \n",
       "         [[[ 8.20571035e-02],\n",
       "           [ 8.20571035e-02],\n",
       "           [ 8.20571035e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.47796942e-02],\n",
       "           [-2.47796942e-02],\n",
       "           [-2.47796942e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[-1.86586693e-01],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 1.16157246e+00]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1), dtype=float32, numpy=\n",
       " array([[[-1.4740843e-20],\n",
       "         [-2.6481845e-03],\n",
       "         [ 6.3204655e-04],\n",
       "         ...,\n",
       "         [-6.2468653e-17],\n",
       "         [ 0.0000000e+00],\n",
       "         [-7.6008975e-03]],\n",
       " \n",
       "        [[ 5.2218931e-04],\n",
       "         [-5.0866473e-20],\n",
       "         [-2.3019556e-02],\n",
       "         ...,\n",
       "         [ 2.1590073e-02],\n",
       "         [ 2.1726626e-04],\n",
       "         [ 6.3414290e-04]],\n",
       " \n",
       "        [[-7.7973031e-03],\n",
       "         [ 4.0544244e-03],\n",
       "         [ 3.4618058e-04],\n",
       "         ...,\n",
       "         [ 2.2231175e-03],\n",
       "         [-3.6112228e-18],\n",
       "         [ 6.8880497e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-3.7801669e-20],\n",
       "         [-5.2113296e-03],\n",
       "         [-3.6838973e-20],\n",
       "         ...,\n",
       "         [-1.6019569e-16],\n",
       "         [-6.6807623e-18],\n",
       "         [ 2.0807814e-04]],\n",
       " \n",
       "        [[-3.9072665e-03],\n",
       "         [-4.4306167e-03],\n",
       "         [-4.4153417e-03],\n",
       "         ...,\n",
       "         [ 1.5818336e-03],\n",
       "         [-1.2157840e-16],\n",
       "         [-7.2187334e-03]],\n",
       " \n",
       "        [[-1.2916706e-20],\n",
       "         [ 1.1722444e-02],\n",
       "         [-3.5399566e-03],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [-1.8658669e-03],\n",
       "         [ 1.1615724e-02]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1, 3, 1), dtype=float32, numpy=\n",
       " array([[[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]],\n",
       " \n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       " \n",
       "        [[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]],\n",
       " \n",
       " \n",
       "         [[[nan],\n",
       "           [nan],\n",
       "           [nan]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 1), dtype=float32, numpy=\n",
       " array([[[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       " \n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       " \n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       " \n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]],\n",
       " \n",
       "        [[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         ...,\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(300, 12, 4, 12), dtype=float32, numpy=\n",
       " array([[[[ 1.05912312e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.16576470e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.16507542e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 1.27171714e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00, -3.91377229e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -3.63786099e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  1.14081185e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -3.85648478e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00, -4.87624155e-03, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -4.48903674e-03, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  1.43186329e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -4.95335460e-03, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -7.11210329e-24,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            7.11210329e-24,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.42242050e-23,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.42242050e-23,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.00764401e-01,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  3.12353402e-01,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.06043234e-01,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.05545774e-01,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.73230544e-02],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  1.44043386e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -3.93532068e-02],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -8.73671323e-02]]],\n",
       " \n",
       " \n",
       "        [[[-6.82625771e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 2.06552505e-01,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-6.64673969e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-7.18225315e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  3.65060718e-16,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -3.77011771e-16,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -3.97995239e-16,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  4.09946371e-16,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00, -2.12116539e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.06047278e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  6.33634776e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.15470977e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -9.97733399e-02,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.27104461e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            7.49018416e-02,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.02232978e-01,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  4.29763586e-11,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  9.99571953e-11,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.28375741e-10,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.45578168e-11,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -3.09373055e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.34689773e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  4.26906253e-11],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  4.01372185e-10]]],\n",
       " \n",
       " \n",
       "        [[[-7.03688525e-03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-6.86261943e-03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 2.13033706e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-7.40386546e-03,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00, -4.34806868e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  1.25365630e-01,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -3.90406996e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -4.28442433e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00, -2.25801468e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  6.64006919e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.08833143e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.29372308e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -3.27966161e-11,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.66946873e-10,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -3.03630149e-10,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            5.03373621e-10,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -3.94140817e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -3.91128734e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -4.14788984e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  1.20005853e-01,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -4.02316097e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -3.37779027e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  4.29354108e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  3.10740933e-10]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 2.71603364e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-2.98950723e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-2.98773958e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 3.26121343e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00, -1.91530269e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -1.75653622e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  5.55910692e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -1.88726764e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  2.75927071e-16, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -3.04054494e-16, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.91847955e-16, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  3.19975325e-16, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.82383994e-23,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.82384026e-23,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            3.64767957e-23,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -3.64767957e-23,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -8.01830292e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  2.48554319e-01,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -8.43836367e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -8.39876533e-02,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.01513034e-10],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -4.41950816e-11],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  1.40078608e-11],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  1.31700248e-10]]],\n",
       " \n",
       " \n",
       "        [[[-1.40235079e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.34063382e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 4.21846919e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.47548467e-02,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00, -6.54804241e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -6.08642120e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  1.90866608e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -6.45219581e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00, -4.94802594e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  1.20520309e-01, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -2.07773075e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -5.02627417e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -2.33360536e-11,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.18789117e-10,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -2.16044529e-10,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            3.58169716e-10,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -3.12550872e-24,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  1.10952521e-23,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  1.00618846e-23,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -1.80316280e-23,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  4.21429053e-02],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  2.14100271e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.08702973e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.47540212e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 9.28059788e-17,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.02150479e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [-1.02090082e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 1.11434596e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00, -9.16726235e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  1.05405273e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  1.71462856e-02,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00, -9.03307647e-03,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00, -1.63420029e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  2.77931616e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  5.14927693e-03, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00, -1.66004375e-02, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            3.16048745e-16,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.01879508e-16,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.09476666e-16,  0.00000000e+00,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.04692571e-16,  0.00000000e+00,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  1.33742727e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  1.12481102e-01,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -6.01218604e-02,  0.00000000e+00],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00, -6.57335296e-02,  0.00000000e+00]],\n",
       " \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.18086398e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  1.63405791e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00,  7.57989213e-02],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            0.00000000e+00,  0.00000000e+00, -1.21118307e-01]]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[score_function_trick(j, sample_decisions_MBS) for j in jacobian_pMBS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[ 0.32618928],\n",
       "         [-0.46606082],\n",
       "         [-0.24732417]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[1.181708  ],\n",
       "         [0.84788454],\n",
       "         [1.1598061 ]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[ 0.46722555],\n",
       "         [-0.04134607],\n",
       "         [ 0.956422  ]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/kernel:0' shape=(1, 3, 1) dtype=float32, numpy=\n",
       " array([[[-1.0510222 ],\n",
       "         [ 0.44143808],\n",
       "         [-1.0136535 ]]], dtype=float32)>,\n",
       " <tf.Variable 'linear_convolution/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'shared_mix_weights:0' shape=(4, 12) dtype=float32, numpy=\n",
       " array([[-0.00253935,  0.04640928,  0.0262731 , -0.00164707,  0.00228095,\n",
       "         -0.03638732, -0.00905061, -0.00208428,  0.01132752, -0.03780596,\n",
       "         -0.03985056,  0.01441014],\n",
       "        [-0.02303494, -0.01648992,  0.00193235, -0.01295837,  0.04136412,\n",
       "          0.00351562,  0.046442  ,  0.02840911, -0.00323936, -0.04069015,\n",
       "         -0.0475201 , -0.04715031],\n",
       "        [-0.02349979,  0.03780172, -0.03891519, -0.03931401,  0.00621573,\n",
       "         -0.01027926, -0.04375323, -0.02539986, -0.0339124 ,  0.03123069,\n",
       "          0.01121119, -0.04748644],\n",
       "        [ 0.04829729,  0.0316637 ,  0.04196342, -0.03072375, -0.01172278,\n",
       "          0.01061754,  0.02759338, -0.00124109,  0.04784672, -0.01345258,\n",
       "          0.00651041,  0.03976151]], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50, 300, 12), dtype=float32, numpy=\n",
       "array([[[ -0.70101863,  -4.1543083 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -4.743504  ,  -5.4328384 ],\n",
       "        [ -0.70101863,  -4.0106015 ,  -3.9229648 , ...,  -5.9634576 ,\n",
       "          -0.6931473 ,  -1.0596601 ],\n",
       "        [ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -4.6655827 ,  -0.6931472 ],\n",
       "        ...,\n",
       "        [ -0.70101863,  -3.49464   ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -6.9662623 ,  -0.6931472 ],\n",
       "        [ -0.70101863,  -4.1543083 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -1.0596601 ,  -4.6279078 ],\n",
       "        [ -4.4377975 ,  -4.2614584 ,  -4.304028  , ...,  -4.379637  ,\n",
       "          -4.1970434 ,  -4.5216155 ]],\n",
       "\n",
       "       [[ -0.70101863,  -4.944219  ,  -3.6131897 , ...,  -3.5844455 ,\n",
       "          -4.7237096 ,  -4.7751513 ],\n",
       "        [ -3.5308998 ,  -0.7111152 ,  -5.2043853 , ...,  -4.6070747 ,\n",
       "          -1.0596601 ,  -0.6931472 ],\n",
       "        [ -0.70101863,  -3.6862466 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -2.1193204 ],\n",
       "        ...,\n",
       "        [ -4.1734886 ,  -4.2659936 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        [ -3.9768908 ,  -3.6862466 ,  -0.6986769 , ...,  -2.1193204 ,\n",
       "          -0.6931473 ,  -4.4854803 ],\n",
       "        [ -3.455101  ,  -4.1134787 ,  -0.6986769 , ...,  -1.4093387 ,\n",
       "         -34.028008  ,  -4.5263796 ]],\n",
       "\n",
       "       [[ -3.5909991 ,  -3.9566472 ,  -3.503215  , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -4.2531633 ],\n",
       "        [ -0.70101863,  -0.7111152 ,  -4.1269865 , ...,  -1.4093387 ,\n",
       "          -1.0596601 ,  -0.6931472 ],\n",
       "        [ -0.70101863,  -4.1620502 ,  -0.6986769 , ...,  -2.1193204 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        ...,\n",
       "        [ -3.8770113 ,  -3.9054954 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        [ -4.186202  ,  -3.4446435 ,  -0.6986769 , ...,  -3.5844455 ,\n",
       "          -0.6931473 ,  -5.1248198 ],\n",
       "        [ -0.70101863,  -4.1543083 ,  -3.7459924 , ...,  -1.4093387 ,\n",
       "          -4.008329  ,  -4.498906  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -2.1193204 ,\n",
       "          -0.6981911 , -33.981426  ],\n",
       "        [ -3.5308998 ,  -3.6862466 ,  -0.6986769 , ...,  -4.684049  ,\n",
       "          -1.0596601 ,  -1.0596601 ],\n",
       "        [ -4.664289  ,  -3.9482121 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        ...,\n",
       "        [ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -0.6981911 ,  -1.0596601 ],\n",
       "        [ -3.4803183 ,  -3.5562396 ,  -4.2427363 , ...,  -0.6931472 ,\n",
       "          -1.0596601 ,  -4.7291613 ],\n",
       "        [ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -4.446317  ,\n",
       "          -6.4578137 ,  -1.3625014 ]],\n",
       "\n",
       "       [[ -3.766892  ,  -3.5562396 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -4.4869437 ,  -3.994617  ],\n",
       "        [ -3.9085677 ,  -0.7111152 ,  -3.7459924 , ...,  -4.4566293 ,\n",
       "          -1.0596601 ,  -0.6931472 ],\n",
       "        [ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -1.0596602 ,\n",
       "          -4.565097  ,  -0.6931472 ],\n",
       "        ...,\n",
       "        [ -3.9085677 ,  -0.7111152 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        [ -0.70101863,  -0.7111152 ,  -0.6986769 , ...,  -2.1193204 ,\n",
       "          -0.6931473 ,  -4.7306566 ],\n",
       "        [ -0.70101863,  -4.6826477 ,  -0.6986769 , ...,  -1.4093387 ,\n",
       "          -4.8597302 ,  -1.3625014 ]],\n",
       "\n",
       "       [[ -0.70101863,  -4.3215737 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -4.1950884 ,  -3.939568  ],\n",
       "        [ -0.70101863,  -4.0438085 ,  -0.6986769 , ...,  -4.4795723 ,\n",
       "          -3.5844455 ,  -0.6931472 ],\n",
       "        [ -3.9085677 ,  -0.7111152 ,  -3.5542488 , ...,  -2.1193204 ,\n",
       "          -4.3290644 ,  -1.0596601 ],\n",
       "        ...,\n",
       "        [ -4.2476397 ,  -0.7111152 ,  -0.6986769 , ...,  -0.6931472 ,\n",
       "          -0.6981911 ,  -0.6931472 ],\n",
       "        [ -4.1734886 ,  -3.9566472 ,  -3.5542488 , ...,  -1.0596602 ,\n",
       "          -0.6931473 ,  -3.9884465 ],\n",
       "        [ -0.70101863,  -4.1620502 ,  -3.6131897 , ...,  -4.4566293 ,\n",
       "         -34.028008  ,  -1.3625014 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_log_probs_MBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=133.47491>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses['train']['loss'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k2_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
