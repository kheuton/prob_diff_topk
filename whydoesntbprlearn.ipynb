{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 13:56:07.931534: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-22 13:56:09.153530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-22 13:56:09.153655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-22 13:56:09.445243: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-22 13:56:09.851644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-22 13:56:13.673492: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch \n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "# Cd to code\n",
    "import os\n",
    "import sys\n",
    "os.chdir('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "sys.path.append('/cluster/home/kheuto01/code/prob_diff_topk')\n",
    "\n",
    "from datasets import example_datasets, to_numpy\n",
    "from torch_models import  MixtureOfTruncNormModel, torch_bpr_uncurried, deterministic_bpr\n",
    "from torch_perturb.torch_pert_topk import PerturbedTopK\n",
    "from distributions import QuantizedNormal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =360\n",
    "num_components=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_noise=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracts/distributions\n",
    "S=23\n",
    "\n",
    "# total timepoints\n",
    "T= 500\n",
    "K=3\n",
    "\n",
    "low_set_1_10 = [QuantizedNormal(10, 0.3) for _ in range(10)]\n",
    "low_set_2_10 = [QuantizedNormal(30, 0.3) for _ in range(10)]\n",
    "high_set_3 = [QuantizedNormal(50,3) for _ in range(3)]\n",
    "\n",
    "dist_S = low_set_1_10 + low_set_2_10 + high_set_3\n",
    "\n",
    "train_y_TS = np.zeros((T, S))\n",
    "for s, dist in enumerate(dist_S):\n",
    "    random_state = np.random.RandomState(10000 * seed + s*123456)\n",
    "    train_y_TS[:, s] = dist.rvs(size=T, random_state=random_state)\n",
    "\n",
    "model = MixtureOfTruncNormModel(num_components=num_components, S=S, low=0, high=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = torch.tensor([1, 10])\n",
    "softinv_means = means + torch.log(-torch.expm1(-means))\n",
    "scales = torch.tensor([0.25, 0.25])\n",
    "softinv_scales = scales - 0.2 + torch.log(-torch.expm1(-scales + 0.2)) \n",
    "#mix_weights = torch.log(1e-13 + torch.tensor(\n",
    "#                                [[1,0]*20+[0,1]*3]))\n",
    "mix_weights = torch.log(1e-13 + torch.tensor([[0.5, 0.5]*23]))\n",
    "model.update_params(torch.cat([softinv_means, softinv_scales, mix_weights.view(-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_score_func =  200\n",
    "M_action = 200\n",
    "train_T = train_y_TS.shape[0]\n",
    "perturbed_top_K_func = PerturbedTopK(k=K, sigma=perturbed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer.zero_grad()\n",
    "mix_model = model()\n",
    "\n",
    "y_sample_TMS = mix_model.sample((train_T, M_score_func))\n",
    "y_sample_action_TMS = y_sample_TMS # AM I A DUMBASS???? mix_model.sample((train_T, M_action))\n",
    "\n",
    "ratio_rating_TMS = y_sample_action_TMS/y_sample_action_TMS.sum(dim=-1, keepdim=True)\n",
    "ratio_rating_TS =  ratio_rating_TMS.mean(dim=1)\n",
    "ratio_rating_TS.requires_grad_(True)\n",
    "\n",
    "def get_log_probs_baked(param):\n",
    "    distribution = model.build_from_single_tensor(param)\n",
    "    log_probs_TMS = distribution.log_prob(y_sample_TMS)\n",
    "\n",
    "    return log_probs_TMS\n",
    "\n",
    "jac_TMSP = torch.autograd.functional.jacobian(get_log_probs_baked, (model.params_to_single_tensor()), strategy='forward-mode', vectorize=True)\n",
    "\n",
    "score_func_estimator_TMSP = jac_TMSP * ratio_rating_TMS.unsqueeze(-1)\n",
    "score_func_estimator_TSP = score_func_estimator_TMSP.mean(dim=1)    \n",
    "\n",
    "# get gradient of negative bpr_t  with respect to ratio rating_TS\n",
    "positive_bpr_T = torch_bpr_uncurried(ratio_rating_TS, torch.tensor(train_y_TS), K=K, perturbed_top_K_func=perturbed_top_K_func)\n",
    "negative_bpr_loss = torch.mean(-positive_bpr_T)\n",
    "loss=negative_bpr_loss\n",
    "\n",
    "loss.backward()\n",
    "loss_grad_TS = ratio_rating_TS.grad\n",
    "\n",
    "gradient_TSP = score_func_estimator_TSP * torch.unsqueeze(loss_grad_TS, -1)\n",
    "gradient_P = torch.sum(gradient_TSP, dim=[0,1])\n",
    "\n",
    "gradient_tuple = model.single_tensor_to_params(gradient_P)\n",
    "\n",
    "deterministic_bpr_T = deterministic_bpr(ratio_rating_TS, torch.tensor(train_y_TS), K=K)\n",
    "det_bpr =torch.mean(deterministic_bpr_T)\n",
    "noisy_bpr = torch.mean(-negative_bpr_loss)\n",
    "\n",
    "for param, gradient in zip(model.parameters(), gradient_tuple):\n",
    "    param.grad = gradient\n",
    "print(f'det bpr: {det_bpr}')\n",
    "print(f'noisy bpr: {noisy_bpr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1883, -0.1883,  0.1856, -0.1856,  0.1834, -0.1834],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_P[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4900, 0.5100],\n",
       "        [0.4900, 0.5100],\n",
       "        [0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(model.mixture_probs[-3:], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PRINT PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det bpr: 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash command to find the string \"det bpr: 0.9\" in a file in the directory\n",
    "# grep -r \"det bpr: 0.9\" . 2>/dev/null"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip_k3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
